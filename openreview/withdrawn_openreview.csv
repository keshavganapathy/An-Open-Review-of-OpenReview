year,paper,authors,emails,ratings,confidences,decisions,cmt_before_review,cmt_between,cmt_after_decision,double_blinded,submission_date,institution,csranking,ranking,categories
2018,Assessing the scalability of biologically-motivated deep learning algorithms and architectures,Sergey Bartunov;Adam Santoro;Blake A. Richards;Geoffrey E. Hinton;Timothy P. Lillicrap,ICLR.cc/2018/Conference/Paper607/Authors,8;5;6,5;3;4,Withdrawn,1,0,,yes,1/13/18,,,,1
2018,Neural Variational Sparse Topic Model,Qianqian Xie,ICLR.cc/2018/Conference/Paper79/Authors,5;3;3,4;4;4,Withdrawn,0,0,,yes,1/21/18,,,,1;5;5
2018,Melody Generation for Pop Music via Word Representation of Musical Properties,Andrew Shin;Leopold Crestel;Hiroharu Kato;Kuniaki Saito;Katsunori Ohnishi;Masataka Yamaguchi;Masahiro Nakawaki;Yoshitaka Ushiku;Tatsuya Harada,andrew@mi.t.u-tokyo.ac.jp;crestel@ircam.fr;kato@mi.t.u-tokyo.ac.jp;k-saito@mi.t.u-tokyo.ac.jp;ohnishi@mi.t.u-tokyo.ac.jp;yamaguchi@mi.t.u-tokyo.ac.jp;nakawaki.ici@gmail.com;ushiku@mi.t.u-tokyo.ac.jp;harada@mi.t.u-tokyo.ac.jp,4;4;5,5;4;4,Withdrawn,0,0,,yes,1/29/18,The University of Tokyo;;The University of Tokyo;The University of Tokyo;The University of Tokyo;The University of Tokyo;;The University of Tokyo;The University of Tokyo,52;139;52;52;52;52;139;52;52,45;3;45;45;45;45;3;45;45,
2018,Spatial Variational Auto-Encoding via Matrix-Variate Normal Distributions,Zhengyang Wang;Hao Yuan;Shuiwang Ji,zwang6@eecs.wsu.edu;hao.yuan@wsu.edu;sji@eecs.wsu.edu,5;4;3,2;4;5,Withdrawn,0,0,,yes,12/3/17,SUN YAT-SEN UNIVERSITY;SUN YAT-SEN UNIVERSITY;SUN YAT-SEN UNIVERSITY,468;468;468,352;352;352,5
2018,Dense Transformer Networks,Jun Li;Yongjun Chen;Lei Cai;Ian Davidson;Shuiwang Ji,jun.li3@wsu.edu;yongjun.chen@wsu.edu;lei.cai@wsu.edu;davidson@cs.ucdavis.edu;sji@eecs.wsu.edu,3;4;4,5;4;4,Withdrawn,0,0,,yes,12/2/17,"SUN YAT-SEN UNIVERSITY;SUN YAT-SEN UNIVERSITY;SUN YAT-SEN UNIVERSITY;University of California, Davis;SUN YAT-SEN UNIVERSITY",468;468;468;78;468,352;352;352;54;352,2
2018,Self-Organization adds application robustness to deep learners,Pitoyo Hartono;Thomas Trappenberg,hartono@ieee.org;tt@cs.dal.edu,4;2;2,4;5;5,Withdrawn,0,0,,yes,12/25/17,Meiji University;,468;139,334;3,5
2018,Information Theoretic Co-Training,David McAllester,mcallester@ttic.edu,4;5;4,4;3;4,Withdrawn,0,0,,yes,1/5/18,Toyota Technological Institute at Chicago,-1,-1,
2018,Towards Quantum Inspired Convolution Networks,Davi Geiger;Zvi Kedem,dg1@nyu.edu;kedem@nyu.edu,3;4;5,5;3;3,Withdrawn,3,0,,yes,12/2/17,New York University;New York University,26;26,27;27,
2018,A cluster-to-cluster framework for neural machine translation,Anonymous,ICLR.cc/2018/Conference/Paper150/Authors,6;3;5,3;4;2,Withdrawn,0,0,,yes,12/13/17,,,,1;3
2018,Deep Epitome for Unravelling Generalized Hamming Network: A Fuzzy Logic Interpretation of Deep Learning,Lixin Fan,ICLR.cc/2018/Conference/Paper167/Authors,3;7;4,3;2;4,Withdrawn,0,0,,yes,1/4/18,,,,1
2018,Interactive Boosting of Neural Networks for Small-sample Image Classification,Xiaoxu Li;Dongliang Chang;Zheng-Hua Tan;Zhanyu Ma;Jun Guo;Jie Cao,xiaoxulilut@gmail.com;dlchanglut@hotmai.com;zt@es.aau.dk;mazhanyu@bupt.edu.cn;guojun@bupt.edu.cn;caoj@lut.cn,5;5;4,4;5;4,Withdrawn,1,4,,yes,1/2/18,;Hotmai;Aarhus University;Beijing University of Post and Telecommunication;Beijing University of Post and Telecommunication;,139;-1;28;468;468;139,3;-1;60;1103;1103;3,
2018,Tensor-Based Preposition Representation,Hongyu Gong;Suma Bhat;Pramod Viswanath,hgong6@illinois.edu;pramodv@illinois.edu;spbhat2@illinois.edu,6;4;5,4;4;4,Withdrawn,0,0,,yes,12/12/17,"University of Illinois, Urbana Champaign;University of Illinois, Urbana Champaign;University of Illinois, Urbana Champaign",3;3;3,37;37;37,
2018,Tactical Decision Making for Lane Changing with Deep Reinforcement Learning,Mustafa Mukadam;Akansel Cosgun;Alireza Nakhaei;Kikuo Fujimura,mmukadam3@gatech.edu;acosgun@hra.com;anakhaei@hra.com;kfujimura@hra.com,3;3;3,4;5;5,Withdrawn,0,0,,yes,12/13/17,Georgia Institute of Technology;Hra;Hra;Hra,13;-1;-1;-1,33;-1;-1;-1,
2018, A Matrix Approximation View of NCE that Justifies Self-Normalization,Jacob Goldberger;Oren Melamud,jacob.goldberger@biu.ac.il;oren@melamuds.com,6;2;3,3;4;5,Withdrawn,0,0,,yes,12/14/17,Bar Ilan University;Melamuds,-1;-1,-1;-1,3
2018,Empirical Investigation on Model Capacity and Generalization of Neural Networks for Text,Anonymous,ICLR.cc/2018/Conference/Paper265/Authors,4;3;4,5;4;5,Withdrawn,0,0,,yes,1/22/18,,,,3;3
2018,Detecting Anomalies in Communication Packet Streams based on  Generative Adversarial Networks,Di Zhang;Qiang Niu;Xingbao Qiu,ICLR.cc/2018/Conference/Paper280/Authors,6;4;5,4;5;3,Withdrawn,0,3,,yes,1/3/18,,,,4;6
2018,Distributional Inclusion Vector Embedding for Unsupervised Hypernymy Detection,Haw-Shiuan Chang;ZiYun Wang;Luke Vilnis;Andrew McCallum,hschang@cs.umass.edu;wang-zy14@mails.tsinghua.edu.cn;luke@cs.umass.edu;mccallum@cs.umass.edu,4;5;5,5;5;5,Withdrawn,0,3,,yes,12/15/17,"University of Massachusetts, Amherst;Tsinghua University;University of Massachusetts, Amherst;University of Massachusetts, Amherst",30;10;30;30,191;30;191;191,3
2018,Embedding Multimodal Relational Data,Pouya Pezeshkpour;Liyan Chen;Sameer Singh,pezeshkp@uci.edu;liyanc@uci.edu;sameer@uci.edu,6;4;5,4;4;5,Withdrawn,0,0,,yes,12/13/17,"University of California, Irvine;University of California, Irvine;University of California, Irvine",36;36;36,99;99;99,
2018,pix2code: Generating Code from a Graphical User Interface Screenshot,Tony Beltramelli,ICLR.cc/2018/Conference/Paper334/Authors,2;5;5,5;4;4,Withdrawn,0,0,,yes,12/14/17,,,,
2018,Improved Learning in Convolutional Neural Networks with Shifted Exponential Linear Units (ShELUs),Bertil Grelsson;Michael Felsberg,ICLR.cc/2018/Conference/Paper459/Authors,1;4;3,5;5;5,Withdrawn,0,5,,yes,1/17/18,,,,1
2018,Robust Task Clustering for Deep and Diverse Multi-Task and Few-Shot Learning,Mo Yu;Xiaoxiao Guo;Jinfeng Yi;Shiyu Chang;Saloni Potdar;Gerald Tesauro;Haoyu Wang;Bowen Zhou,yum@us.ibm.com;xiaoxiao.guo@ibm.com;jinfengyi.ustc@gmail.com,5;4;5,4;4;4,Withdrawn,0,0,,yes,12/14/17,International Business Machines;International Business Machines;JD AI Research,-1;-1;-1,-1;-1;-1,6
2018,Per-Weight Class-Based Learning Rates via Analytical Continuation,Michael Rotman;Lior Wolf,migo007@gmail.com;wolf@fb.com,3;3;3,4;2;4,Withdrawn,0,0,,yes,12/2/17,Tel Aviv University;Facebook,37;-1,217;-1,1
2018,VSE++: Improving Visual-Semantic Embeddings with Hard Negatives,Fartash Faghri;David J. Fleet;Jamie Ryan Kiros;Sanja Fidler,faghri@cs.toronto.edu;fleet@cs.toronto.edu;rkiros@cs.toronto.edu;fidler@cs.toronto.edu,4,4,Withdrawn,0,0,,yes,11/16/17,"Department of Computer Science, University of Toronto;Department of Computer Science, University of Toronto;Department of Computer Science, University of Toronto;Department of Computer Science, University of Toronto",17;17;17;17,22;22;22;22,
2018,Dynamically Learning the Learning Rates:  Online Hyperparameter Optimization,Tuhin Sarkar;Anima Anandkumar;Leo Dirac,tsarkar@mit.edu;animakumar@gmail.com;leodirac@amazon.com,4;5;4,4;4;4,Withdrawn,0,0,,yes,1/3/18,Massachusetts Institute of Technology;University of California-Irvine;Amazon,2;36;-1,5;99;-1,
2018,MULTI-MODAL GEOLOCATION ESTIMATION USING DEEP NEURAL NETWORKS,Jesse Johns;Jeremiah Rounds;Michael Henry,jesse.johns@pnnl.gov;jeremiah.rounds@pnnl.gov;michael.j.henry@pnnl.gov,4;4;3,4;4;4,Withdrawn,0,0,,yes,1/3/18,Pacific Northwest National Laboratory;Pacific Northwest National Laboratory;Pacific Northwest National Laboratory,-1;-1;-1,-1;-1;-1,1
2018,Accelerating Convolutional Neural Networks using Iterative Two-Pass Decomposition,Wei-Shiang Lin;Hao-Ning Wu;Chih-Tsun Huang,weishianglin1993@gmail.com;wuhoward2002@gmail.com;cthuang@cs.nthu.edu.tw,4;3;5,4;5;4,Withdrawn,0,0,,yes,1/5/18,;;National Tsing Hua University,139;139;181,3;3;323,
2018,Adaptive Weight Sparsity for Training Deep Neural Networks,Michael James;Jack Lindsey;Ilya Sharapov,michael@cerebras.net;jacklindsey@stanford.edu;ilya@cerebras.net,5;3;4,3;4;2,Withdrawn,0,1,,yes,1/20/18,"Cerebras Systems, Inc;Stanford University;Cerebras Systems, Inc",-1;4;-1,-1;3;-1,
2018,Deep Net Triage: Assessing The Criticality of Network Layers by Structural Compression,Theodore S. Nowak;Jason J. Corso,tsnowak@umich.edu;jjcorso@umich.edu,5;4;5,4;4;3,Withdrawn,0,0,,yes,1/6/18,University of Michigan;University of Michigan,8;8,21;21,1
2018,Deep Active Learning over the Long Tail,Yonatan Geifman;Ran El-Yaniv,ICLR.cc/2018/Conference/Paper718/Authors,5;4;4,3;4;4,Withdrawn,0,1,,yes,1/5/18,,,,1
2018,THE LOCAL DIMENSION OF DEEP MANIFOLD,Mengxiao Zhang;Wangquan Wu;Yanren Zhang;Kun He;Tao Yu;Huan Long;John E. Hopcroft,zmx@hust.edu.cn;u201514497@hust.edu.cn;hhxjzyr@hust.edu.cn;brooklet60@hust.edu.cn;ydtydr@sjtu.edu.cn;longhuan@cs.sjtu.edu.cn;jeh@cs.cornell.edu,3;3;5,4;3;4,Withdrawn,0,0,,yes,1/3/18,Hong Kong University of Science and Technology;Hong Kong University of Science and Technology;Hong Kong University of Science and Technology;Hong Kong University of Science and Technology;Shanghai Jiao Tong University;Shanghai Jiao Tong University;Cornell University,40;40;40;40;57;57;7,44;44;44;44;188;188;19,5
2018,Learning to Imagine Manipulation Goals for Robot Task Planning,Chris Paxton;Kapil Katyal;Christian Rupprecht;Raman Arora;Gregory D Hager,cpaxton@jhu.edu;kkatyal2@jhu.edu;christian.rupprecht@in.tum.de;arora@cs.jhu.edu;hager@cs.jhu.edu,3;3;3,4;3;3,Withdrawn,1,0,,yes,12/22/17,Johns Hopkins University;Johns Hopkins University;Technical University Munich;Johns Hopkins University;Johns Hopkins University,71;71;55;71;71,13;13;41;13;13,
2018,Human-like Clustering with Deep Convolutional Neural Networks,Ali Borji;Aysegul Dundar,aliborji@gmail.com;adundar@purdue.edu,4;3,5;5,Withdrawn,1,1,,yes,12/4/17,University of Central Florida;Purdue University,81;28,1103;60,2;2;5
2018,Attribute-aware Collaborative Filtering: Survey and Classification,Wen-Hao Chen;Chin-Chi Hsu;Mi-Yen Yeh;Shou-De Lin,b02902023@ntu.edu.tw;chinchi@iis.sinica.edu.tw;miyen@iis.sinica.edu.tw;sdlin@csie.ntu.edu.tw,5;5;4,4;5;5,Withdrawn,0,0,,yes,12/11/17,National Taiwan University;Academia Sinica;Academia Sinica;National Taiwan University,85;-1;-1;85,197;-1;-1;197,
2018,Continuous Propagation: Layer-Parallel Training,Michael James;Devansh Arpit;Herman Sahota;Ilya Sharapov,michae@cerebras.net;devansharpit@gmail.com;herman@cerebras.net;ilya@cerebras.net,5;4;3,4;3;4,Withdrawn,1,3,,yes,1/19/18,"Cerebras Systems, Inc;University of Montreal;Cerebras Systems, Inc;Cerebras Systems, Inc",-1;124;-1;-1,-1;108;-1;-1,1
2018,Learning Topics using Semantic Locality,Ziyi Zhao;Krittaphat Pugdeethosapol;Sheng Lin;Zhe Li;Yanzhi Wang;Qinru Qiu,zzhao37@syr.edu;kpugdeet@syr.edu;shlin@syr.edu;zli89@syr.edu;ywang393@syr.edu;qiqiu@syr.edu,3;4;3,4;4;5,Withdrawn,0,0,,yes,1/24/18,Syracuse University;Syracuse University;Syracuse University;Syracuse University;Syracuse University;Syracuse University,244;244;244;244;244;244,275;275;275;275;275;275,1
2018,Anticipatory Asynchronous Advantage Actor-Critic (A4C): The power of Anticipation in Deep Reinforcement Learning,Xun Luan;Tharun Medini;Anshumali Shrivastava,xun.luan@rice.edu;trm3@rice.edu;anshumali@rice.edu,4;2;3,4;5;5,Withdrawn,0,2,,yes,1/13/18,Rice University;Rice University;Rice University,85;85;85,86;86;86,1
2018,Sparse Deep Scattering Croisé Network,Romain Cosentino;Randall Balestriero;Richard Baraniuk;Ankit Patel,rom.cosentino@gmail.com;randallbalestriero@gmail.com;ankitpatel715@gmail.com;baraniuk@gmail.com,6,4,Withdrawn,0,0,,yes,11/25/17,Rice University;Rice University;;,85;85;139;139,86;86;3;3,1
2018,Incremental Learning in Deep Convolutional Neural Networks Using Partial Network Sharing,Syed Shakib Sarwar;Aayush Ankit;Kaushik Roy,sarwar@purdue.edu;aankit@purdue.edu;kaushik@purdue.edu,4;2;4,4;5;5,Withdrawn,0,0,,yes,12/7/17,Purdue University;Purdue University;Purdue University,28;28;28,60;60;60,6
2018,Bayesian Embeddings for Long-Tailed Datasets,Victor Fragoso;Deva Ramanan,victor.fragoso@mail.wvu.edu;deva@andrew.cmu.edu,5;5;5,4;4;4,Withdrawn,1,3,,yes,1/17/18,West Virginia University;Carnegie Mellon University,-1;1,-1;24,1
2018,Deep Hyperspherical Defense against Adversarial Perturbations,Weiyang Liu;Zhen Liu;Zhehui Chen;Bo Dai;Tuo Zhao;Le Song,wyliu@gatech.edu;liuzhen1994@gatech.edu;zchen451@gatech.edu;bohr.dai@gmail.com;tourzhao@gatech.edu;lsong@cc.gatech.edu,4;5;5,5;4;3,Withdrawn,0,0,,yes,12/4/17,Georgia Institute of Technology;Georgia Institute of Technology;Georgia Institute of Technology;Georgia Institute of Technology;Georgia Institute of Technology;Georgia Institute of Technology,13;13;13;13;13;13,33;33;33;33;33;33,1;4;4
2018,FastNorm: Improving Numerical Stability of Deep Network Training with Efficient Normalization,Sadhika Malladi;Ilya Sharapov,sadhika@mit.edu;ilya@cerebras.net,4;4;3,3;4;3,Withdrawn,0,2,,yes,1/20/18,"Massachusetts Institute of Technology;Cerebras Systems, Inc",2;-1,5;-1,1
2018,Cluster-based Warm-Start Nets,Anonymous,ICLR.cc/2018/Conference/Paper998/Authors,6;3;3,5;4;4,Withdrawn,0,4,,yes,1/5/18,,,,1
2018,Do Convolutional Neural Networks act  as Compositional Nearest Neighbors?,Chunhui Liu;Aayush Bansal;Victor Fragoso;Deva Ramanan,ICLR.cc/2018/Conference/Paper1109/Authors,4;3;3,5;5;3,Withdrawn,1,13,,yes,1/17/18,,,,2;5
2018,DETECTING ADVERSARIAL PERTURBATIONS WITH SALIENCY,Chiliang Zhang;Zuochang Ye;Bo Zhang;Deli Zhao,zhangcl16@mails.tsinghua.edu.cn;zuochang@tsinhua.edu.cn;zhangbo@xiaomi.com;zhaodeli@gmail.com,3;4;4;4,5;4;4;4,Withdrawn,0,1,,yes,12/12/17,Tsinghua University;Tsinghua University;Xiaomi;Xiaomi,10;10;-1;-1,30;30;-1;-1,4
2018,Withdraw,Liyuan Liu;Jingbo Shang;Xiaotao Gu;Xiang Ren;Jian Peng;Jiawei Han,ll2@illinois.edu;shang7@illinois.edu;xiaotao2@illinois.du;xiangren@usc.edu;jianpeng@illinois.edu;hanj@illinois.edu,5;4;3,3;5;5,Withdrawn,0,0,,yes,12/15/17,"University of Illinois, Urbana Champaign;University of Illinois, Urbana Champaign;;University of Southern California;University of Illinois, Urbana Champaign;University of Illinois, Urbana Champaign",3;3;139;31;3;3,37;37;3;66;37;37,
2018,Complex- and Real-Valued Neural Network Architectures,Nils Moenning;Suresh Manandhar,nm819@york.ac.uk;suresh.manandhar@york.ac.uk,2;4;3,5;4;4,Withdrawn,0,3,,yes,1/3/18,University of York;University of York,210;210,137;137,
2018,Learning with Mental Imagery,Anonymous,ICLR.cc/2018/Conference/Paper839/Authors,4;3;3,4;4;4,Withdrawn,0,0,,yes,1/5/18,,,,4;5;5
2018,Withdrawn,withdrawn.,withdrawn,5;7;5,5;4;4,Withdrawn,0,0,,yes,1/2/18,,,,
2018,HyperNetworks with statistical filtering for defending adversarial examples,Zhun Sun;Mete Ozay;Takayuki Okatani,ICLR.cc/2018/Conference/Paper293/Authors,5;4;5,3;3;4,Withdrawn,0,0,,yes,12/18/17,,,,1;4;4
2018,withdrawn,withdrawn,withdrawn,4;5;4,4;4;4,Withdrawn,0,0,,yes,9/27/18,,,,
2019,Exponentially Decaying Flows for Optimization in Deep Learning,Mitsuharu Takeori;Kenta Nakamura,takeori.mitsuharu.d5s@jp.nssol.nssmc.com;nakamura.kenta.4n4@jp.nssol.nssmc.com,3;3;2,5;3;5,Withdrawn,0,0,,yes,9/27/18,NS Solutions Corporation;NS Solutions Corporation,-1;-1,-1;-1,
2019,In search of theoretically grounded pruning,Filip Svoboda;Edgar Liberis;Nicholas D. Lane,filip.svoboda@stx.ox.ac.uk;edgar.liberis@chch.ox.ac.uk;nicholas.lane@cs.ox.ac.uk,4;3;5,3;4;3,Withdrawn,0,3,,yes,9/27/18,University of Oxford;University of Oxford;University of Oxford,50;50;50,1;1;1,1
2019,Structured Content Preservation for Unsupervised Text Style Transfer,Youzhi Tian;Zhiting Hu;Zhou Yu,yztian@ucdavis.edu;zhitingh@cs.cmu.edu;joyu@ucdavis.edu,5;6;4,4;3;5,Withdrawn,0,0,,yes,9/27/18,"University of California, Davis;Carnegie Mellon University;University of California, Davis",81;1;81,54;24;54,1;3
2019,Advanced Neuroevolution: A gradient-free algorithm to train Deep Neural Networks,Ahmed Aly;David Weikersdorfer;Claire Delaunay,aaa2cn@virginia.edu;dweikersdorfer@nvidia.com;cdelaunay@nvidia.com,1;1;5,5;5;4,Withdrawn,2,11,,yes,9/27/18,University of Virginia;NVIDIA;NVIDIA,65;-1;-1,113;-1;-1,
2019,Bridging HMMs and RNNs through Architectural Transformations,Jan Buys;Yonatan Bisk;Yejin Choi,jbuys@cs.washington.edu;ybisk@yonatanbisk.com;yejin@cs.washington.edu,3;5;5,3;4;4,Withdrawn,0,7,,yes,9/27/18,University of Washington;University of Washington;University of Washington,6;6;6,25;25;25,3
2019,Learning with Little Data: Evaluation of Deep Learning Algorithms,Andreas Look;Stefan Riedelbauch,andreas.look@ihs.uni-stuttgart.de;stefan.riedelbauch@ihs.uni-stuttgart.de,6;4;4,4;3;5,Withdrawn,0,3,,yes,9/27/18,University of Stuttgart;University of Stuttgart,95;95,219;219,1;4;5;5;6
2019,Hierarchical Deep Reinforcement Learning Agent with Counter Self-play  on Competitive Games ,Huazhe Xu;Keiran Paster;Qibin Chen;Haoran Tang;Pieter Abbeel;Trevor Darrell;Sergey Levine,huazhe_xu@berkeley.edu;keirp@berkeley.edu;cqb@tsinghua.edu.cn;hrtang@math.berkeley.edu;pabbeel@cs.berkeley.edu;trevor@eecs.berkeley.edu;svlevine@eecs.berkeley.edu,3;2;2,3;4;3,Withdrawn,0,0,,yes,9/27/18,University of California Berkeley;University of California Berkeley;Tsinghua University;University of California Berkeley;University of California Berkeley;University of California Berkeley;University of California Berkeley,5;5;8;5;5;5;5,18;18;30;18;18;18;18,
2019,Label Smoothing and Logit Squeezing: A Replacement for Adversarial Training?,Ali Shafahi;Amin Ghiasi;Furong Huang;Tom Goldstein,ashafahi@cs.umd.edu;amin@cs.umd.edu;furongh@cs.umd.edu;tomg@cs.umd.edu,7;4;2,5;3;5,Withdrawn,13,9,,yes,9/27/18,"University of Maryland, College Park;University of Maryland, College Park;University of Maryland, College Park;University of Maryland, College Park",12;12;12;12,69;69;69;69,1;4;4
2019,Rotation Equivariant Networks via Conic Convolution and the DFT,Benjamin Chidester;Minh N. Do;Jian Ma,bchidest@andrew.cmu.edu;minhdo@illinois.edu;jianma@cs.cmu.edu,4;7;6,4;2;3,Withdrawn,0,1,,yes,9/27/18,"Carnegie Mellon University;University of Illinois, Urbana Champaign;Carnegie Mellon University",1;3;1,24;37;24,1
2019,GradMix: Multi-source Transfer across Domains and Tasks,Junnan Li;Ziwei Xu;Yongkang Wong;Qi Zhao;Mohan S. Kankanhalli,lijunnan@u.nus.edu;ziwei-xu@comp.nus.edu.sg;yongkang.wong@nus.edu.sg;qzhao@cs.umn.edu;mohan@comp.nus.edu.sg,3;5;3,5;4;5,Withdrawn,0,4,,yes,9/27/18,"National University of Singapore;National University of Singapore;National University of Singapore;University of Minnesota, Minneapolis;National University of Singapore",16;16;16;57;16,22;22;22;56;22,2;6;6
2019,Understanding and Improving Sequence-Labeling NER with Self-Attentive LSTMs,Peng-Hsuan Li;Wei-Yun Ma,jacobvsdanniel@iis.sinica.edu.tw;ma@iis.sinica.edu.tw,4;3;3,4;5;4,Withdrawn,0,4,,yes,9/27/18,Academia Sinica;Academia Sinica,-1;-1,-1;-1,1
2019,Differentiable Greedy Networks,Thomas Powers;Rasool Fakoor;Siamak Shakeri;Abhinav Sethy;Amanjit Kainth;Abdel-rahman Mohamed;Ruhi Sarikaya,tcpowers@uw.edu;rasool.fakoor@mavs.uta.edu;siamaks@amazon.com;sethya@amazon.com;amanjitsingh.kainth@mail.utoronto.ca;asamir@cs.toronto.edu;rsarikay@amazon.com,5;2;4,4;5;4,Withdrawn,0,4,,yes,9/27/18,"University of Washington, Seattle;University of Texas, Arlington;Amazon;Amazon;Toronto University;Department of Computer Science, University of Toronto;Amazon",6;115;-1;-1;18;18;-1,25;601;-1;-1;22;22;-1,
2019,Efficient Federated Learning via Variational Dropout,Wei Du;Xiao Zeng;Ming Yan;Mi Zhang,duwei1@msu.edu;zengxia6@msu.edu;myan@msu.edu;mizhang@msu.edu,4;4;3,4;3;4,Withdrawn,0,1,,yes,9/27/18,SUN YAT-SEN UNIVERSITY;SUN YAT-SEN UNIVERSITY;SUN YAT-SEN UNIVERSITY;SUN YAT-SEN UNIVERSITY,478;478;478;478,352;352;352;352,
2019,Applications of Gaussian Processes in Finance,Rajbir S. Nirwan;Nils Bertschinger,nirwan@fias.uni-frankfurt.de;bertschinger@fias.uni-frankfurt.de,4;5;3,5;4;4,Withdrawn,0,2,,yes,9/27/18,Goethe University;Goethe University,65;65,70;70,
2019,An Attention-Based Model for Learning Dynamic Interaction Networks,Sandro Cavallari;Vincent W Zheng;Hongyun Cai;Erik Cambria,sandro001@e.ntu.edu.sg;vincent.zheng@adsc-create.edu.sg;hongyun.c@adsc.com.sg;cambria@ntu.edu.sg,4;3;4,3;5;4,Withdrawn,0,0,,yes,9/27/18,National Taiwan University;ADSC;Advanced Digital Sciences Center;National Taiwan University,85;-1;-1;85,197;-1;-1;197,1
2019,Modeling Evolution of Language Through Time with Neural Networks,Edouard Delasalles;Sylvain Lamprier;Ludovic Denoyer,edouard.delasalles@lip6.fr;sylvain.lamprier@lip6.fr;ludovic.denoyer@lip6.fr,3;4;4,5;5;4,Withdrawn,0,0,,yes,9/27/18,LIP6;LIP6;LIP6,-1;-1;-1,-1;-1;-1,3
2019,Knowledge Representation for Reinforcement Learning using General Value Functions,Gheorghe Comanici;Doina Precup;Andre Barreto;Daniel Kenji Toyama;Eser Aygün;Philippe Hamel;Sasha Vezhnevets;Shaobo Hou;Shibl Mourad,gcomanici@google.com;doinap@google.com;andrebarreto@google.com;kenjitoyama@google.com;eser@google.com;hamelphi@google.com;vezhnick@google.com;shaobohou@google.com;shibl@google.com,6;7;4,3;3;4,Withdrawn,0,0,,yes,9/27/18,Google;Google;Google;Google;Google;Google;Google;Google;Google,-1;-1;-1;-1;-1;-1;-1;-1;-1,-1;-1;-1;-1;-1;-1;-1;-1;-1,
2019,,,vladymyrov@gmail.com,5;4;4,4;4;4,Withdrawn,0,0,,yes,9/27/18,,,,
2019,Geometric Operator Convolutional Neural Network,Yangling Ma;Yixin Luo;Zhouwang Yang,yangma@mail.ustc.edu.cn;seeing@mail.ustc.edu.cn;yangzw@ustc.edu.cn,2;5;3,5;5;4,Withdrawn,2,0,,yes,9/27/18,University of Science and Technology of China;University of Science and Technology of China;University of Science and Technology of China,478;478;478,132;132;132,4
2019,Online Bellman Residue Minimization via Saddle Point Optimization,Zhuoran Yang;Cheng Zhou;Tong Zhang;Han Liu,zy6@princeton.edu;mikechzhou@tencent.com;tongzhang@tongzhang-ml.org;hanliu.cmu@gmail.com,5;5;4,4;4;4,Withdrawn,0,3,,yes,9/27/18,Princeton University;Tencent AI Lab;;,30;-1;140;140,7;-1;3;3,
2019,Dual Importance Weight GAN,Gahye Lee;Seungkyu Lee,waldstein94@gmail.com;seungkyu@khu.ac.kr,4;3;5,4;5;4,Withdrawn,0,0,,yes,9/27/18,KyungHee univ.;Kyung Hee University,-1;-1,-1;-1,1;4;5;5
2019,Explainable Adversarial Learning: Implicit Generative Modeling of Random Noise during Training for Adversarial Robustness,Priyadarshini Panda;Kaushik Roy,pandap@purdue.edu;kaushik@purdue.edu,3;5;5,4;4;4,Withdrawn,0,7,,yes,9/27/18,Purdue University;Purdue University,26;26,60;60,1;4;4;5
2019,Nonlinear Channels Aggregation Networks for Deep Action Recognition,Zhigang Zhu;Hongbing Ji;Wenbo Zhang;Cheng Ouyang,zgzhu_xidian@163.com;hbji@xidian.edu.cn;zwbsoul@163.com;ouoyc@aliyun.com,3;3;3,3;4;5,Withdrawn,0,0,,yes,9/27/18,Tsinghua University;Tsinghua University;163;Aliyun,8;8;-1;-1,30;30;-1;-1,
2019,A SINGLE SHOT PCA-DRIVEN ANALYSIS OF NETWORK STRUCTURE TO REMOVE REDUNDANCY,Isha Garg;Priyadarshini Panda;Kaushik Roy,gargi@purdue.edu;pandap@purdue.edu;kaushik@purdue.edu,4;4;5,5;4;5,Withdrawn,0,0,,yes,9/27/18,Purdue University;Purdue University;Purdue University,26;26;26,60;60;60,2;3
2019,D2KE: From Distance to Kernel and Embedding via Random Features For Structured Inputs,Lingfei Wu;Ian E.H. Yen;Fangli Xu;Pradeep Ravikumar;Michael J. Witbrock,lwu@email.wm.edu;eyan@cs.cmu.edu;fxu02@email.wm.edu;pradeepr@cs.cmu.edu;witbrock@us.ibm.com,4;3;5,4;4;4,Withdrawn,0,0,,yes,9/27/18,College of William and Mary;Carnegie Mellon University;College of William and Mary;Carnegie Mellon University;International Business Machines,169;1;169;1;-1,261;24;261;24;-1,
2019,Latent Transformations for Object  View Points Synthesis,Sangpil Kim;Nick Winovich;Hyung-gun Chi;Guang Lin;Karthik Ramani,kim2030@purdue.edu;nwinovic@purdue.edu;chi45@purdue.edu;guanglin@purdue.edu;ramani@purdue.edu,4;2;5,4;4;2,Withdrawn,0,2,,yes,9/27/18,Purdue University;Purdue University;Purdue University;Purdue University;Purdue University,26;26;26;26;26,60;60;60;60;60,1;4;5
2019,Network Reparameterization for Unseen Class Categorization,Kai Li;Martin Renqiang Min;Bing Bai;Yun Fu;Hans Peter Graf,li.kai.gml@gmail.com;renqiang@nec-labs.com;bbai@nec-labs.com;yunfu@ece.neu.edu;hpg@nec-labs.com,5;3;5,5;5;3,Withdrawn,7,2,,yes,9/27/18,Northeastern University;NEC-Labs;NEC-Labs;Northeastern University;NEC-Labs,16;-1;-1;16;-1,839;-1;-1;839;-1,6
2019,Explaining Neural Networks Semantically and Quantitatively,Hao Chen;Runjin Chen;Quanshi Zhang,bridgechen@hust.edu.cn;chenrunjin@sjtu.edu.cn;zqs1022@sjtu.edu.cn,4;4;4,4;5;4,Withdrawn,0,4,,yes,9/27/18,Hong Kong University of Science and Technology;Shanghai Jiao Tong University;Shanghai Jiao Tong University,39;52;52,44;188;188,
2019,Explaining AlphaGo: Interpreting Contextual Effects in Neural Networks,Zenan Ling;Haotian Ma;Yu Yang;Robert C. Qiu;Song-Chun Zhu;Quanshi Zhang,lingzenan@sjtu.edu.cn;11612807@mail.sustc.edu.cn;yy19970901@ucla.edu;rqiu@tntech.edu;sczhu@stat.ucla.edu;zqs1022@sjtu.edu.cn,3;4;4,5;4;5,Withdrawn,1,3,,yes,9/27/18,"Shanghai Jiao Tong University;University of Science and Technology of China;University of California, Los Angeles;Tennessee Technological University;University of California, Los Angeles;Shanghai Jiao Tong University",52;478;20;-1;20;52,188;132;15;-1;15;188,
2019,Deepström Networks,Luc Giffon;Hachem Kadri;Stéphane Ayache;Thierry Artières,luc.giffon@lis-lab.fr;hachem.kadri@lis-lab.fr;stephane.ayache@lis-lab.fr;thierry.artieres@lis-lab.fr,4;5;3,4;4;5,Withdrawn,0,1,,yes,9/27/18,Aix Marseille Université;Aix Marseille Université;Aix Marseille Université;Aix Marseille Université,478;478;478;478,297;297;297;297,
2019,One Bit Matters: Understanding Adversarial Examples as the Abuse of Redundancy,Jingkang Wang;Ruoxi Jia;Gerald Friedland;Bo Li;Costas Spanos,wangjksjtu_01@sjtu.edu.cn;ruoxijia@berkeley.edu;fractor@eecs.berkeley.edu;lxbosky@gmail.com;spanos@berkeley.edu,3;3;3,4;4;4,Withdrawn,2,1,,yes,9/27/18,Shanghai Jiao Tong University;University of California Berkeley;University of California Berkeley;University of California Berkeley;University of California Berkeley,52;5;5;5;5,188;18;18;18;18,1;4;4
2019,,,samitha.herath@data61.csiro.au;u5505348@anu.edu.au;mehrtash.harandi@monash.edu,4;3;5,4;4;5,Withdrawn,0,3,,yes,9/27/18,", CSIRO;Australian National University;Monash University",-1;106;123,-1;48;80,
2019,Context-aware Forecasting for Multivariate Stationary Time-series,Valentin Guiguet;Nicolas Baskiotis;Vincent Guigue;Patrick Gallinari,guiguetvalentin@gmail.com;nicolas.baskiotis@lip6.fr;vincent.guigue@lip6.fr;patrick.gallinari@lip6.fr,5;5;4,3;5;4,Withdrawn,0,1,,yes,9/27/18,LIP6;LIP6;LIP6;LIP6,-1;-1;-1;-1,-1;-1;-1;-1,1
2019,HANDLING CONCEPT DRIFT  IN WIFI-BASED INDOOR LOCALIZATION USING REPRESENTATION LEARNING,Raihan Seraj;Negar Ghourchian;Michel Allegue-Martinez,raihan.seraj@mail.mcgill.ca;negar.gh@aerial.ai;michel.allegue@aerial.ai,2;3;4,1;4;4,Withdrawn,0,0,,yes,9/27/18,McGill University;Aerial Technologies Inc.;Aerial Technologies Inc.,85;-1;-1,42;-1;-1,
2019,Transfer Learning for Estimating Causal Effects Using Neural Networks,Sören R. Künzel;Bradly C. Stadie;Nikita Vemuri;Varsha Ramakrishnan;Jasjeet S. Sekhon;Pieter Abbeel,srk@berkeley.edu;bstadie@berkeley.edu;nikitavemuri@berkeley.edu;vio@berkeley.edu;sekhon@berkeley.edu;pabbeel@cs.berkeley.edu,7;5;3,3;4;3,Withdrawn,0,0,,yes,9/27/18,University of California Berkeley;University of California Berkeley;University of California Berkeley;University of California Berkeley;University of California Berkeley;University of California Berkeley,5;5;5;5;5;5,18;18;18;18;18;18,6
2019,Variational Autoencoders for Text Modeling without Weakening the Decoder,Ryo Kamoi;Hiroyasu Fukutomi,ryo_kamoi_st@keio.jp;hiroyasu.fukutomi@datasection.co.jp,4;4;1,3;5;4,Withdrawn,6,1,,yes,9/27/18,Keio University;,62;140,12;3,1;5;5;5
2019,A PRIVACY-PRESERVING IMAGE CLASSIFICATION FRAMEWORK WITH A LEARNABLE OBFUSCATOR,Xiangyi Meng;Zixuan Huang;Yuefeng Du;Antoni Chan;Cong Wang,xy.meng@my.cityu.edu.hk;zixuhuang3-c@my.cityu.edu.hk;yf.du@my.cityu.edu.hk;abchan@cityu.edu.hk;congwang@cityu.edu.hk,5;5;5,4;4;5,Withdrawn,2,0,,yes,9/27/18,City University of Hong Kong;City University of Hong Kong;City University of Hong Kong;City University of Hong Kong;City University of Hong Kong,89;89;89;89;89,40;40;40;40;40,4;4
2019,ODIN: Outlier Detection In Neural Networks,Rickard Sjögren;Johan Trygg,rickard.sjoegren@sartorius-stedim.com;johan.trygg@sartorius-stedim.com,5;4;4,4;4;4,Withdrawn,1,4,,yes,9/27/18,Computational Life Science Cluster;Sartorius-stedim,-1;-1,-1;-1,
2019,Improving latent variable descriptiveness by modelling rather than ad-hoc factors,Alex Mansbridge;Roberto Fierimonte;Ilya Feige;David Barber,amansbridge@turing.ac.uk;roberto.fierimonte@gmail.com;ilya@asidatascience.com;david.barber@ucl.ac.uk,4;4;6,4;4;3,Withdrawn,0,3,,yes,9/27/18,Alan Turing Institute;;University College London;University College London,-1;140;50;50,-1;3;16;16,3;5;5;5
2019,Capacity of Deep Neural Networks under Parameter Quantization,Yoonho Boo;Sungho Shin;and Wonyong Sung,dnsgh337@snu.ac.kr;ssh9919@snu.ac.kr;wysung@snu.ac.kr,5;5;5,3;4;3,Withdrawn,0,0,,yes,9/27/18,Seoul National University;Seoul National University;Seoul National University,41;41;41,74;74;74,3
2019,Learning of Sophisticated Curriculums by viewing them as Graphs over Tasks,Lucas Willems;Yoshua Bengio,lcswillems@gmail.com;yoshua.bengio@umontreal.ca,3;2;4,1;2;4,Withdrawn,0,3,,yes,9/27/18,Ecole Normale Superieure;University of Montreal,99;123,603;108,1
2019,RNNs with Private and Shared Representations for Semi-Supervised Sequence Learning,Ge Ya Luo;Jie Fu;Pengfei Liu;Zhi Hao Luo;Chris Pal,olga.xu@umontreal.ca;jie.fu@polymtl.ca;pfliu14@fudan.edu.cn;zhi-hao.luo@polymtl.ca;christopher.pal@polymtl.ca,3;5;4,5;5;4,Withdrawn,0,3,,yes,9/27/18,University of Montreal;Polytechnique Montreal;Fudan University;Polytechnique Montreal;Polytechnique Montreal,123;386;78;386;386,108;108;116;108;108,
2019,MAJOR-MINOR LSTMS FOR WORD-LEVEL LANGUAGE MODEL,Kai Shuang;Rui Li;Mengyu Gu;Qianqian Yang;Jonathan;Sen Su,shuangk@bupt.edu.cn;lirui@bupt.edu.cn;pattygu0622@bupt.edu.cn;echo_yang@bupt.edu.cn;jonathan.loo@uwl.ac.uk;susen@bupt.edu.cn,4;3;3,5;4;5,Withdrawn,2,4,,yes,9/27/18,Beijing University of Post and Telecommunication;Beijing University of Post and Telecommunication;Beijing University of Post and Telecommunication;Beijing University of Post and Telecommunication;;Beijing University of Post and Telecommunication,-1;-1;-1;-1;140;-1,-1;-1;-1;-1;3;-1,3
2019,SALSA-TEXT : SELF ATTENTIVE LATENT SPACE BASED ADVERSARIAL TEXT GENERATION,Jules Gagnon-Marchand;Hamed Sadeghi;Mehdi Rezagholizadeh;Md. Akmal Haider,jgagnonmarchand@gmail.com;haamed.sadeghi@gmail.com;mehdi.rezagholizadeh@gmail.com;md.akmal.haidar@huawei.com,4;4;5,3;4;4,Withdrawn,0,0,,yes,9/27/18,Huawei Technologies Ltd.;Huawei Technologies Ltd.;;Huawei Technologies Ltd.,-1;-1;140;-1,-1;-1;3;-1,1;4
2019,,Qingpeng Cai;Ling Pan;Pingzhong Tang,cqpcurry@gmail.com;penny.ling.pan@gmail.com;kenshinping@gmail.com,4;5;1,4;3;4,Withdrawn,0,2,,yes,9/27/18,Tsinghua University;Tsinghua University;Tsinghua University,8;8;8,30;30;30,
2019,Neuron Hierarchical Networks,Han Yue;De-An Wu;Lei Wu;Ji Xie,johnhany@163.com;wudean.cn@uestc.edu.cn;wulei@uestc.edu.cn;zonghengxs@163.com,5;4;4,4;4;4,Withdrawn,0,0,,yes,9/27/18,University of Electronic Science and Technology of China;University of Electronic Science and Technology of China;University of Electronic Science and Technology of China;163,169;169;169;-1,843;843;843;-1,
2019,Linearizing Visual Processes with Deep Generative Models,Alexander Sagel;Hao Shen,a.sagel@tum.de;shen@fortiss.org,3;3;4,4;4;3,Withdrawn,0,3,,yes,9/27/18,Technical University Munich;Fortiss,54;-1,41;-1,4;5;5
2019,Inhibited Softmax for Uncertainty Estimation in Neural Networks,Marcin Możejko;Mateusz Susik;Rafał Karczewski,marcin@sigmoidal.io;msusik@sigmoidal.io;rafal@sigmoidal.io,4;4;3,4;3;4,Withdrawn,0,1,,yes,9/27/18,;;,140;140;140,3;3;3,
2019,Improving Gaussian mixture latent variable model convergence with Optimal Transport,Benoit Gaujac;Ilya Feige;David Barber,benoit.gaujac.16@ucl.ac.uk;ilya@asidatascience.com;david.barber@ucl.ac.uk,5;5;5,3;4;4,Withdrawn,0,3,,yes,9/27/18,University College London;University College London;University College London,50;50;50,16;16;16,5;5
2019,From Amortised to Memoised Inference: Combining Wake-Sleep and Variational-Bayes for Unsupervised Few-Shot Program Learning,Luke B. Hewitt;Joshua B. Tenenbaum,lbh@mit.edu;jbt@mit.edu,3;3;3,5;5;4,Withdrawn,0,1,,yes,9/27/18,Massachusetts Institute of Technology;Massachusetts Institute of Technology,2;2,5;5,1;5
2019,,,v-ziclin@microsoft.com;lizo@microsoft.com,6;2;4,2;5;3,Withdrawn,3,0,,yes,9/27/18,Microsoft;Microsoft,-1;-1,-1;-1,
2019,Encoder Discriminator Networks for Unsupervised Representation Learning,Nils Wandel,nils.wandel@ais.uni-bonn.de,3;4;3,4;4;5,Withdrawn,0,4,,yes,9/27/18,University of Bonn,123,100,
2019,Geometry of Deep Convolutional Networks,Stefan Carlsson,stefanc@kth.se,2;4;3,5;4;2,Withdrawn,0,0,,yes,9/27/18,"KTH Royal Institute of Technology, Stockholm, Sweden",140,173,
2019,Learning and Data Selection in Big Datasets,Hossein S. Ghadikolaei;Hadi Ghauch;Carlo Fischione;Mikael Skoglund,hshokri@kth.se;ghauch@kth.se;carlofi@kth.se;skoglund@kth.se,4;3;3,3;4;5,Withdrawn,0,0,,yes,9/27/18,"KTH Royal Institute of Technology, Stockholm, Sweden;KTH Royal Institute of Technology, Stockholm, Sweden;KTH Royal Institute of Technology, Stockholm, Sweden;KTH Royal Institute of Technology, Stockholm, Sweden",140;140;140;140,173;173;173;173,
2019,Data Poisoning Attack against Unsupervised Node Embedding Methods,Mingjie Sun;Jian Tang;Huichen Li;Bo Li;Chaowei Xiao;Yao Chen;Dawn Song,sunmj15@gmail.com;tangjianpku@gmail.com;huichen3@illinois.edu;lxbosky@gmail.com;xiaocw@umich.edu;antoniechen@tencent.com;dawnsong@gmail.com,4;4;4,5;4;3,Withdrawn,0,0,,yes,9/27/18,"Tsinghua University;HEC Montreal;University of Illinois, Urbana Champaign;University of California Berkeley;University of Michigan;Tencent AI Lab;University of California Berkeley",8;-1;3;5;8;-1;5,30;-1;37;18;21;-1;18,1;4;4;4
2019,Shaping representations through communication,Olivier Tieleman;Angeliki Lazaridou;Shibl Mourad;Charles Blundell;Doina Precup,tieleman@google.com;angeliki@google.com;shibl@google.com;cblundell@google.com;doinap@google.com,5;4;5,4;4;4,Withdrawn,0,1,,yes,9/27/18,Google;Google;Google;Google;Google,-1;-1;-1;-1;-1,-1;-1;-1;-1;-1,5;6;6
2019,,,hongyang.gao@wsu.edu,5;4;4,4;5;4,Withdrawn,6,3,,yes,9/27/18,SUN YAT-SEN UNIVERSITY,478,352,
2019,,,na@na.edu,3;5;5,4;4;4,Withdrawn,0,3,,yes,9/27/18,University of Arizona,169,161,
2019,Exploiting Invariant Structures for Compression in Neural Networks,Jiahao Su;Jingling Li;Bobby Bhattacharjee;Furong Huang,jiahaosu@terpmail.umd.edu;jingling@cs.umd.edu;bobby@cs.umd.edu;furongh@cs.umd.edu,4;4;4,4;4;4,Withdrawn,0,1,,yes,9/27/18,"University of Maryland, College Park;University of Maryland, College Park;University of Maryland, College Park;University of Maryland, College Park",12;12;12;12,69;69;69;69,1
2019,Evading Defenses to Transferable Adversarial Examples by Mitigating Attention Shift,Yinpeng Dong;Tianyu Pang;Hang Su;Jun Zhu,dyp17@mails.tsinghua.edu.cn;pty17@mails.tsinghua.edu.cn;suhangss@mail.tsinghua.edu.cn;dcszj@mail.tsinghua.edu.cn,4;4;4,3;4;3,Withdrawn,0,5,,yes,9/27/18,Tsinghua University;Tsinghua University;Tsinghua University;Tsinghua University,8;8;8;8,30;30;30;30,1;4;4
2019,Classification of Building Noise Type/Position via Supervised Learning,Hwiyong Choi;Haesang Yang;Seungjun Lee;Woojae Seong,its_me_chy@snu.ac.kr;coupon3@snu.ac.kr;tl7qns7ch@snu.ac.kr;wseong@snu.ac.kr,4;4;4,2;4;4,Withdrawn,0,0,,yes,9/27/18,Seoul National University;Seoul National University;Seoul National University;Seoul National University,41;41;41;41,74;74;74;74,
2019,Nesterov's method is the discretization of a differential equation with Hessian damping,Adam M. Oberman;Maxime Laborde,adam.oberman@mcgill.ca;maxime.laborde@mcgill.ca,4;5;6,5;4;5,Withdrawn,5,0,,yes,9/27/18,McGill University;McGill University,85;85,42;42,
2019,"A Forensic Representation to Detect Non-Trivial Image Duplicates, and How it Applies to Semantic Segmentation",M. Cicconet;H. Elliott;D.L. Richmond;D. Wainstock;M. Walsh,cicconet@gmail.com;elliott.hunter@gmail.com;daverichmond@gmail.com;daniel_wainstock@hms.harvard.edu;mary_walsh@hms.harvard.edu,4;3;2,4;5;5,Withdrawn,0,0,,yes,9/27/18,Harvard University;;;Harvard University;Harvard University,39;140;140;39;39,6;3;3;6;6,1;2
2019,End-to-end Learning of a Convolutional Neural Network via Deep Tensor Decomposition,Samet Oymak;Mahdi Soltanolkotabi,sametoymak@gmail.com;soltanol@usc.edu,5;5;5,3;3;3,Withdrawn,0,0,,yes,9/27/18,"University of California, Riverside;University of Southern California",57;30,197;66,
2019,Domain Adaptive Transfer Learning,Jiquan Ngiam;Daiyi Peng;Vijay Vasudevan;Simon Kornblith;Quoc Le;Ruoming Pang,jngiam@google.com;daiyip@google.com;vrv@google.com;skornblith@google.com;qvl@google.com;rpang@google.com,3;4;7,5;4;4,Withdrawn,0,3,,yes,9/27/18,Google;Google;Google;Google;Google;Google,-1;-1;-1;-1;-1;-1,-1;-1;-1;-1;-1;-1,2;6
2019,Deep clustering based on a mixture of autoencoders,Shlomo E. Chazan;Sharon Gannot;Jacob Goldberger,shlomi.chazan@biu.ac.il;sharon.gannot@biu.ac.il;jacob.goldberger@biu.ac.il,6;4;5,3;3;5,Withdrawn,0,1,,yes,9/27/18,Bar Ilan University;Bar Ilan University;Bar Ilan University,95;95;95,456;456;456,1;5
2019,Live Face De-Identification in Video,Oran Gafni;Lior Wolf;Yaniv Taigman,oran@fb.com;wolf@fb.com;yaniv@fb.com,6;4;6,4;4;4,Withdrawn,0,4,,yes,9/27/18,Facebook;Facebook;Facebook,-1;-1;-1,-1;-1;-1,
2019,IMAGE DEFORMATION META-NETWORK FOR ONE-SHOT LEARNING,Zitian Chen;Yanwei Fu;Yu-Xiong Wang;Lin Ma;Wei Liu;Martial Hebert,tankche2@gmail.com;yanweifu@fudan.edu.cn;yuxiongw@cs.cmu.edu;forest.linma@gmail.com;wl2223@columbia.edu;hebert@ri.cmu.edu,5;7;6,4;1;4,Withdrawn,0,3,,yes,9/27/18,Fudan University;Fudan University;Carnegie Mellon University;Tencent AI Lab;Columbia University;Carnegie Mellon University,78;78;1;-1;15;1,116;116;24;-1;14;24,6
2019,Towards Resisting Large Data Variations via Introspective Learning,Yunhan Zhao;Ye Tian;Wei Shen;Alan Yuille,yzhao83@jhu.edu;tytian@outlook.com;shenwei1231@gmail.com;alan.l.yuille@gmail.com,4;5;6,4;4;3,Withdrawn,0,7,,yes,9/27/18,Johns Hopkins University;Verb Surgical;Johns Hopkins University;Johns Hopkins University,72;-1;72;72,13;-1;13;13,1;5
2019,Realistic Adversarial Examples in 3D Meshes,Chaowei Xiao;Dawei Yang;Bo Li;Jia Deng;Mingyan Liu,xiaocw@umich.edu;ydawei@umich.edu;lxbosky@gmail.com;jiadeng@cs.princeton.edu;mingyan@umich.edu,5;3;5,3;3;3,Withdrawn,0,0,,yes,9/27/18,University of Michigan;University of Michigan;University of California Berkeley;Princeton University;University of Michigan,8;8;5;30;8,21;21;18;7;21,4;4
2019,Representation Flow for Action Recognition,AJ Piergiovanni;Michael S. Ryoo,ajpiergi@indiana.edu;mryoo@indiana.edu,3;5;5,5;5;4,Withdrawn,2,10,,yes,9/27/18,University of Arizona;University of Arizona,169;169,161;161,
2019,PointGrow: Autoregressively Learned Point Cloud Generation with Self-Attention,Yongbin Sun;Yue Wang;Ziwei Liu;Joshua E. Siegel;Sanjay Sarma,yb_sun@mit.edu;yuewang@csail.mit.edu;zwliu.hust@gmail.com;j_siegel@mit.edu;sesarma@mit.edu,3;6;6,4;4;5,Withdrawn,0,0,,yes,9/27/18,Massachusetts Institute of Technology;Massachusetts Institute of Technology;The Chinese University of Hong Kong;Massachusetts Institute of Technology;Massachusetts Institute of Technology,2;2;57;2;2,5;5;40;5;5,
2019,Stacked U-Nets: A No-Frills Approach to Natural Image Segmentation,Sohil Shah;Pallabi Ghosh;Larry S Davis;Tom Goldstein,sohilas@umd.edu;tomg@cs.umd.edu;pallabig@umd.edu;lsd@umiacs.umd.edu,5;3;5,5;5;5,Withdrawn,0,1,,yes,9/27/18,"University of Maryland, College Park;University of Maryland, College Park;University of Maryland, College Park;University of Maryland, College Park",12;12;12;12,69;69;69;69,2;2
2019,UNSUPERVISED CONVOLUTIONAL NEURAL NETWORKS FOR ACCURATE VIDEO FRAME INTERPOLATION WITH INTEGRATION OF MOTION COMPONENTS,Thang Van Nguyen;Kyu-Joong Lee;Hyuk-Jae Lee,itmanhieu@snu.ac.kr;kyujoonglee@sunmoon.ac.kr;hjlee@capp.snu.ac.kr,3;5;4,4;4;5,Withdrawn,0,0,,yes,9/27/18,Seoul National University;Kyung Hee;Seoul National University,41;-1;41,74;-1;74,1
2019,Compositional GAN: Learning Conditional Image Composition,Samaneh Azadi;Deepak Pathak;Sayna Ebrahimi;Trevor Darrell,sazadi@berkeley.edu;pathak@berkeley.edu;sayna@berkeley.edu;trevor@eecs.berkeley.edu,4;4;5,5;4;4,Withdrawn,0,5,,yes,9/27/18,University of California Berkeley;University of California Berkeley;University of California Berkeley;University of California Berkeley,5;5;5;5,18;18;18;18,4;5;5
2019,PolyCNN: Learning Seed Convolutional Filters,Felix Juefei-Xu;Vishnu Naresh Boddeti;Marios Savvides,juefei.xu@gmail.com;vishnu@msu.edu;msavvide@ri.cmu.edu,3;4;4,4;2;3,Withdrawn,0,0,,yes,9/27/18,Alibaba Group;SUN YAT-SEN UNIVERSITY;Carnegie Mellon University,-1;478;1,-1;352;24,
2019,A Main/Subsidiary Network Framework for Simplifying Binary Neural Networks,Yinghao Xu;Xin Dong;Yudian Li;Hao Su,justimyhxu@zju.edu.cn;xindong@g.harvard.edu;daniellee2519@gmail.com;haosu@eng.ucsd.edu,5,4,Withdrawn,0,0,,yes,9/27/18,"Zhejiang University;Harvard University;University of Electronic Science and Technology of China;University of California, San Diego",57;39;169;11,177;6;843;31,
2019,A Teacher Student Network For Faster Video Classification,Shweta Bhardwaj;Mukundhan Srinivasan;Mitesh M. Khapra,cs16s003@cse.iitm.ac.in;msrinivasan@nvidia.com;miteshk@cse.iitm.ac.in,4;4;4,4;5;5,Withdrawn,0,0,,yes,9/27/18,Indian Institute of Technology Madras;NVIDIA;Indian Institute of Technology Madras,153;-1;153,625;-1;625,
2019,Data Interpretation and Reasoning Over Scientific Plots,Pritha Ganguly;Nitesh Methani;Mitesh M. Khapra,prithag@cse.iitm.ac.in;nmethani@cse.iitm.ac.in,6;6;3,4;4;4,Withdrawn,0,0,,yes,9/27/18,Indian Institute of Technology Madras;Indian Institute of Technology Madras,153;153,625;625,
2019,Logit Regularization Methods for Adversarial Robustness,Cecilia Summers;Michael J. Dinneen,ceciliasummers07@gmail.com;mjd@cs.auckland.ac.nz,3;5;2,5;5;5,Withdrawn,10,5,,yes,9/27/18,University of Auckland;University of Auckland,-1;-1,-1;-1,1;4;4
2019,Feature Matters: A Stage-by-Stage Approach for Task Independent Knowledge Transfer,Mengya Gao;Yujun Shen;Quanquan Li;Liang Wan;Xiaoou Tang,daisy@tju.edu.cn;sy116@ie.cuhk.edu.hk;liquanquan@sensetime.com;lwan@tju.edu.cn;xtang@ie.cuhk.edu.hk,5;4;4,4;4;4,Withdrawn,0,0,,yes,9/27/18,Zhejiang University;The Chinese University of Hong Kong;SenseTime Group Limited;Zhejiang University;The Chinese University of Hong Kong,57;57;-1;57;57,177;40;-1;177;40,
2019,Parametrizing Fully Convolutional Nets with a Single High-Order Tensor,Jean Kossaifi;Adrian Bulat;Georgios Tzimiropoulos;Maja Pantic,jean.kossaifi@gmail.com;bulat.adrian@gmail.com;yorgos.tzimiropoulos@nottingham.ac.uk;maja.pantic@gmail.com,4;3;4,4;4;5,Withdrawn,0,4,,yes,9/27/18,Imperial College London;Samsung;The University of Nottingham;Imperial College London,72;-1;228;72,8;-1;146;8,2
2019,Associate Normalization,Song-Hao Jia;Ding-Jie Chen;Hwann-Tzong Chen,gasoonjia@icloud.com;djchen.tw@gmail.com;htchen@cs.nthu.edu.tw,3;5;2,5;4;5,Withdrawn,0,0,,yes,9/27/18,National Tsing Hua University;Academia Sinica;National Tsing Hua University,199;-1;199,323;-1;323,1
2019,Online abstraction with MDP homomorphisms for Deep Learning,Ondrej Biza;Robert Platt,bizaondr@fit.cvut.cz;rplatt@ccs.neu.edu,4;5,3;3,Withdrawn,0,0,,yes,9/27/18,Czech Technical University in Prague;Northeastern University,314;16,740;839,
2019,Generalized Label Propagation Methods for Semi-Supervised Learning,Qimai Li;Xiao-Ming Wu;Zhichao Guan.,csqmli@comp.polyu.edu.hk;xiao-ming.wu@polyu.edu.hk;zcguan@zju.edu.cn,4;3;6,4;4;5,Withdrawn,2,3,,yes,9/27/18,The Hong Kong Polytechnic University;The Hong Kong Polytechnic University;Zhejiang University,-1;-1;57,-1;-1;177,1
2019,Rethinking Knowledge Graph Propagation for Zero-Shot Learning,Michael Kampffmeyer;Yinbo Chen;Xiaodan Liang;Hao Wang;Yujia Zhang;Eric P. Xing,michael.c.kampffmeyer@uit.no;cyvius96@gmail.com;xdliang328@gmail.com;hwang87@mit.edu;zhangyujia2014@ia.ac.cn;epxing@cs.cmu.edu,7;5;5,4;3;4,Withdrawn,0,3,,yes,9/27/18,"UiT The Arctic University of Norway;Tsinghua University;SUN YAT-SEN UNIVERSITY;Massachusetts Institute of Technology;Institute of automation, Chinese academy of science, Chinese Academy of Sciences;Carnegie Mellon University",-1;8;478;2;62;1,-1;30;352;5;1103;24,
2019,A Unified View of Deep Metric Learning via Gradient Analysis,Xun Wang;Xintong Han;Weilin Huang;Dengke Dong;Matthew R. Scott,xunwang@malong.com;xinhan@malong.com;whuang@malong.com,3;6;5,4;4;4,Withdrawn,2,3,,yes,9/27/18,Malong Technologies;Malong Technologies;Malong Technologies,-1;-1;-1,-1;-1;-1,
2019,Learning Spatio-Temporal Representations Using Spike-Based Backpropagation,Deboleena Roy;Priyadarshini Panda;Kaushik Roy,roy77@purdue.edu;pandap@purdue.edu;kaushik@purdue.edu,3;4;3,5;5;4,Withdrawn,0,0,,yes,9/27/18,Purdue University;Purdue University;Purdue University,26;26;26,60;60;60,5;5
2019,withdrawn,withdrawn,aaron.chadha.14@ucl.ac.uk;i.andreopoulos@ucl.ac.uk,4;4;3,5;4;5,Withdrawn,0,0,,yes,9/27/18,University College London;University College London,50;50,16;16,
2019,Cosine similarity-based Adversarial process,Hee-Soo Heo;Hye-Jin Shim;Jee-Weon Jung;IL-Ho Yang;Sung-Hyun Yoon;Ha-Jin Yu,zhasgone@naver.com;shimhyejin930615@gmail.com;aberforth19@naver.com;heisco@hanmail.net;ysh901108@naver.com;hjyu@uos.ac.kr,4;3;5,3;5;4,Withdrawn,0,0,,yes,9/27/18,"School of Computer Science, University of Seoul;;Naver;;Naver;School of Computer Science, University of Seoul",-1;140;-1;140;-1;-1,-1;3;-1;3;-1;-1,4
2019,Low-Cost Parameterizations of Deep Convolutional Neural Networks,Eran Treister;Lars Ruthotto;Michal Sharoni;Sapir Zafrani;Eldad Haber,erant@bgu.ac.il;lruthotto@emory.edu;sharmic@post.bgu.ac.il;sapirza@post.bgu.ac.il;ehaber@eos.ubc.ca,4;4;5,3;4;5,Withdrawn,0,0,,yes,9/27/18,Ben Gurion University of the Negev;Emory University;Ben Gurion University of the Negev;Ben Gurion University of the Negev;University of British Columbia,-1;65;-1;-1;36,-1;50;-1;-1;34,
2019,Engaging Image Captioning Via Personality,Kurt Shuster;Samuel Humeau;Hexiang Hu;Antoine Bordes;Jason Weston,kshuster@fb.com;samuelhumeau@fb.com;hexianghu@fb.com;abordes@fb.com;jaseweston@gmail.com,5;5;5,5;5;5,Withdrawn,0,1,,yes,9/27/18,Facebook;Facebook;Facebook;Facebook;,-1;-1;-1;-1;140,-1;-1;-1;-1;3,
2019,Spectral Convolutional Networks on Hierarchical Multigraphs,Boris Knyazev;Xiao Lin;Mohamed R. Amer;Graham W. Taylor,bknyazev@uoguelph.ca;xiao.lin@sri.com;mohamed.amer@sri.com;gwtaylor@uoguelph.ca,4;3;4,4;5;4,Withdrawn,0,0,,yes,9/27/18,University of Guelph;SRI International;SRI International;University of Guelph,261;-1;-1;261,1103;-1;-1;1103,
2019,,,youngjoon.yoo@navercorp.com,4;4;6,4;5;5,Withdrawn,0,0,,yes,9/27/18,NAVER,-1,-1,
2019,,Dai Quoc Nguyen;Tu Dinh Nguyen;Dinh Phung,dai.nguyen@monash.edu;tu.dinh.nguyen@monash.edu;dinh.phung@monash.edu,4;5;5,4;3;4,Withdrawn,0,3,,yes,9/27/18,Monash University;Monash University;Monash University,123;123;123,80;80;80,
2019,MCTSBug: Generating Adversarial Text Sequences via Monte Carlo Tree Search and Homoglyph Attack,Ji Gao;Jack Lanchantin;Yanjun Qi,jg6yd@virginia.edu;jjl5sw@virginia.edu;yanjun@virginia.edu,3;4,4;3,Withdrawn,0,1,,yes,9/27/18,University of Virginia;University of Virginia;University of Virginia,65;65;65,113;113;113,4;4
2019,Bamboo: Ball-Shape Data Augmentation Against Adversarial Attacks from All Directions,Huanrui Yang;Jingchi Zhang;Hsin-Pai Cheng;Wenhan Wang;Yiran Chen;Hai Li,huanrui.yang@duke.edu;jingchi.zhang@duke.edu;hc218@duke.edu;wenhanw@microsoft.com;yiran.chen@duke.edu;hai.li@duke.edu,4;3,3;5,Withdrawn,3,0,,yes,9/27/18,Duke University;Duke University;Duke University;Microsoft;Duke University;Duke University,44;44;44;-1;44;44,17;17;17;-1;17;17,1;4;4
2019,Learning Grounded Sentence Representations by Jointly Using Video and Text Information,Patrick Bordes;Eloi Zablocki;Laure Soulier;Benjamin Piwowarski;Patrick Gallinari,patrick.bordes@lip6.fr;eloi.zablocki@gmail.com;laure.soulier@lip6.fr;benjamin.piwowarski@lip6.fr;patrick.gallinari@lip6.fr,4;3;6,4;5;4,Withdrawn,0,1,,yes,9/27/18,LIP6;LIP6;LIP6;LIP6;LIP6,-1;-1;-1;-1;-1,-1;-1;-1;-1;-1,
2019,Isolating effects of age with fair representation learning when assessing dementia,Zining Zhu;Jekaterina Novikova;Frank Rudzicz,zining.zhu@mail.utoronto.ca;jekaterina@winterlightlabs.com;frank@spoclab.com,4;4;5,3;3;4,Withdrawn,0,4,,yes,9/27/18,Toronto University;Winterlight Labs;University of Toronto,18;-1;18,22;-1;22,
2019,Diagnosing Language Inconsistency in Cross-Lingual Word Embeddings,Yoshinari Fujinuma;Jordan Boyd-Graber;Michael J. Paul,yoshinari.fujinuma@colorado.edu;jbg@umiacs.umd.edu;michael.j.paul@colorado.edu,6;4;4,4;4;5,Withdrawn,0,0,,yes,9/27/18,"University of Colorado, Boulder;University of Maryland, College Park;University of Colorado, Boulder",44;12;44,100;69;100,
2019,Bilingual-GAN: Neural Text Generation and Neural Machine Translation as Two Sides of the Same Coin,Ahmad Rashid;Alan Do-Omri;Mehdi Rezagholizadeh;Md. Akmal Haidar;Hamed Sadeghi,ahmadrash@gmail.com;alan.do-omri@mail.mcgill.ca;mehdi.rezagholizadeh@gmail.com;md.akmal.haidar@huawei.com;haamed.sadeghi@gmail.com,3;4;4,5;3;5,Withdrawn,0,0,,yes,9/27/18,Huawei Technologies Ltd.;McGill University;;Huawei Technologies Ltd.;Huawei Technologies Ltd.,-1;85;140;-1;-1,-1;42;3;-1;-1,4;5
2019,"Learning Robust, Transferable Sentence Representations for Text Classification",Wasi Uddin Ahmad;Xueying Bai;Nanyun Peng;Kai-Wei Chang,wasiahmad@cs.ucla.edu;xubai@cs.stonybrook.edu;npeng@isi.edu;kwchang@cs.ucla.edu,4;3;4,4;2;4,Withdrawn,0,2,,yes,9/27/18,"University of California, Los Angeles;State University of New York, Stony Brook;USC/ISI;University of California, Los Angeles",20;41;-1;20,15;258;-1;15,6
2019,,Masoud Faraki;Mahsa Baktashmotlagh;Tom Drummond;Mathieu Salzmann,masoud.faraki@monash.edu;m.baktashmotlagh@qut.edu.au;tom.drummond@monash.edu;mathieu.salzmann@epfl.ch,4;4;3,4;4;5,Withdrawn,2,0,,yes,9/27/18,Monash University;South China University of Technology;Monash University;Swiss Federal Institute of Technology Lausanne,123;478;123;478,80;576;80;38,
2019,Empirical observations on the instability of aligning word vector spaces with GANs,Mareike Hartmann;Yova Kementchedjhieva;Anders Søgaard,hartmann@di.ku.dk;yova@di.ku.dk;soegaard@di.ku.dk,4;6;5,4;3;4,Withdrawn,0,0,,yes,9/27/18,University of Copenhagen;University of Copenhagen;University of Copenhagen,99;99;99,109;109;109,3;4;5;5
2019,Low-Rank Matrix Factorization of LSTM as Effective Model Compression,Genta Indra Winata;Andrea Madotto;Jamin Shin;Elham J. Barezi,giwinata@connect.ust.hk;amadotto@connect.ust.hk;jay.shin@connect.ust.hk;ejs@connect.ust.hk,5;5;4,4;2;4,Withdrawn,2,3,,yes,9/27/18,The Hong Kong University of Science and Technology;The Hong Kong University of Science and Technology;The Hong Kong University of Science and Technology;The Hong Kong University of Science and Technology,39;39;39;39,44;44;44;44,3;3;3
2019,Combining Global Sparse Gradients with Local Gradients,Alham Fikri Aji;Kenneth Heafield,a.fikri@ed.ac.uk;kheafiel@inf.ed.ac.uk,5;5;3,4;3;4,Withdrawn,0,0,,yes,9/27/18,University of Edinburgh;University of Edinburgh,33;33,27;27,1;3
2019,KNOWLEDGE DISTILL VIA LEARNING NEURON MANIFOLD,Zeyi Tao;Qi Xia;Qun Li,ztao@email.wm.edu;qxia01@email.wm.edu;liqun@cs.wm.edu,5;1;3,3;5;4,Withdrawn,0,0,,yes,9/27/18,College of William and Mary;College of William and Mary;College of William and Mary,169;169;169,261;261;261,1
2019,Adversarial Decomposition of Text Representation,Alexey Romanov;Anna Rumshisky;Anna Rogers;David Donahue,jgc128@outlook.com;arum@cs.uml.edu;arogers@cs.uml.edu;david_donahue@student.uml.edu,3;6;4,4;3;3,Withdrawn,0,4,,yes,9/27/18,"University of Massachusetts, Lowell;University of Massachusetts, Lowell;University of Massachusetts, Lowell;University of Massachusetts, Lowell",-1;-1;-1;-1,-1;-1;-1;-1,4;5
2019,How to learn (and how not to learn) multi-hop reasoning with memory networks,Jifan Chen;Greg Durrett,jf_chen@utexas.edu;gdurrett@cs.utexas.edu,3;5;5,5;5;4,Withdrawn,0,0,,yes,9/27/18,"University of Texas, Austin;University of Texas, Austin",22;22,49;49,
2019,Learning to Attend On Essential Terms: An Enhanced Retriever-Reader Model for Open-domain Question Answering,Jianmo Ni;Chenguang Zhu;Weizhu Chen;Julian McAuley,jin018@ucsd.edu;chezhu@microsoft.com;wzchen@microsoft.com;jmcauley@cs.ucsd.edu,4;5;5,4;4;4,Withdrawn,2,0,,yes,9/27/18,"University of California, San Diego;Microsoft;Microsoft;University of California, San Diego",11;-1;-1;11,31;-1;-1;31,1
2019,The Missing Ingredient in Zero-Shot Neural Machine Translation,Naveen Arivazhagan;Ankur Bapna;Orhan Firat;Roee Aharoni;Melvin Johnson;Wolfgang Macherey,naveenariva@gmail.com;ankurbpn@google.com;orhanf@google.com;roee.aharoni@gmail.com;melvinp@google.com;wmach@google.com,5;4;3,5;3;3,Withdrawn,0,6,,yes,9/27/18,Google;Google;Google;Bar Ilan University;Google;Google,-1;-1;-1;95;-1;-1,-1;-1;-1;456;-1;-1,1;3
2019,Iterative Binary Decisions,Stephan Alaniz;Zeynep Akata,s.alaniz@uva.nl;z.akata@uva.nl,4;4;4,4;4;3,Withdrawn,0,1,,yes,9/27/18,University of Amsterdam;University of Amsterdam,169;169,59;59,
2019,What Is in a Translation Unit?  Comparing Character and Subword Representations Beyond Translation,Nadir Durrani;Fahim Dalvi;Hassan Sajjad;Yonatan Belinkov;Preslav Nakov,ndurrani@qf.org.qa;faimaduddin@qf.org.qa;hsajjad@qf.org.qa;belinkov@mit.edu;pnakov@hbku.edu.qa,5;5;5,4;4;3,Withdrawn,0,0,,yes,9/27/18,QCRI;QCRI;QCRI;Massachusetts Institute of Technology;Peking University,199;199;199;2;24,1103;1103;1103;5;27,2;3
2019,Robust Text Classifier on Test-Time Budgets,Md Rizwan Parvez;Tolga Bolukbasi;Kai-Wei Chang;Venkatesh Saligrama,rizwan@cs.ucla.edu;tolgab@bu.edu;kwchang@cs.ucla.edu;srv@bu.edu,4;4;5,4;4;3,Withdrawn,0,0,,yes,9/27/18,"University of California, Los Angeles;Boston University;University of California, Los Angeles;Boston University",20;65;20;65,15;70;15;70,
2019,Hiding Objects from Detectors: Exploring Transferrable Adversarial Patterns,Shangbang Long;Jie Fu;Chris Pal,longlongsb@pku.edu.cn;jie.fu@polymtl.ca;christopher.pal@polymtl.ca,6;4;3,4;4;3,Withdrawn,0,3,,yes,9/27/18,Peking University;Polytechnique Montreal;Polytechnique Montreal,24;386;386,27;108;108,1;4
2019,Unsupervised Latent Tree Induction with Deep Inside-Outside Recursive Auto-Encoders ,Andrew Drozdov;Patrick Verga;Mohit Yadev;Mohit Iyyer;Andrew McCallum,adrozdov@cs.umass.edu;pat@cs.umass.edu;ymohit@cs.umass.edu;miyyer@cs.umass.edu;mccallum@cs.umass.edu,5;6;2,4;3;4,Withdrawn,0,5,,yes,9/27/18,"University of Massachusetts, Amherst;University of Massachusetts, Amherst;University of Massachusetts, Amherst;University of Massachusetts, Amherst;University of Massachusetts, Amherst",30;30;30;30;30,191;191;191;191;191,2;5
2019,Tangent-Normal Adversarial Regularization for Semi-supervised Learning,Bing Yu;Jingfeng Wu;Jinwen Ma;Zhanxing Zhu,byu@pku.edu.cn;pkuwjf@pku.edu.cn;jwma@math.pku.edu.cn;zhanxing.zhu@pku.edu.cn,5;4;7,3;5;4,Withdrawn,0,1,,yes,9/27/18,Peking University;Peking University;Peking University;Peking University,24;24;24;24,27;27;27;27,4
2019,Answer-based Adversarial Training for Generating Clarification Questions,Sudha Rao;Hal Daumé III,raosudha@cs.umd.edu;hal@umiacs.umd.edu,4;4;6,4;5;4,Withdrawn,0,0,,yes,9/27/18,"University of Maryland, College Park;University of Maryland, College Park",12;12,69;69,4;5;5
2019,IncSQL: Training Incremental Text-to-SQL Parsers with Non-Deterministic Oracles,Tianze Shi;Kedar Tatwawadi;Kaushik Chakrabarti;Yi Mao;Oleksandr Polozov;Weizhu Chen,tianze@cs.cornell.edu;kedart@stanford.edu;kaushik@microsoft.com;maoyi@microsoft.com;polozov@microsoft.com;wzchen@microsoft.com,4;6;3,4;3;5,Withdrawn,0,0,,yes,9/27/18,Cornell University;Stanford University;Microsoft;Microsoft;Microsoft;Microsoft,7;4;-1;-1;-1;-1,19;3;-1;-1;-1;-1,1
2019,Mitigating Bias in Natural Language Inference Using Adversarial Learning,Yonatan Belinkov;Adam Poliak;Stuart M. Shieber;Benjamin Van Durme,belinkov@seas.harvard.edu;azpoliak@cs.jhu.edu;shieber@seas.harvard.edu;vandurme@cs.jhu.edu,4;4;8,5;4;4,Withdrawn,0,5,,yes,9/27/18,Harvard University;Johns Hopkins University;Harvard University;Johns Hopkins University,39;72;39;72,6;13;6;13,4
2019,Multi-Modal Generative Adversarial Networks for Diverse Datasets,Matan Ben-Yosef;Daphna Weinshall,matan.benyosef@mail.huji.ac.il;daphna@cs.huji.ac.il,4;6,4;4,Withdrawn,0,0,,yes,9/27/18,Hebrew University of Jerusalem;Hebrew University of Jerusalem,65;65,205;205,4;5;5
2019,Few-Shot Learning by Exploiting Object Relation,Liangqu Long;Wei Wang;Jun Wen;Meihui  Zhang;Qian  Lin,liangqu.long@gmail.com;wangwei@comp.nus.edu.sg;jungel2star@gmail.com;meihui_zhang@bit.edu.cn;linqian@comp.nus.edu.sg,6;4;4,4;4;3,Withdrawn,0,0,,yes,9/27/18,;National University of Singapore;;BIT;National University of Singapore,140;16;140;-1;16,3;22;3;-1;22,6
2019,CrystalGAN: Learning to Discover Crystallographic Structures with Generative Adversarial Networks,Asma Nouira;Nataliya Sokolovska;Jean-Claude Crivello,asma.nouira.91@gmail.com;nataliya.sokolovska@upmc.fr;jccrivello@icmpe.cnrs.fr,3;7;4,4;2;2,Withdrawn,0,0,,yes,9/27/18,";Computer Science Lab  - Pierre and Marie Curie University, Paris, France;CNRS",140;478;-1,3;123;-1,4;5;5
2019,Exploration using Distributional RL and UCB,Borislav Mavrin;Hengshuai Yao;Linglong Kong;ShangtongZhang,mavrin@ualberta.ca;hengshuai.yao@huawei.com;lkong@ualberta.ca;zhangshangtong.cpp@gmail.com,4;4;4,3;5;4,Withdrawn,0,3,,yes,9/27/18,University of Alberta;Huawei Technologies Ltd.;University of Alberta;University of Oxford,99;-1;99;50,119;-1;119;1,
2019,The Body is not a Given: Joint Agent Policy Learning and Morphology Evolution,Dylan Banarse;Yoram Bachrach;Siqi Liu;Chrisantha Fernando;Nicolas Heess;Pushmeet Kohli;Guy Lever;Thore Graepel,dylski@google.com;yorambac@google.com;guylever@google.com;heess@google.com;pushmeet@google.com;liusiqi@google.com;chrisantha@google.com;thore@google.com,4;4;3;4,4;4;4;3,Withdrawn,0,1,,yes,9/27/18,Google;Google;Google;Google;Google;Google;Google;Google,-1;-1;-1;-1;-1;-1;-1;-1,-1;-1;-1;-1;-1;-1;-1;-1,1;5
2019,From Adversarial Training to Generative Adversarial Networks,Xuanqing Liu;Cho-Jui Hsieh,xqliu@cs.ucla.edu;chohsieh@cs.ucla.edu,3;6;4,3;3;4,Withdrawn,0,1,,yes,9/27/18,"University of California, Los Angeles;University of California, Los Angeles",20;20,15;15,1;4;4;5;5
2019,An Efficient Network for Predicting Time-Varying Distributions,Connie Kou;Hwee Kuan Lee;Teck Khim Ng;Jorge Sanz,koukl@comp.nus.edu.sg;leehk@bii.a-star.edu.sg;ngtk@comp.nus.edu.sg;jorges@nus.edu.sg,5;4;5,4;3;4,Withdrawn,0,0,,yes,9/27/18,National University of Singapore;A*STAR;National University of Singapore;National University of Singapore,16;-1;16;16,22;-1;22;22,1
2019,Quantile Regression Reinforcement Learning with State Aligned Vector Rewards,Oliver Richter;Roger Wattenhofer,richtero@ethz.ch;wattenhofer@ethz.ch,4;3;4,4;3;4,Withdrawn,0,8,,yes,9/27/18,Swiss Federal Institute of Technology;Swiss Federal Institute of Technology,10;10,10;10,
2019,Fatty and Skinny: A Joint Training Method of Watermark Encoder and Decoder,Sanghyun Hong;Mahmoud Mohammadi;Noseong Park,shhong@cs.umd.edu;mmoham12@uncc.edu;npark9@gmu.edu,4;4;4,4;4;4,Withdrawn,0,0,,yes,9/27/18,"University of Maryland, College Park;University of North Carolina, Charlotte;George Mason University",12;-1;99,69;-1;336,1;4;4;4;5;5
2019,Transfer Learning via Unsupervised Task Discovery for Visual Question Answering,Hyeonwoo Noh;Taehoon Kim;Jonghwan Mun;Bohyung Han,shgusdngogo@postech.ac.kr;carpedm20@gmail.com;choco1916@postech.ac.kr;bhhan@snu.ac.kr,4;5;8,5;5;5,Withdrawn,0,0,,yes,9/27/18,POSTECH;OpenAI;POSTECH;Seoul National University,123;-1;123;41,137;-1;137;74,
2019,Confidence Calibration in Deep Neural Networks through Stochastic Inferences,Seonguk Seo;Paul Hongsuck Seo;Bohyung Han,seonguk@snu.ac.kr;hsseo@postech.ac.kr;bhhan@snu.ac.kr,5;3;5,4;2;4,Withdrawn,0,0,,yes,9/27/18,Seoul National University;POSTECH;Seoul National University,41;123;41,74;137;74,1
2019,Noise-Tempered Generative Adversarial Networks,Simon Jenni;Paolo Favaro,jenni@inf.unibe.ch;paolo.favaro@inf.unibe.ch,4;5;5,5;4;4,Withdrawn,0,4,,yes,9/27/18,University of Bern;University of Bern,386;386,105;105,1;4;5;5
2019,SpaMHMM: Sparse Mixture of Hidden Markov Models for Graph Connected Entities,Diogo Pernes;Jaime S. Cardoso,dpc@inesctec.pt;jaime.cardoso@inesctec.pt,3;3;3,4;4;4,Withdrawn,0,3,,yes,9/27/18,University of Porto;University of Porto,18;18,22;22,
2019,Self-Binarizing Networks,Fayez Lahoud;Radhakrishna Achanta;Pablo Márquez-Neila;Sabine Süsstrunk,fayez.lahoud@epfl.ch;radhakrishna.achanta@epfl.ch;pablo.marquez@artorg.unibe.ch;sabine.susstrunk@epfl.ch,5;5;5,4;4;4,Withdrawn,4,1,,yes,9/27/18,Swiss Federal Institute of Technology Lausanne;Swiss Federal Institute of Technology Lausanne;University of Bern;Swiss Federal Institute of Technology Lausanne,478;478;386;478,38;38;105;38,
2019,UNSUPERVISED MONOCULAR DEPTH ESTIMATION WITH CLEAR BOUNDARIES,Yihan Hu;Heng Luo;Yifeng Geng,y4hu@eng.ucsd.edu;heng.luo@horizon.ai;yifeng.geng@horizon.ai,4;4;3,3;5;4,Withdrawn,0,0,,yes,9/27/18,"University of California, San Diego;Horizon Robotics;Horizon Robotics",11;-1;-1,31;-1;-1,
2019,Object-Contrastive Networks: Unsupervised Object Representations,Soeren Pirk;Mohi Khansari;Yunfei Bai;Corey Lynch;Pierre Sermanet,pirk@google.com;khansari@google.com;yunfeibai@google.com;coreylynch@google.com;sermanet@google.com,3;3;5,5;5;4,Withdrawn,0,0,,yes,9/27/18,Google;Google;Google;Google;Google,-1;-1;-1;-1;-1,-1;-1;-1;-1;-1,
2019,TFGAN: Improving Conditioning for Text-to-Video Synthesis,Yogesh Balaji;Martin Renqiang Min;Bing Bai;Rama Chellappa;Hans Peter Graf,yogesh@cs.umd.edu;renqiang@nec-labs.com;bbai@nec-labs.com;rama@umiacs.umd.edu;hpg@nec-labs.com,6;3;5,3;5;4,Withdrawn,0,0,,yes,9/27/18,"University of Maryland, College Park;NEC-Labs;NEC-Labs;University of Maryland, College Park;NEC-Labs",12;-1;-1;12;-1,69;-1;-1;69;-1,4;5;5
2019,Learning Graph Decomposition,Jie Song;Bjoern Andres;Michael Black;Otmar Hilliges;Siyu Tang,jsong@inf.ethz.ch;bjoern.andres@de.bosch.com;black@tuebingen.mpg.de;otmar.hilliges@inf.ethz.ch;stang@tuebingen.mpg.de,7;4;5,4;4;4,Withdrawn,0,0,,yes,9/27/18,"Swiss Federal Institute of Technology;Bosch;Max Planck Institute for Intelligent Systems, Max-Planck Institute;Swiss Federal Institute of Technology;Max Planck Institute for Intelligent Systems, Max-Planck Institute",10;-1;-1;10;-1,10;-1;-1;10;-1,2
2019,Logically-Constrained Neural Fitted Q-iteration,Mohammadhosein Hasanbeig;Alessandro Abate;Daniel Kroening,hosein.hasanbeig@cs.ox.ac.uk;aabate@cs.ox.ac.uk;kroening@cs.ox.ac.uk,5;4;5,2;5;4,Withdrawn,0,5,,yes,9/27/18,University of Oxford;University of Oxford;University of Oxford,50;50;50,1;1;1,
2019,Distributed Deep Policy Gradient for Competitive Adversarial Environment,Denis Osipychev;Girish Chowdhary,deniso2@illinois.edu;girishc@illinois.edu,4;4;3,4;3;5,Withdrawn,0,0,,yes,9/27/18,"University of Illinois, Urbana Champaign;University of Illinois, Urbana Champaign",3;3,37;37,
2019,Found by NEMO: Unsupervised Object Detection from Negative Examples and Motion,Rico Jonschkowski,rjon@google.com,5;3;4,4;4;4,Withdrawn,0,1,,yes,9/27/18,Google,-1,-1,2
2019,Visualizing and Discovering Behavioural Weaknesses in Deep Reinforcement Learning,Christian Rupprecht;Cyril Ibrahim;Chris Pal,christian.rupprecht@in.tum.de;cyril.ibrahim@elementai.com;christopher.pal@polymtl.ca,5;5;4,4;4;5,Withdrawn,0,2,,yes,9/27/18,Technical University Munich;Element AI;Polytechnique Montreal,54;-1;386,41;-1;108,5
2019,Estimating Heterogeneous Treatment Effects Using Neural Networks With The Y-Learner,Bradly C. Stadie;Sören R. Künzel;Nikita Vemuri;Jasjeet S. Sekhon,bstadie@berkeley.edu;srk@berkeley.edu;nikitavemuri@berkeley.edu;sekhon@berkeley.edu,5;5;4,3;4;4,Withdrawn,0,0,,yes,9/27/18,University of California Berkeley;University of California Berkeley;University of California Berkeley;University of California Berkeley,5;5;5;5,18;18;18;18,
2019,Generative Model For Material Irradiation Experiments Based On Prior Knowledge And Attention Mechanism,MinCong Luo;Li Liu,luomincong@foxmail.com;1920148271@qq.com,3;3,4;4,Withdrawn,0,0,,yes,9/27/18,Chinese Academy of Sciences;,62;140,1103;3,4;5
2019, Generating Text through Adversarial Training using Skip-Thought Vectors,Afroz Ahamad,afrozsahamad@gmail.com,3;2;2,5;5;5,Withdrawn,0,0,,yes,9/27/18,"BITS Pilani, BITS Pilani",-1,-1,3;4;5;5
2019,Evolving intrinsic motivations for altruistic behavior,Jane X. Wang;Edward Hughes;Chrisantha Fernando;Wojciech M. Czarnecki;Edgar A. Duenez-Guzman;Joel Z. Leibo,wangjane@google.com;edwardhughes@google.com;chrisantha@google.com;lejlot@google.com;duenez@google.com;jzl@google.com,5;6;3,3;2;4,Withdrawn,0,0,,yes,9/27/18,Google;Google;Google;Google;Google;Google,-1;-1;-1;-1;-1;-1,-1;-1;-1;-1;-1;-1,5
2020,RefNet: Automatic Essay Scoring by Pairwise Comparison,Jiaxin Li;Jinan Zhou,jiaxin.li@link.cuhk.edu.hk;jinan.zhou@link.cuhk.edu.hk,1;3;1,I have published in this field for several years.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:I assessed the sensibility of the derivations and theory.;I have read many papers in this area.:I carefully checked the experiments.:I read the paper thoroughly.:N/A;I do not know much about this area.:I carefully checked the experiments.:I read the paper thoroughly.:I assessed the sensibility of the derivations and theory.,Withdrawn,0,0,,yes,9/25/19,The Chinese University of Hong Kong;The Chinese University of Hong Kong,59;59,35;35,1
2020,Topology of deep neural networks,Gregory Naitzat;Andrey Zhitnikov;Lek-Heng Lim,gregn@uchicago.edu;andreyz@technion.ac.il;lekheng@galton.uchicago.edu,1;3;3,I have published in this field for several years.:I carefully checked the experiments.:I read the paper thoroughly.:I carefully checked the derivations and theory.;I have published in this field for several years.:I assessed the sensibility of the experiments.:I read the paper thoroughly.:I assessed the sensibility of the derivations and theory.;I do not know much about this area.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:I assessed the sensibility of the derivations and theory.,Withdrawn,0,0,,yes,9/25/19,University of Chicago;Technion;University of Chicago,48;26;48,9;412;9,
2020,Provable Convergence and Global Optimality  of Generative Adversarial Network,Qi Cai;Zhuoran Yang;Jason D. Lee;Shaolei S. Du;Zhaoran Wang,qicai2022@u.northwestern.edu;zy6@princeton.edu;jasonlee@princeton.edu;ssdu@ias.edu;zhaoranwang@gmail.com,3;3;3,I do not know much about this area.:N/A:I read the paper thoroughly.:I assessed the sensibility of the derivations and theory.;I have read many papers in this area.:N/A:I read the paper at least twice and used my best judgement in assessing the paper.:I did not assess the derivations or theory.;I have read many papers in this area.:N/A:I read the paper thoroughly.:I carefully checked the derivations and theory.,Withdrawn,0,1,,yes,9/25/19,"Northwestern University;Princeton University;Princeton University;Institue for Advanced Study, Princeton;Northwestern University",44;31;31;-1;44,22;6;6;-1;22,1;4;5;5
2020,Improving Irregularly Sampled Time Series Learning with Dense Descriptors of Time,Rafael Teixeira Sousa;Lucas Araújo Pereira;Anderson da Silva Soares,rafaelts777@gmail.com;apereiral@outlook.com;engsoares@gmail.com,1;3;1,I have read many papers in this area.:I assessed the sensibility of the experiments.:I read the paper thoroughly.:I assessed the sensibility of the derivations and theory.;I have published one or two papers in this area.:I carefully checked the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:I carefully checked the derivations and theory.;I have published one or two papers in this area.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:I assessed the sensibility of the derivations and theory.,Withdrawn,0,0,,yes,9/25/19,Universidade Federal de Goiàs;;,-1;-1;-1,-1;-1;-1,1
2020,Understanding and Training Deep Diagonal Circulant Neural Networks,Alexandre Araujo;Benjamin Negrevergne;Yann Chevaleyre;Jamal Atif,alexandre.araujo@dauphine.eu;benjamin.negrevergne@dauphine.psl.eu;yann.chevaleyre@lamsade.dauphine.fr;jamal.atif@lamsade.dauphine.fr,1;3,I have read many papers in this area.:I assessed the sensibility of the experiments.:I made a quick assessment of this paper.:I assessed the sensibility of the derivations and theory.;I have read many papers in this area.:I assessed the sensibility of the experiments.:I read the paper thoroughly.:I carefully checked the derivations and theory.,Withdrawn,0,2,,yes,9/25/19,Univeristé Paris-Dauphine;Univeristé Paris-Dauphine;Univeristé Paris-Dauphine;Univeristé Paris-Dauphine,481;481;481;481,1397;1397;1397;1397,
2020,DP-LSSGD: An Optimization Method to Lift the Utility in Privacy-Preserving ERM,Bao Wang;Quanquan Gu;March Boedihardjo;Farzin Barekat;Stanley J. Osher,wangbaonj@gmail.com;qgu@cs.ucla.edu;march@math.ucla.edu;fbarekat@math.ucla.edu;sjo@math.ucla.edu,3;6;3,I have published in this field for several years.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:I assessed the sensibility of the derivations and theory.;I have published one or two papers in this area.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:I assessed the sensibility of the derivations and theory.;I have published one or two papers in this area.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:I assessed the sensibility of the derivations and theory.,Withdrawn,0,3,,yes,9/25/19,"University of California, Los Angeles;University of California, Los Angeles;University of California, Los Angeles;University of California, Los Angeles;University of California, Los Angeles",20;20;20;20;20,17;17;17;17;17,
2020,On Global Feature Pooling for Fine-grained Visual Categorization,Pei Guo;Connor Anderson;Ryan Farrell,peiguo@cs.byu.edu;thecatalystak@gmail.com;farrell@cs.byu.edu,6;3;1,I have published one or two papers in this area.:I carefully checked the experiments.:I read the paper thoroughly.:N/A;I have published one or two papers in this area.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:N/A;I have read many papers in this area.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:I assessed the sensibility of the derivations and theory.,Withdrawn,2,0,,yes,9/25/19,Brigham Young University;Brigham Young University;Brigham Young University,-1;-1;-1,-1;-1;-1,1
2020,Quantifying Exposure Bias for Neural Language Generation,Tianxing He;Jingzhao Zhang;Zhiming Zhou;James Glass,cloudygoose@csail.mit.edu;jzhzhang@mit.edu;heyohai@apex.sjtu.edu.cn;glass@mit.edu,3;3;3,I have published one or two papers in this area.:I carefully checked the experiments.:I read the paper thoroughly.:I carefully checked the derivations and theory.;I have read many papers in this area.:I carefully checked the experiments.:I read the paper thoroughly.:I assessed the sensibility of the derivations and theory.;I have published one or two papers in this area.:I carefully checked the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:N/A,Withdrawn,0,6,,yes,9/25/19,Massachusetts Institute of Technology;Massachusetts Institute of Technology;Shanghai Jiao Tong University;Massachusetts Institute of Technology,2;2;53;2,5;5;157;5,3
2020,Mix-review: Alleviate Forgetting in the Pretrain-Finetune Framework for Neural Language Generation Models,Tianxing He;Jun Liu;Kyunghyun Cho;Myle Ott;Bing Liu;James Glass;Fuchun Peng,tianxing@mit.edu;junliu@fb.com;kyunghyuncho@fb.com;myleott@fb.com;bingl@fb.com;glass@mit.edu;fuchunpeng@fb.com,3;3;6,I have published in this field for several years.:I carefully checked the experiments.:I read the paper thoroughly.:I carefully checked the derivations and theory.;I have published one or two papers in this area.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:N/A;I have read many papers in this area.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:I assessed the sensibility of the derivations and theory.,Withdrawn,0,3,,yes,9/25/19,Massachusetts Institute of Technology;Facebook;Facebook;Facebook;Facebook;Massachusetts Institute of Technology;Facebook,2;-1;-1;-1;-1;2;-1,5;-1;-1;-1;-1;5;-1,
2020,INVOCMAP: MAPPING METHOD NAMES TO METHOD INVOCATIONS VIA MACHINE LEARNING,Hung Phan;Ali Jannesari,hungphd@iastate.edu;jannesar@iastate.edu,1;1;1,I have published in this field for several years.:I assessed the sensibility of the experiments.:I made a quick assessment of this paper.:N/A;I do not know much about this area.:I assessed the sensibility of the experiments.:I made a quick assessment of this paper.:N/A;I do not know much about this area.:I assessed the sensibility of the experiments.:I made a quick assessment of this paper.:I assessed the sensibility of the derivations and theory.,Withdrawn,0,4,,yes,9/25/19,Iowa State University;Iowa State University,172;172,399;399,3
2020,Fix-Net: pure fixed-point representation of deep neural networks,Lukas Enderich;Fabian Timm;Lars Rosenbaum;Wolfram Burgard,lukas.enderich@de.bosch.com;fabian.timm@de.bosch.com;lars.rosenbaum@de.bosch.com;burgard@informatik.uni-freiburg.de,3;3;3,I have published one or two papers in this area.:I carefully checked the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:I carefully checked the derivations and theory.;I have published one or two papers in this area.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:I assessed the sensibility of the derivations and theory.;I have read many papers in this area.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:N/A,Withdrawn,0,0,,yes,9/25/19,Bosch;Bosch;Bosch;Universität Freiburg,-1;-1;-1;118,-1;-1;-1;85,
2020,Random Partition Relaxation for Training Binary and Ternary Weight Neural Network,Lukas Cavigelli;Luca Benini,cavigelli@iis.ee.ethz.ch;benini@iis.ee.ethz.ch,1;3;1;3,I have published in this field for several years.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:I assessed the sensibility of the derivations and theory.;I have published in this field for several years.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:I assessed the sensibility of the derivations and theory.;I have published one or two papers in this area.:I carefully checked the experiments.:I read the paper thoroughly.:I carefully checked the derivations and theory.;I have published in this field for several years.:I carefully checked the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:I carefully checked the derivations and theory.,Withdrawn,0,1,,yes,9/25/19,Swiss Federal Institute of Technology;Swiss Federal Institute of Technology,10;10,13;13,
2020,Emergent Communication in Networked Multi-Agent Reinforcement Learning,Shubham Gupta;Rishi Hazra;Amebdkar Dukkipati,shubhamg@iisc.ac.in;rishihazra@iisc.ac.in;ambedkar@iisc.ac.in,3;1;3,I do not know much about this area.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:N/A;I have published one or two papers in this area.:I assessed the sensibility of the experiments.:I read the paper thoroughly.:I carefully checked the derivations and theory.;I have read many papers in this area.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:I assessed the sensibility of the derivations and theory.,Withdrawn,0,3,,yes,9/25/19,Indian Institute of Science;Indian Institute of Science;Indian Institute of Science,95;95;95,301;301;301,
2020,Recognizing Plans by Learning Embeddings from Observed Action Distributions,Yantian Zha;Yikang Li;Sriram Gopalakrishnan;Hankz Hankui Zhuo;Baoxin Li;Subbarao Kambhampati,yantian.zha@asu.edu;yikangli@asu.edu;sgopal28@asu.edu;zhuohank@mail.sysu.edu.cn;baoxin.li@asu.edu;rao@asu.edu,1;3;1;3,I do not know much about this area.:I carefully checked the experiments.:I read the paper thoroughly.:I carefully checked the derivations and theory.;I do not know much about this area.:I did not assess the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:I did not assess the derivations or theory.;I do not know much about this area.:I did not assess the experiments.:I made a quick assessment of this paper.:I did not assess the derivations or theory.;I do not know much about this area.:I assessed the sensibility of the experiments.:I read the paper thoroughly.:I assessed the sensibility of the derivations and theory.,Withdrawn,0,5,,yes,9/25/19,Arizona State University;Arizona State University;Arizona State University;SUN YAT-SEN UNIVERSITY;Arizona State University;Arizona State University,95;95;95;481;95;95,155;155;155;299;155;155,
2020,Cancer homogeneity in single cell revealed by Bi-state model and Binary matrix factorization,Changlin Wan;Wennan Chang;Sha Cao;Xiao Wang;Chi Zhang,wan82@purdue.edu;chang534@purdue.edu;shacao@iu.edu;wangxiao@purdue.edu;czhang87@iu.edu,1;1;1,I have published one or two papers in this area.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:I assessed the sensibility of the derivations and theory.;I have published one or two papers in this area.:I assessed the sensibility of the experiments.:I read the paper thoroughly.:I carefully checked the derivations and theory.;I have published in this field for several years.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:I did not assess the derivations or theory.,Withdrawn,0,0,,yes,9/25/19,"Purdue University;Purdue University;Indiana University, Bloomington;Purdue University;Indiana University, Bloomington",27;27;73;27;73,88;88;134;88;134,
2020,Residual EBMs: Does Real vs. Fake Text Discrimination Generalize?,Anton Bakhtin;Sam Gross;Myle Ott;Yuntian Deng;Marc'Aurelio Ranzato;Arthur Szlam,yolo@fb.com;sgross@fb.com;myleott@fb.com;dengyuntian@g.harvard.edu;ranzato@fb.com;aszlam@fb.com,1;3;3;1,I have read many papers in this area.:I assessed the sensibility of the experiments.:I read the paper thoroughly.:I assessed the sensibility of the derivations and theory.;I have published in this field for several years.:I carefully checked the experiments.:I read the paper thoroughly.:N/A;I have read many papers in this area.:I carefully checked the experiments.:I read the paper thoroughly.:N/A;I have published in this field for several years.:I assessed the sensibility of the experiments.:I read the paper thoroughly.:I assessed the sensibility of the derivations and theory.,Withdrawn,0,0,,yes,9/25/19,Facebook;Facebook;Facebook;Harvard University;Facebook;Facebook,-1;-1;-1;39;-1;-1,-1;-1;-1;7;-1;-1,3
2020,EnsembleNet: A novel architecture for Incremental Learning,Suri Bhasker Sri Harsha;Y Kalidas,cs18s506@iittp.ac.in;ykalidas@iittp.ac.in,1;1;1,I have published one or two papers in this area.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:I did not assess the derivations or theory.;I have published in this field for several years.:I carefully checked the experiments.:I read the paper thoroughly.:I carefully checked the derivations and theory.;I have read many papers in this area.:I assessed the sensibility of the experiments.:I read the paper thoroughly.:I carefully checked the derivations and theory.,Withdrawn,0,3,,yes,9/25/19,Indian Institute of Technology Tirupati;Indian Institute of Technology Tirupati,-1;-1,-1;-1,
2020,Dual Sequential Monte Carlo: Tunneling Filtering and Planning in Continuous POMDPs,Yunbo Wang;Bo Liu;Jiajun Wu;Yuke Zhu;Simon Shaolei Du;Li Fei-Fei;Joshua B. Tenenbaum,yunbo.thu@gmail.com;bliu@cs.utexas.edu;jiajunw@stanford.edu;yukez@cs.stanford.edu;ssdu@ias.edu;feifeili@cs.stanford.edu;jbt@mit.edu,1;3;3,I have published one or two papers in this area.:I assessed the sensibility of the experiments.:I read the paper thoroughly.:I assessed the sensibility of the derivations and theory.;I have published one or two papers in this area.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:I assessed the sensibility of the derivations and theory.;I have published in this field for several years.:I carefully checked the experiments.:I read the paper thoroughly.:I carefully checked the derivations and theory.,Withdrawn,0,4,,yes,9/25/19,"Tsinghua University;University of Texas, Austin;Stanford University;Stanford University;Institue for Advanced Study, Princeton;Stanford University;Massachusetts Institute of Technology",8;22;4;4;-1;4;2,23;38;4;4;-1;4;5,4
2020,Fast Bilinear Matrix Normalization via  Rank-1 Update,Tan Yu;Yunfeng Cai;Ping Li,tanyu01@baidu.com;caiyunfeng@baidu.com;liping11@baidu.com,6;3;1,I do not know much about this area.:I assessed the sensibility of the experiments.:I made a quick assessment of this paper.:I did not assess the derivations or theory.;I have read many papers in this area.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:I assessed the sensibility of the derivations and theory.;I have read many papers in this area.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:I assessed the sensibility of the derivations and theory.,Withdrawn,0,7,,yes,9/25/19,Baidu;Baidu;Baidu,-1;-1;-1,-1;-1;-1,1;2
2020,Task-Mediated Representation Learning,Sergei Bugrov;Ron Sun,bugros@rpi.edu;rsun@rpi.edu,1;1;1,I have read many papers in this area.:I carefully checked the experiments.:I read the paper thoroughly.:I carefully checked the derivations and theory.;I have published in this field for several years.:I carefully checked the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:I carefully checked the derivations and theory.;I have read many papers in this area.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:N/A,Withdrawn,0,0,,yes,9/25/19,Rensselaer Polytechnic Institute;Rensselaer Polytechnic Institute,172;172,438;438,5
2020,Universality Theorems for Generative Models,Valentin Khrulkov;Ivan Oseledets,khrulkov.v@gmail.com;i.oseledets@skoltech.ru,3;1;3,I have read many papers in this area.:N/A:I read the paper thoroughly.:I carefully checked the derivations and theory.;I have published in this field for several years.:N/A:I read the paper thoroughly.:I carefully checked the derivations and theory.;I have published one or two papers in this area.:N/A:I read the paper thoroughly.:I carefully checked the derivations and theory.,Withdrawn,0,0,,yes,9/25/19,Skolkovo Institute of Science and Technology;Skolkovo Institute of Science and Technology,-1;-1,-1;-1,1;1;5
2020,Embodied Language Grounding with Implicit 3D Visual Feature Representations,Mihir Prabhudesai;Hsiao-Yu Fish Tung;Syed Ashar Javed;Maximilian Sieb;Adam W. Harley;Katerina Fragkiadaki,mprabhud@cs.cmu.edu;htung@cs.cmu.edu;sajaved@andrew.cmu.edu;aharley@cs.cmu.edu;katef@cs.cmu.edu,3;3;3,I have published in this field for several years.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:N/A;I do not know much about this area.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:I assessed the sensibility of the derivations and theory.;I have read many papers in this area.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:N/A,Withdrawn,0,0,,yes,9/25/19,Carnegie Mellon University;Carnegie Mellon University;Carnegie Mellon University;Carnegie Mellon University;Carnegie Mellon University,1;1;1;1;1,27;27;27;27;27,2
2020,Geometry-Aware Visual Predictive Models of Intuitive Physics,Hsiao-Yu Fish Tung;Zhou Xian;Mihir Prabhudesai;Katerina Fragkiadaki,htung@cs.cmu.edu;zhouxian@cmu.edu;mprabhud@cs.cmu.edu;katef@cs.cmu.edu,3;6;3,I have published one or two papers in this area.:I assessed the sensibility of the experiments.:I read the paper thoroughly.:N/A;I have read many papers in this area.:I carefully checked the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:I assessed the sensibility of the derivations and theory.;I have published one or two papers in this area.:I carefully checked the experiments.:I read the paper thoroughly.:I carefully checked the derivations and theory.,Withdrawn,0,0,,yes,9/25/19,Carnegie Mellon University;Carnegie Mellon University;Carnegie Mellon University;Carnegie Mellon University,1;1;1;1,27;27;27;27,2
2020,PNEN: Pyramid Non-Local Enhanced Networks,Feida Zhu;Chaowei Fang;Kai-Kuang Ma,feida.zhu@ntu.edu.sg;chwfang@connect.hku.hk;ekkma@ntu.edu.sg,1;1;6,I have read many papers in this area.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:I assessed the sensibility of the derivations and theory.;I have published one or two papers in this area.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:I carefully checked the derivations and theory.;I have read many papers in this area.:I carefully checked the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:I assessed the sensibility of the derivations and theory.,Withdrawn,0,0,,yes,9/25/19,National Taiwan University;The University of Hong Kong;National Taiwan University,86;92;86,120;35;120,1
2020,"Being Bayesian, Even Just a Bit, Fixes Overconfidence in ReLU Networks",Agustinus Kristiadi;Matthias Hein;Philipp Hennig,agustinus.kristiadi@uni-tuebingen.de;matthias.hein@uni-tuebingen.de;philipp.hennig@uni-tuebingen.de,1;1;3,I have published one or two papers in this area.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:I assessed the sensibility of the derivations and theory.;I have read many papers in this area.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:I assessed the sensibility of the derivations and theory.;I have read many papers in this area.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:I assessed the sensibility of the derivations and theory.,Withdrawn,0,1,,yes,9/25/19,University of Tuebingen;University of Tuebingen;University of Tuebingen,154;154;154,91;91;91,1
2020,Auto Network Compression with Cross-Validation Gradient,Nannan Tian;Yong Liu,tiannannan@iie.ac.cn;liuyong@iie.ac.cn,1;3;1,I have published one or two papers in this area.:I assessed the sensibility of the experiments.:I read the paper thoroughly.:I carefully checked the derivations and theory.;I have read many papers in this area.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:I assessed the sensibility of the derivations and theory.;I have published in this field for several years.:I assessed the sensibility of the experiments.:I read the paper thoroughly.:I carefully checked the derivations and theory.,Withdrawn,0,1,,yes,9/25/19,"Institute of information engineering, CAS;Institute of information engineering, CAS",-1;-1,-1;-1,1
2020,Feature-based Augmentation for Semi-Supervised Learning,Min-Hye Oh;Byung-Gook Park,listogato3@gmail.com;bgpark@snu.ac.kr,3;1;6,I have published one or two papers in this area.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:I assessed the sensibility of the derivations and theory.;I have published in this field for several years.:I carefully checked the experiments.:I read the paper thoroughly.:I carefully checked the derivations and theory.;I have published one or two papers in this area.:I assessed the sensibility of the experiments.:I read the paper thoroughly.:I carefully checked the derivations and theory.,Withdrawn,0,0,,yes,9/25/19,;Seoul National University,-1;41,-1;64,
2020,Capsule Networks without Routing Procedures,Zhenhua Chen;Xiwen Li;Chuhua Wang;David Crandall,chen478@iu.edu;xiwenli@wustl.edu;cw234@iu.edu;djcran@indiana.edu,1;3;3,I have published in this field for several years.:I carefully checked the experiments.:I read the paper thoroughly.:I carefully checked the derivations and theory.;I have read many papers in this area.:I assessed the sensibility of the experiments.:I read the paper thoroughly.:I assessed the sensibility of the derivations and theory.;I do not know much about this area.:I carefully checked the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:N/A,Withdrawn,6,3,,yes,9/25/19,"Indiana University, Bloomington;Washington University, St. Louis;Indiana University, Bloomington;University of Arizona",73;100;73;172,134;52;134;103,1;4
2020,Noisy $\ell^{0}$-Sparse Subspace Clustering on Dimensionality Reduced Data,Yingzhen Yang,superyyzg@gmail.com,3;6;3,I have read many papers in this area.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:I assessed the sensibility of the derivations and theory.;I have published in this field for several years.:I assessed the sensibility of the experiments.:I read the paper thoroughly.:I assessed the sensibility of the derivations and theory.;I do not know much about this area.:I assessed the sensibility of the experiments.:I made a quick assessment of this paper.:I did not assess the derivations or theory.,Withdrawn,0,0,,yes,9/25/19,Independent Researcher,-1,-1,1
2020,Side-Tuning: Network Adaptation via Additive Side Networks,Alexander Sax;Jeffrey Zhang;Amir Zamir;Silvio Savarese;Jitendra Malik,sax@berkeley.edu;jozhang@berkeley.edu;zamir@cs.stanford.edu;ssilvio@cs.stanford.edu;malik@eecs.berkeley.edu,3;3;3,I have published in this field for several years.:I carefully checked the experiments.:I read the paper thoroughly.:N/A;I have published one or two papers in this area.:I carefully checked the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:I carefully checked the derivations and theory.;I have published one or two papers in this area.:I carefully checked the experiments.:I read the paper thoroughly.:I carefully checked the derivations and theory.,Withdrawn,0,5,,yes,9/25/19,University of California Berkeley;University of California Berkeley;Stanford University;Stanford University;University of California Berkeley,5;5;4;4;5,13;13;4;4;13,3;6
2020,Deep Multivariate Mixture of Gaussians for Object Detection under Occlusion,Yihui He;Jianren Wang,he2@andrew.cmu.edu;jianrenw@andrew.cmu.edu,1;1;6,I have read many papers in this area.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:I assessed the sensibility of the derivations and theory.;I have published in this field for several years.:I carefully checked the experiments.:I read the paper thoroughly.:I carefully checked the derivations and theory.;I have read many papers in this area.:I carefully checked the experiments.:I read the paper thoroughly.:N/A,Withdrawn,0,0,,yes,9/25/19,Carnegie Mellon University;Carnegie Mellon University,1;1,27;27,1
2020,Dynamic Graph Message Passing Networks,Li Zhang;Dan Xu;Anurag Arnab;Philip H.S. Torr,lz@robots.ox.ac.uk;danxu@robots.ox.ac.uk;anurag.arnab@gmail.com;phst@robots.ox.ac.uk,3;3;3,I have published one or two papers in this area.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:I assessed the sensibility of the derivations and theory.;I have published one or two papers in this area.:I assessed the sensibility of the experiments.:I read the paper thoroughly.:I assessed the sensibility of the derivations and theory.;I have published one or two papers in this area.:I carefully checked the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:N/A,Withdrawn,0,3,,yes,9/25/19,University of Oxford;University of Oxford;Google;University of Oxford,50;50;-1;50,1;1;-1;1,1;2
2020,POLYNOMIAL ACTIVATION FUNCTIONS,Vikas Gottemukkula,vikas11187@gmail.com,3;1;1,I have published one or two papers in this area.:I did not assess the experiments.:I made a quick assessment of this paper.:I assessed the sensibility of the derivations and theory.;I have published one or two papers in this area.:I carefully checked the experiments.:I read the paper thoroughly.:I carefully checked the derivations and theory.;I have published in this field for several years.:I carefully checked the experiments.:I read the paper thoroughly.:I carefully checked the derivations and theory.,Withdrawn,0,0,,yes,9/25/19,Zoloz,-1,-1,
2020,CopyCAT: Taking Control of Neural Policies with Constant Attacks,Léonard Hussenot;Matthieu Geist;Olivier Pietquin,hussenot@google.com;mfgeist@google.com;pietquin@google.com,1;3;3,I have published one or two papers in this area.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:N/A;I have published one or two papers in this area.:I carefully checked the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:I carefully checked the derivations and theory.;I do not know much about this area.:I assessed the sensibility of the experiments.:I made a quick assessment of this paper.:I assessed the sensibility of the derivations and theory.,Withdrawn,0,4,,yes,9/25/19,Google;Google;Google,-1;-1;-1,-1;-1;-1,4;4
2020,Influence-aware Memory for Deep Reinforcement Learning,Miguel Suau;Elena Congeduti;Rolf A.N. Starre;Aleksander Czechowski;Frans A. Oliehoek,m.suaudecastro@tudelft.nl;e.congeduti@tudelft.nl;a.t.czechowski@tudelft.nl;r.a.n.starre@tudelft.nl;f.a.oliehoek@tudelft.nl,1;3;1,I have published one or two papers in this area.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:N/A;I have read many papers in this area.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:I assessed the sensibility of the derivations and theory.;I have published one or two papers in this area.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:I assessed the sensibility of the derivations and theory.,Withdrawn,1,4,,yes,9/25/19,Delft University of Technology;Delft University of Technology;Delft University of Technology;Delft University of Technology;Delft University of Technology,89;89;89;89;89,67;67;67;67;67,
2020,CurricularFace: Adaptive Curriculum Learning Loss for Deep Face Recognition,Yuge Huang;Yuhan Wang;Ying Tai;Xiaoming Liu;Pengcheng Shen;Shaoxin Li;Jilin Li;Feiyue Huang,huangyg@zju.edu.cn;wang_yuhan@zju.edu.cn;yingtai@tencent.com;liuxm@cse.msu.edu;quantshen@tencent.com;darwinli@tencent.com;jerolinli@tencent.com;garyhuang@tencent.com,3;6;3,I have published in this field for several years.:I carefully checked the experiments.:I read the paper thoroughly.:I carefully checked the derivations and theory.;I have read many papers in this area.:I assessed the sensibility of the experiments.:I read the paper thoroughly.:I assessed the sensibility of the derivations and theory.;I do not know much about this area.:I assessed the sensibility of the experiments.:I made a quick assessment of this paper.:N/A,Withdrawn,0,3,,yes,9/25/19,Zhejiang University;Zhejiang University;Tencent AI Lab;SUN YAT-SEN UNIVERSITY;Tencent AI Lab;Tencent AI Lab;Tencent AI Lab;Tencent AI Lab,56;56;-1;481;-1;-1;-1;-1,107;107;-1;299;-1;-1;-1;-1,
2020,Compressive Hyperspherical Energy Minimization,Rongmei Lin;Weiyang Liu;Zhen Liu;Chen Feng;Zhiding Yu;James M. Rehg;Li Xiong;Le Song,rongmei.lin@emory.edu;wyliu@gatech.edu;zhen.liu.2@umontreal.ca;cfeng@nyu.edu;zhidingy@nvidia.com;rehg@gatech.edu;lxiong@emory.edu;lsong@cc.gatech.edu,6;3;3;3,I do not know much about this area.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:I assessed the sensibility of the derivations and theory.;I do not know much about this area.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:I did not assess the derivations or theory.;I have read many papers in this area.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:I assessed the sensibility of the derivations and theory.;I have published in this field for several years.:I assessed the sensibility of the experiments.:I read the paper thoroughly.:I assessed the sensibility of the derivations and theory.,Withdrawn,0,9,,yes,9/25/19,Emory University;Georgia Institute of Technology;University of Montreal;New York University;NVIDIA;Georgia Institute of Technology;Emory University;Georgia Institute of Technology,172;13;128;25;-1;13;172;13,416;38;85;29;-1;38;416;38,1;4
2020,Testing Robustness Against Unforeseen Adversaries,Daniel Kang*;Yi Sun*;Dan Hendrycks;Tom Brown;Jacob Steinhardt,ddkang@stanford.edu;yisun@math.columbia.edu;hendrycks@berkeley.edu;tom@openai.com;jsteinhardt@berkeley.edu,3;3;3,I have published one or two papers in this area.:I carefully checked the experiments.:I read the paper thoroughly.:I carefully checked the derivations and theory.;I have published one or two papers in this area.:I assessed the sensibility of the experiments.:I made a quick assessment of this paper.:N/A;I do not know much about this area.:I assessed the sensibility of the experiments.:I made a quick assessment of this paper.:I assessed the sensibility of the derivations and theory.,Withdrawn,1,4,,yes,9/25/19,Stanford University;Columbia University;University of California Berkeley;OpenAI;University of California Berkeley,4;15;5;-1;5,4;16;13;-1;13,4;4
2020,Reasoning-Aware Graph Convolutional Network for Visual Question Answering,Yangyang Cheng;Chun Yuan,chengyang317@gmail.com;yuanc@sz.tsinghua.edu.cn,3;3;3,I have read many papers in this area.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:I assessed the sensibility of the derivations and theory.;I have published in this field for several years.:I carefully checked the experiments.:I read the paper thoroughly.:I carefully checked the derivations and theory.;I have published one or two papers in this area.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:I carefully checked the derivations and theory.,Withdrawn,0,0,,yes,9/25/19,Tsinghua University;Tsinghua University,8;8,23;23,
2020,Text Embedding Bank Module for Detailed Image Paragraph Caption,Zengming Shen;Arjun Gupta;Thomas S. Huang,zshen5@illinois.edu;arjung2@illinois.edu;t-huang1@illinois.edu,1;1;1,I have published in this field for several years.:I carefully checked the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:I did not assess the derivations or theory.;I have read many papers in this area.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:N/A;I have published in this field for several years.:I carefully checked the experiments.:I read the paper thoroughly.:I carefully checked the derivations and theory.,Withdrawn,0,0,,yes,9/25/19,"University of Illinois, Urbana Champaign;University of Illinois, Urbana Champaign;University of Illinois, Urbana Champaign",3;3;3,48;48;48,3
2020,FNNP: Fast Neural Network Pruning Using Adaptive Batch Normalization,Bailin Li;Bowen Wu;Jiang Su;Guangrun Wang,bl-zorro@163.com;wubw6@mail2.sysu.edu.cn;sujiang@dm-ai.cn;wangguangrun@dm-ai.cn,3;3;1,I have read many papers in this area.:I assessed the sensibility of the experiments.:I read the paper thoroughly.:I carefully checked the derivations and theory.;I do not know much about this area.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:I carefully checked the derivations and theory.;I have read many papers in this area.:I assessed the sensibility of the experiments.:I made a quick assessment of this paper.:N/A,Withdrawn,1,5,,yes,9/25/19,SUN YAT-SEN UNIVERSITY;SUN YAT-SEN UNIVERSITY;DMAI Inc.;DMAI Inc.,481;481;-1;-1,299;299;-1;-1,
2020,Boosting Ticket: Towards Practical Pruning for Adversarial Training with Lottery Ticket Hypothesis,Bai Li;Shiqi Wang;Yunhan Jia;Yantao Lu;Zhenyu Zhong;Lawrence Carin;Suman Jana,bai.li@duke.edu;tcwangshiqi@cs.columbia.edu;jack0082010@gmail.com;ylu25@syr.edu;edwardzhong@baidu.com;lcarin@duke.edu;suman@cs.columbia.edu,3;1;3,I have read many papers in this area.:I assessed the sensibility of the experiments.:I read the paper thoroughly.:N/A;I have published one or two papers in this area.:I assessed the sensibility of the experiments.:N/A:N/A;I have published one or two papers in this area.:I carefully checked the experiments.:I read the paper thoroughly.:I carefully checked the derivations and theory.,Withdrawn,0,0,,yes,9/25/19,Duke University;Columbia University;University of Michigan;Syracuse University;Baidu;Duke University;Columbia University,47;15;8;233;-1;47;15,20;16;21;292;-1;20;16,1;4
2020,Stabilizing Neural ODE Networks with Stochasticity,Xuanqing Liu;Tesi Xiao;Si Si;Qin Cao;Sanjiv Kumar;Cho-Jui Hsieh,xqliu@cs.ucla.edu;texiao@ucdavis.edu;sisidaisy@google.com;qincao@google.com;sanjivk@google.com;chohsieh@cs.ucla.edu,6;1;3,I have read many papers in this area.:I assessed the sensibility of the experiments.:I read the paper thoroughly.:I carefully checked the derivations and theory.;I have read many papers in this area.:I carefully checked the experiments.:I read the paper thoroughly.:I carefully checked the derivations and theory.;I have published in this field for several years.:I carefully checked the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:I assessed the sensibility of the derivations and theory.,Withdrawn,0,0,,yes,9/25/19,"University of California, Los Angeles;University of California, Davis;Google;Google;Google;University of California, Los Angeles",20;79;-1;-1;-1;20,17;55;-1;-1;-1;17,1;4;4
2020,Robustness and/or Redundancy Emerge in Overparametrized Deep Neural Networks,Stephen Casper;Xavier Boix;Vanessa D'Amario;Christopher Rodriguez;Ling Guo;Kasper Vinken;Gabriel Kreiman,scasper@college.harvard.edu;xboix@mit.edu;vanedamario@gmail.com;chrizrodz@gmail.com;kasper.vinken@kuleuven.be;gabriel.kreiman@childrens.harvard.edu,8;1;3,I have published one or two papers in this area.:I carefully checked the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:N/A;I have read many papers in this area.:I assessed the sensibility of the experiments.:N/A:N/A;I have published in this field for several years.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:N/A,Withdrawn,0,0,,yes,9/25/19,Harvard University;Massachusetts Institute of Technology;Università degli Studi di Genova;;KU Leuven;Harvard University,39;2;-1;-1;118;39,7;5;-1;-1;45;7,
2020,Interpretable Deep Neural Network Models: Hybrid of Image Kernels and Neural Networks,Mr. Jay Hoon Jung;and Prof. YoungMin Kwon,jay.jung@stonybrook.edu;youngmin.kwon@sunykorea.ac.kr,1;1;3,I have published one or two papers in this area.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:I carefully checked the derivations and theory.;I have published in this field for several years.:I assessed the sensibility of the experiments.:I read the paper thoroughly.:I assessed the sensibility of the derivations and theory.;I have published one or two papers in this area.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:I assessed the sensibility of the derivations and theory.,Withdrawn,0,0,,yes,9/25/19,"State University of New York, Stony Brook;Korea University",41;323,304;179,
2020,EnsembleNet: End-to-End Optimization of Multi-headed Models,Hanhan Li;Joe Ng;Apostol (Paul) Natsev,mirror.haha@gmail.com;yhng@google.com;natsev@google.com,3;3;1,I have published one or two papers in this area.:I carefully checked the experiments.:I read the paper thoroughly.:I assessed the sensibility of the derivations and theory.;I do not know much about this area.:I assessed the sensibility of the experiments.:I made a quick assessment of this paper.:I carefully checked the derivations and theory.;I have read many papers in this area.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:I assessed the sensibility of the derivations and theory.,Withdrawn,0,6,,yes,9/25/19,Google;Google;Google,-1;-1;-1,-1;-1;-1,
2020,PatchVAE: Learning Local Latent Codes for Recognition,Kamal Gupta;Saurabh Singh;Abhinav Shrivastava,kamalgupta308@gmail.com;saurabhsingh@google.com;abhinav@cs.umd.edu,3;3;3,I have published one or two papers in this area.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:I assessed the sensibility of the derivations and theory.;I have published one or two papers in this area.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:I assessed the sensibility of the derivations and theory.;I have published one or two papers in this area.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:N/A,Withdrawn,0,0,,yes,9/25/19,"University of Maryland, College Park;Google;University of Maryland, College Park",12;-1;12,91;-1;91,5
2020,Improving One-Shot NAS By Suppressing The Posterior Fading,Xiang Li*;Chen Lin*;Chuming Li;Ming Sun;Wei Wu;Junjie Yan;Wanli Ouyang,xiang_li_1@brown.edu;linchen@sensetime.com;lichuming@sensetime.com;sunming1@sensetime.com;wuwei@sensetime.com;yanjunjie@sensetime.com;wanli.ouyang@sydney.edu.au,3;3;3,I do not know much about this area.:I assessed the sensibility of the experiments.:I read the paper thoroughly.:I assessed the sensibility of the derivations and theory.;I do not know much about this area.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:I assessed the sensibility of the derivations and theory.;I have published in this field for several years.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:I assessed the sensibility of the derivations and theory.,Withdrawn,0,3,,yes,9/25/19,Brown University;SenseTime Group Limited;SenseTime Group Limited;SenseTime Group Limited;SenseTime Group Limited;SenseTime Group Limited;University of Sydney,67;-1;-1;-1;-1;-1;86,53;-1;-1;-1;-1;-1;60,1;2;2
2020,Min-max Entropy for Weakly Supervised Pointwise Localization,Belharbi Soufiane;Rony Jérôme;Dolz Jose;Ben Ayed Ismail;McCaffrey Luke;Granger Eric,soufiane.belharbi.1@etsmtl.net;jerome.rony.1@etsmtl.net;jose.dolz@etsmtl.ca;ismail.benayed@etsmtl.ca;luke.mccaffrey@mcgill.ca;eric.granger@etsmtl.ca,3;3;1,I have published one or two papers in this area.:I carefully checked the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:I assessed the sensibility of the derivations and theory.;I have published one or two papers in this area.:I carefully checked the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:I assessed the sensibility of the derivations and theory.;I have published in this field for several years.:I assessed the sensibility of the experiments.:I read the paper thoroughly.:I carefully checked the derivations and theory.,Withdrawn,0,0,,yes,9/25/19,École de technologie supérieure;École de technologie supérieure;École de technologie supérieure;École de technologie supérieure;McGill University;École de technologie supérieure,481;481;481;481;86;481,1397;1397;1397;1397;42;1397,1
2020,Context-Gated Convolution,Xudong Lin;Lin Ma;Wei Liu;Shih-Fu Chang,xudong.lin@columbia.edu;forest.linma@gmail.com;wl2223@columbia.edu;shih.fu.chang@columbia.edu,3;3;3,I have published one or two papers in this area.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:I assessed the sensibility of the derivations and theory.;I have published one or two papers in this area.:I carefully checked the experiments.:I read the paper thoroughly.:N/A;I have published one or two papers in this area.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:N/A,Withdrawn,0,3,,yes,9/25/19,Columbia University;Tencent AI Lab;Columbia University;Columbia University,15;-1;15;15,16;-1;16;16,1;3
2020,FAKE CAN BE REAL IN GANS,Song Tao;Jia Wang,taosong@sjtu.edu.cn;jiawang@sjtu.edu.cn,1;3;8,I have published one or two papers in this area.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:I assessed the sensibility of the derivations and theory.;I have published in this field for several years.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:I assessed the sensibility of the derivations and theory.;I do not know much about this area.:I assessed the sensibility of the experiments.:I made a quick assessment of this paper.:I did not assess the derivations or theory.,Withdrawn,0,4,,yes,9/25/19,Shanghai Jiao Tong University;Shanghai Jiao Tong University,53;53,157;157,1;4;5;5
2020,WHAT ILLNESS OF LANDSCAPE CAN OVER-PARAMETERIZATION ALONE CURE?,Dawei Li;Tian Ding;Ruoyu Sun,dawei2@illinois.edu;dt016@ie.cuhk.edu.hk;ruoyus@illinois.edu,3;3;1,I have read many papers in this area.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:I assessed the sensibility of the derivations and theory.;I have read many papers in this area.:N/A:I made a quick assessment of this paper.:I assessed the sensibility of the derivations and theory.;I have published in this field for several years.:N/A:I read the paper at least twice and used my best judgement in assessing the paper.:I assessed the sensibility of the derivations and theory.,Withdrawn,0,9,,yes,9/25/19,"University of Illinois, Urbana Champaign;The Chinese University of Hong Kong;University of Illinois, Urbana Champaign",3;59;3,48;35;48,1
2020,Representational Disentanglement for Multi-Domain Image Completion,Liyue Shen;Wentao Zhu;Xiaosong Wang;Lei Xing;John Pauly;Baris Turkbey;Stephanie Harmon;Thomas Sanford;Sherif Mehralivand;Peter L. Choyke;Bradford J. Wood;Daguang Xu,liyues@stanford.edu;wentaoz@nvidia.com;xiaosongw@nvidia.com;lei@stanford.edu;pauly@stanford.edu;ismail.turkbey@nih.gov;stephanie.harmon@nih.gov;thomas.sanford@nih.gov;sherif.mehralivand@nih.gov;pchoyke@mail.nih.gov;bwood@nih.gov;daguangx@nvidia.com,3;3;3,I have published one or two papers in this area.:I carefully checked the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:I assessed the sensibility of the derivations and theory.;I have published in this field for several years.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:I assessed the sensibility of the derivations and theory.;I have published in this field for several years.:I assessed the sensibility of the experiments.:I read the paper thoroughly.:I carefully checked the derivations and theory.,Withdrawn,0,3,,yes,9/25/19,Stanford University;NVIDIA;NVIDIA;Stanford University;Stanford University;National Institutes of Health;National Institutes of Health;National Institutes of Health;National Institutes of Health;National Institutes of Health;National Institutes of Health;NVIDIA,4;-1;-1;4;4;-1;-1;-1;-1;-1;-1;-1,4;-1;-1;4;4;-1;-1;-1;-1;-1;-1;-1,1;2;4;5;5
2020,SCL: Towards Accurate Domain Adaptive Object Detection via Gradient Detach Based Stacked Complementary Losses,Zhiqiang Shen;Harsh Maheshwari;Weichen Yao;Marios Savvides,zhiqians@andrew.cmu.edu;harshmaheshwari135@gmail.com;wyao2@andrew.cmu.edu;marioss@andrew.cmu.edu,3;3;3,I have published in this field for several years.:I carefully checked the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:I carefully checked the derivations and theory.;I have published in this field for several years.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:N/A;I have published in this field for several years.:I assessed the sensibility of the experiments.:I made a quick assessment of this paper.:I assessed the sensibility of the derivations and theory.,Withdrawn,1,5,,yes,9/25/19,Carnegie Mellon University;Indian Institute of Technology Kharagpur;Carnegie Mellon University;Carnegie Mellon University,1;266;1;1,27;476;27;27,2
2020,Relevant-features based Auxiliary Cells for Robust and Energy Efficient Deep Learning,Aparna Aketi;Priyadarshini Panda;Kaushik Roy,saketi@purdue.edu;priya.panda@yale.edu;kaushik@purdue.edu,1;3;6,I have published in this field for several years.:I carefully checked the experiments.:I made a quick assessment of this paper.:N/A;I have published one or two papers in this area.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:I assessed the sensibility of the derivations and theory.;I have read many papers in this area.:I carefully checked the experiments.:I read the paper thoroughly.:I assessed the sensibility of the derivations and theory.,Withdrawn,0,5,,yes,9/25/19,Purdue University;Yale University;Purdue University,27;64;27,88;8;88,
2020,Learning to Transfer Learn,Linchao Zhu;Sercan O. Arik;Yi Yang;Tomas Pfister,zhulinchao7@gmail.com;soarik@google.com;yi.yang@uts.edu.au;tpfister@google.com,3;3,I have published in this field for several years.:I carefully checked the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:I carefully checked the derivations and theory.;I have published one or two papers in this area.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:I assessed the sensibility of the derivations and theory.,Withdrawn,0,4,,yes,9/25/19,University of Technology Sydney;Google;University of Technology Sydney;Google,108;-1;108;-1,193;-1;193;-1,1;6
2020,Variational lower bounds on mutual information based on nonextensive statistical mechanics,Valeriu Balaban;Yang Zikun;Paul Bogdan,vbalaban@usc.edu;yangzikun@buaa.edu.cn;pbogdan@usc.edu,3;1;3,I have read many papers in this area.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:I assessed the sensibility of the derivations and theory.;I have read many papers in this area.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:I carefully checked the derivations and theory.;I have read many papers in this area.:I carefully checked the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:I carefully checked the derivations and theory.,Withdrawn,0,0,,yes,9/25/19,University of Southern California;Beihang University;University of Southern California,31;118;31,62;594;62,
2020,Instance adaptive adversarial training: Improved accuracy tradeoffs in neural nets,Yogesh Balaji;Tom Goldstein;Judy Hoffman,yogesh@cs.umd.edu;tomg@cs.umd.edu;judy@gatech.edu,3;6;3,I have read many papers in this area.:I carefully checked the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:N/A;I have read many papers in this area.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:N/A;I have published in this field for several years.:I carefully checked the experiments.:I read the paper thoroughly.:N/A,Withdrawn,0,5,,yes,9/25/19,"University of Maryland, College Park;University of Maryland, College Park;Georgia Institute of Technology",12;12;13,91;91;38,1;4;4
2020,Robust Few-Shot Learning with Adversarially Queried Meta-Learners,Micah Goldblum;Liam Fowl;Tom Goldstein,goldblumcello@gmail.com;lhfowl@gmail.com;tomg@cs.umd.edu,3;6;3,I have published one or two papers in this area.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:N/A;I have published one or two papers in this area.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:I assessed the sensibility of the derivations and theory.;I have published one or two papers in this area.:I carefully checked the experiments.:I read the paper thoroughly.:I carefully checked the derivations and theory.,Withdrawn,0,4,,yes,9/25/19,"University of Maryland, College Park;University of Maryland, College Park;University of Maryland, College Park",12;12;12,91;91;91,4;6;6
2020,Mixture Density Networks Find Viewpoint the Dominant Factor for Accurate Spatial Offset Regression,Ali Varamesh;Tinne Tuytelaars,ali.varamesh@kuleuven.be;tinne.tuytelaars@esat.kuleuven.be,3;1;3,I do not know much about this area.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:N/A;I do not know much about this area.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:I assessed the sensibility of the derivations and theory.;I have published in this field for several years.:I carefully checked the experiments.:I read the paper thoroughly.:I carefully checked the derivations and theory.,Withdrawn,0,3,,yes,9/25/19,KU Leuven;KU Leuven,118;118,45;45,1;2;2;2
2020,Learning Adversarial Grammars for Future Prediction,AJ Piergiovanni;Alexander Toshev;Anelia Angelova;Michael Ryoo,ajpiergi@indiana.edu;toshev@google.com;anelia@google.com;mryoo@google.com,1;1,I have published one or two papers in this area.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:N/A;I have read many papers in this area.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:I assessed the sensibility of the derivations and theory.,Withdrawn,0,2,,yes,9/25/19,University of Arizona;Google;Google;Google,172;-1;-1;-1,103;-1;-1;-1,4
2020,Dual-Component Deep Domain Adaptation: A New Approach for Cross Project Software Vulnerability Detection,Van Nguyen;Trung Le;Olivier de Vel;Paul Montague;John C Grundy;Dinh Phung,van.nk@monash.edu;trunglm@monash.edu;olivier.devel@dst.defence.gov.au;paul.montague@dst.defence.gov.au;john.grundy@monash.edu;dinh.phung@monash.edu,1;6;3,I do not know much about this area.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:N/A;I have read many papers in this area.:I carefully checked the experiments.:I read the paper thoroughly.:I assessed the sensibility of the derivations and theory.;I have read many papers in this area.:I carefully checked the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:I assessed the sensibility of the derivations and theory.,Withdrawn,0,0,,yes,9/25/19,Monash University;Monash University;;;Monash University;Monash University,118;118;-1;-1;118;118,75;75;-1;-1;75;75,4;5;5;6
2020,FAN: Focused Attention Networks,Chu Wang;Babak Samari;Vladimir Kim;Siddhartha Chaudhuri;Kaleem Siddiqi,chuwang@cim.mcgill.ca;babak@cim.mcgill.ca;vokim@adobe.com;sidch@adobe.com;siddiqi@cim.mcgill.ca,3;3;3,I have published one or two papers in this area.:I carefully checked the experiments.:I read the paper thoroughly.:I carefully checked the derivations and theory.;I have published in this field for several years.:I assessed the sensibility of the experiments.:I read the paper thoroughly.:I carefully checked the derivations and theory.;I do not know much about this area.:I assessed the sensibility of the experiments.:I read the paper thoroughly.:N/A,Withdrawn,0,8,,yes,9/25/19,McGill University;McGill University;Adobe Systems;Adobe Systems;McGill University,86;86;-1;-1;86,42;42;-1;-1;42,1
2020,State2vec: Off-Policy Successor Feature Approximators,Sephora Madjiheurem;Laura Toni,sephora.madjiheurem.17@ucl.ac.uk;l.toni@ucl.ac.uk,1;1;3,I have published one or two papers in this area.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:I assessed the sensibility of the derivations and theory.;I have published in this field for several years.:I carefully checked the experiments.:N/A:N/A;I have published one or two papers in this area.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:I assessed the sensibility of the derivations and theory.,Withdrawn,0,0,,yes,9/25/19,University College London;University College London,50;50,15;15,
2020,Semi-supervised Autoencoding Projective Dependency Parsing,Xiao Zhang;Dan Goldwasser,zhang923@purdue.edu;dgoldwas@purdue.edu,1;3;6,I have published one or two papers in this area.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:I assessed the sensibility of the derivations and theory.;I have read many papers in this area.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:I assessed the sensibility of the derivations and theory.;I have read many papers in this area.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:I assessed the sensibility of the derivations and theory.,Withdrawn,0,0,,yes,9/25/19,Purdue University;Purdue University,27;27,88;88,5
2020,Progressive Knowledge Distillation For Generative Modeling,Yu-Xiong Wang;Adrien Bardes;Ruslan Salakhutdinov;Martial Hebert,yuxiongw@cs.cmu.edu;adrien.bardes@dbmail.com;rsalakhu@cs.cmu.edu;hebert@ri.cmu.edu,3;3;6,I have read many papers in this area.:I carefully checked the experiments.:I read the paper thoroughly.:I carefully checked the derivations and theory.;I have published one or two papers in this area.:I carefully checked the experiments.:I read the paper thoroughly.:I carefully checked the derivations and theory.;I have published one or two papers in this area.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:N/A,Withdrawn,0,0,,yes,9/25/19,Carnegie Mellon University;Ecole Normale Superieure;Carnegie Mellon University;Carnegie Mellon University,1;100;1;1,27;45;27;27,5;6;6
2020,Lyceum: An efficient and scalable ecosystem for robot learning,Colin X. Summers;Kendall Lowrey;Aravind Rajeswaran;Emanuel Todorov;Siddhartha Srinivasa,colinxs@cs.washington.edu;klowrey@cs.washington.edu;todorov@cs.washington.edu;siddh@cs.washington.edu;aravraj@cs.washington.edu,1;6;3,I have read many papers in this area.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:N/A;I do not know much about this area.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:I assessed the sensibility of the derivations and theory.;I have read many papers in this area.:I carefully checked the experiments.:I read the paper thoroughly.:N/A,Withdrawn,0,1,,yes,9/25/19,University of Washington;University of Washington;University of Washington;University of Washington;University of Washington,6;6;6;6;6,26;26;26;26;26,
2020,Adversarial Attribute Learning by  Exploiting negative correlated attributes,Satoshi Tsutsui;Yanwei Fu;David Crandall,stsutsui@indiana.edu;yanweifu@fudan.edu.cn;djcran@indiana.edu,1;3;3,I have published one or two papers in this area.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:N/A;I have published in this field for several years.:I carefully checked the experiments.:I read the paper thoroughly.:N/A;I have published in this field for several years.:I carefully checked the experiments.:I read the paper thoroughly.:I carefully checked the derivations and theory.,Withdrawn,0,1,,yes,9/25/19,University of Arizona;Fudan University;University of Arizona,172;79;172,103;109;103,1;4
2020,VISUALIZING POINT CLOUD CLASSIFIERS BY MORPHING POINT CLOUDS INTO POTATOES,Ziwen Chen;Wenxuan Wu;Zhongang Qi;Fuxin Li,chenziwe@grinnell.edu;wuwen@oregonstate.edu;qiz@oregonstate.edu;lif@oregonstate.edu,3;3;3;6,I have published in this field for several years.:I carefully checked the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:I assessed the sensibility of the derivations and theory.;I do not know much about this area.:I assessed the sensibility of the experiments.:I made a quick assessment of this paper.:I assessed the sensibility of the derivations and theory.;I have read many papers in this area.:I carefully checked the experiments.:I read the paper thoroughly.:I carefully checked the derivations and theory.;I do not know much about this area.:I carefully checked the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:I assessed the sensibility of the derivations and theory.,Withdrawn,0,4,,yes,9/25/19,Grinnell College;Oregon State University;Oregon State University;Oregon State University,-1;77;77;77,-1;373;373;373,
2020,Learning Multi-Agent Communication Through Structured Attentive Reasoning,Murtaza Rangwala;Ryan Williams,murtazar@vt.edu;rywilli1@vt.edu,3;1;1,I have published one or two papers in this area.:I carefully checked the experiments.:I read the paper thoroughly.:I assessed the sensibility of the derivations and theory.;I have published one or two papers in this area.:I assessed the sensibility of the experiments.:I read the paper thoroughly.:N/A;I have published one or two papers in this area.:I carefully checked the experiments.:I read the paper thoroughly.:I carefully checked the derivations and theory.,Withdrawn,0,3,,yes,9/25/19,Virginia Tech;Virginia Tech,79;79,240;240,1
2020,The Power of  Semantic Similarity based Soft-Labeling for Generalized Zero-Shot Learning,Shabnam Daghaghi;Tharun Medini;Anshumali Shrivastava,shabnam.daghaghi@rice.edu;tharun.medini@rice.edu;anshumali@rice.edu,6;1;3;3;3,I have published in this field for several years.:I carefully checked the experiments.:I read the paper thoroughly.:I carefully checked the derivations and theory.;I have published one or two papers in this area.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:I carefully checked the derivations and theory.;I have read many papers in this area.:I carefully checked the experiments.:I read the paper thoroughly.:N/A;I do not know much about this area.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:N/A;I have published one or two papers in this area.:I carefully checked the experiments.:I read the paper thoroughly.:I assessed the sensibility of the derivations and theory.,Withdrawn,0,5,,yes,9/25/19,Rice University;Rice University;Rice University,84;84;84,105;105;105,
2020,Spline Templated Based Handwriting Generation,Daniel Clothiaux;Ravi Starzl,dclothia@andrew.cmu.edu;rstarzl@cs.cmu.edu,6;3;1,I do not know much about this area.:I carefully checked the experiments.:I made a quick assessment of this paper.:I assessed the sensibility of the derivations and theory.;I do not know much about this area.:I carefully checked the experiments.:I read the paper thoroughly.:I assessed the sensibility of the derivations and theory.;I have read many papers in this area.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:I carefully checked the derivations and theory.,Withdrawn,0,3,,yes,9/25/19,Carnegie Mellon University;Carnegie Mellon University,1;1,27;27,
2020,Improving the robustness of ImageNet classifiers using elements of human visual cognition,Emin Orhan;Brenden Lake,aeminorhan@gmail.com;brenden@nyu.edu,3;1;3,I have read many papers in this area.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:I assessed the sensibility of the derivations and theory.;I have read many papers in this area.:I assessed the sensibility of the experiments.:I read the paper thoroughly.:N/A;I have read many papers in this area.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:I assessed the sensibility of the derivations and theory.,Withdrawn,0,3,,yes,9/25/19,New York University;New York University,25;25,29;29,1;4
2020,Going Deeper with Lean Point Networks,Eric-Tuan Le;Iasonas Kokkinos;Niloy J. Mitra,eric-tuan.le.18@ucl.ac.uk;i.kokkinos@cs.ucl.ac.uk;n.mitra@cs.ucl.ac.uk,1;6;3,I have published in this field for several years.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:N/A;I do not know much about this area.:I carefully checked the experiments.:I read the paper thoroughly.:N/A;I have read many papers in this area.:I assessed the sensibility of the experiments.:I made a quick assessment of this paper.:I assessed the sensibility of the derivations and theory.,Withdrawn,0,3,,yes,9/25/19,University College London;University College London;University College London,50;50;50,15;15;15,1;2
2020,Newton Residual Learning,Grigorios Chrysos;Jiankang Deng;Yannis Panagakis;Stefanos Zafeiriou,g.chrysos@imperial.ac.uk;j.deng16@imperial.ac.uk;i.panagakis@imperial.ac.uk;s.zafeiriou@imperial.ac.uk,8;1;3,I have read many papers in this area.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:I assessed the sensibility of the derivations and theory.;I have published one or two papers in this area.:I assessed the sensibility of the experiments.:I read the paper thoroughly.:I carefully checked the derivations and theory.;I have published in this field for several years.:I assessed the sensibility of the experiments.:I read the paper thoroughly.:I assessed the sensibility of the derivations and theory.,Withdrawn,1,1,,yes,9/25/19,Imperial College London;Imperial College London;Imperial College London;Imperial College London,73;73;73;73,10;10;10;10,2
2020,Training-Free Uncertainty Estimation for Neural Networks,Lu Mi;Hao Wang;Yonglong Tian;Nir Shavit,lumi@mit.edu;hoguewang@gmail.com;yonglong@mit.edu;shanir@csail.mit.edu,1;6;6;1,I have published in this field for several years.:I carefully checked the experiments.:I read the paper thoroughly.:I carefully checked the derivations and theory.;I have read many papers in this area.:I carefully checked the experiments.:I read the paper thoroughly.:I carefully checked the derivations and theory.;I do not know much about this area.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:N/A;I have published one or two papers in this area.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:N/A,Withdrawn,0,5,,yes,9/25/19,Massachusetts Institute of Technology;Massachusetts Institute of Technology;Massachusetts Institute of Technology;Massachusetts Institute of Technology,2;2;2;2,5;5;5;5,1;2
2020,AMUSED: A Multi-Stream Vector Representation Method for Use In Natural Dialogue,Gaurav Kumar;Rishabh Joshi;Jaspreet Singh;Promod Yenigalla,gaurav.k1@samsung.com;rjoshi2@andrew.cmu.edu;jaspreet.ahluwalia@stonybrook.edu;promod.y@samsung.com,6;1;3,I have read many papers in this area.:I carefully checked the experiments.:I read the paper thoroughly.:I carefully checked the derivations and theory.;I have published in this field for several years.:I carefully checked the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:I assessed the sensibility of the derivations and theory.;I have published one or two papers in this area.:I assessed the sensibility of the experiments.:N/A:N/A,Withdrawn,0,3,,yes,9/25/19,"Samsung;Carnegie Mellon University;State University of New York, Stony Brook;Samsung",-1;1;41;-1,-1;27;304;-1,1;6
2020,PAD-Nets: Learning Dynamic Receptive Fields via Pixel-Wise Adaptive Dilation,Dongdong Wang;Hao Hu;Jie Yao;Zihang Zou;Liqiang Wang,daniel.wang@knights.ucf.edu;hhu@fxpal.com;17112098@bjtu.edu.cn;zzz@knights.ucf.edu;lwang@cs.ucf.edu,1;3;3,I have published one or two papers in this area.:I assessed the sensibility of the experiments.:I read the paper thoroughly.:I assessed the sensibility of the derivations and theory.;I have published one or two papers in this area.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:I assessed the sensibility of the derivations and theory.;I have published in this field for several years.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:I assessed the sensibility of the derivations and theory.,Withdrawn,0,0,,yes,9/25/19,"University of Central Florida;FX Palo Alto Laboratory, Inc.;Beijing jiaotong univercity;University of Central Florida;University of Central Florida",77;-1;481;77;77,609;-1;952;609;609,
2020,Posterior Sampling: Make Reinforcement Learning Sample Efficient Again,Calvin Seward;Urs Bergmann;Roland Vollgraf;Sepp Hochreiter,seward@bioinf.jku.at;urs.bergmann@zalando.de;roland.vollgraf@zalando.de;hochreit@bioinf.jku.at,3;3;6;1,I have published in this field for several years.:I carefully checked the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:I assessed the sensibility of the derivations and theory.;I have published one or two papers in this area.:I assessed the sensibility of the experiments.:I made a quick assessment of this paper.:N/A;I have read many papers in this area.:I assessed the sensibility of the experiments.:I made a quick assessment of this paper.:I did not assess the derivations or theory.;I have published in this field for several years.:I carefully checked the experiments.:I read the paper thoroughly.:I carefully checked the derivations and theory.,Withdrawn,0,4,,yes,9/25/19,Johannes Kepler University Linz;Zalando Research;Zalando Research;Johannes Kepler University Linz,481;-1;-1;481,620;-1;-1;620,
2020,Unifying Part Detection And Association For Multi-person Pose Estimation,Rania Briq;Andreas Doering;Juergen Gall,briq@iai.uni-bonn.de;doering@iai.uni-bonn.de;gall@iai.uni-bonn.de,3;6;3,I have read many papers in this area.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:N/A;I have read many papers in this area.:I carefully checked the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:N/A;I have read many papers in this area.:I carefully checked the experiments.:I read the paper thoroughly.:N/A,Withdrawn,0,0,,yes,9/25/19,University of Bonn;University of Bonn;University of Bonn,128;128;128,106;106;106,2
2020,Slow Thinking Enables Task-Uncertain Lifelong and Sequential Few-Shot Learning,Rosalie Dolor;Hsin-Chi Chu;Shan-Hung Wu,rosalie@ghtinc.com;hcchu@datalab.cs.nthu.edu.tw;shwu@cs.nthu.edu.tw,3;3;3,I have read many papers in this area.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:I assessed the sensibility of the derivations and theory.;I have published one or two papers in this area.:I assessed the sensibility of the experiments.:I read the paper thoroughly.:I assessed the sensibility of the derivations and theory.;I have published one or two papers in this area.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:I assessed the sensibility of the derivations and theory.,Withdrawn,0,0,,yes,9/25/19,Ghtinc;National Tsing Hua University;National Tsing Hua University,-1;172;172,-1;365;365,6
2020,How Aggressive Can Adversarial Attacks Be: Learning Ordered Top-k Attacks,Zekun Zhang;Tianfu Wu,zzhang56@ncsu.edu;tianfu_wu@ncsu.edu,3;3;1,I have published one or two papers in this area.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:I assessed the sensibility of the derivations and theory.;I have published one or two papers in this area.:I assessed the sensibility of the experiments.:N/A:N/A;I have published in this field for several years.:I carefully checked the experiments.:I read the paper thoroughly.:I carefully checked the derivations and theory.,Withdrawn,0,0,,yes,9/25/19,North Carolina State University;North Carolina State University,86;86,310;310,1;4;4
2020,PolyGAN: High-Order Polynomial Generators,Grigorios Chrysos;Stylianos Moschoglou;Yannis Panagakis;Stefanos Zafeiriou,g.chrysos@imperial.ac.uk;s.moschoglou@imperial.ac.uk;i.panagakis@imperial.ac.uk;s.zafeiriou@imperial.ac.uk,1;3;1;1,I have published one or two papers in this area.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:I did not assess the derivations or theory.;I have published in this field for several years.:I carefully checked the experiments.:I read the paper thoroughly.:I carefully checked the derivations and theory.;I have published one or two papers in this area.:I carefully checked the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:I assessed the sensibility of the derivations and theory.;I have read many papers in this area.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:I assessed the sensibility of the derivations and theory.,Withdrawn,0,1,,yes,9/25/19,Imperial College London;Imperial College London;Imperial College London;Imperial College London,73;73;73;73,10;10;10;10,4;5;5
2020,Generative Multi Source Domain Adaptation,Subhankar Roy;Aliaksandr Siarohin;Enver Sangineto;Moin Nabi;Tassilo Klein;Nicu Sebe;Elisa Ricci,subhankar.roy@unitn.it;aliaksandr.siarohin@unitn.it;enver.sangineto@unitn.it;m.nabi@sap.com;tassilo.klein@sap.com;niculae.sebe@unitn.it;eliricci@fbk.eu,3;3;1,I have read many papers in this area.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:I assessed the sensibility of the derivations and theory.;I have published one or two papers in this area.:I carefully checked the experiments.:I read the paper thoroughly.:I assessed the sensibility of the derivations and theory.;I have published in this field for several years.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:I assessed the sensibility of the derivations and theory.,Withdrawn,0,5,,yes,9/25/19,University of Trento;University of Trento;University of Trento;SAP;SAP;University of Trento;Fondazione Bruno Kessler,18;18;18;323;323;18;-1,307;307;307;258;258;307;-1,4;5
2020,Semi-Supervised Named Entity Recognition with CRF-VAEs,Thomas Effland;Michael Collins,teffland@cs.columbia.edu;mcollins@cs.columbia.edu;mc3354@columbia.edu,3;3;1,I have published in this field for several years.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:N/A;I have read many papers in this area.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:I assessed the sensibility of the derivations and theory.;I have published one or two papers in this area.:I assessed the sensibility of the experiments.:I read the paper thoroughly.:I assessed the sensibility of the derivations and theory.,Withdrawn,1,3,,yes,9/25/19,Columbia University;Columbia University;Columbia University,15;15;15,16;16;16,1;5;5
2020,Understanding the (Un)interpretability of Natural Image Distributions Using Generative Models,Ryen Krusinga;Sohil Shah;Matthias Zwicker;Tom Goldstein;David Jacobs,krusinga@cs.umd.edu;sohilas@umd.edu;zwicker@inf.unibe.ch;tom@cs.umd.edu;djacobs@umiacs.umd.edu,1;3;3,I have published one or two papers in this area.:I assessed the sensibility of the experiments.:I read the paper thoroughly.:I carefully checked the derivations and theory.;I have read many papers in this area.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:I assessed the sensibility of the derivations and theory.;I have published in this field for several years.:I assessed the sensibility of the experiments.:I read the paper thoroughly.:I assessed the sensibility of the derivations and theory.,Withdrawn,1,0,,yes,9/25/19,"University of Maryland, College Park;University of Maryland, College Park;University of Bern;University of Maryland, College Park;University of Maryland, College Park",12;12;390;12;12,91;91;113;91;91,5;5
2020,Depth-Recurrent Residual Connections for Super-Resolution of Real-Time Renderings,Erik Franz;Mengyu Chu;Rüdiger Westermann;Nils Thuerey,franzer@in.tum.de;mengyu.chu@tum.de;westermann@tum.de;nils.thuerey@tum.de,3;3;3,I have published one or two papers in this area.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:I assessed the sensibility of the derivations and theory.;I do not know much about this area.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:N/A;I have published in this field for several years.:I carefully checked the experiments.:I read the paper thoroughly.:I carefully checked the derivations and theory.,Withdrawn,0,0,,yes,9/25/19,Technical University Munich;Technical University Munich;Technical University Munich;Technical University Munich,53;53;53;53,43;43;43;43,4;5
2020,The Blessing of Dimensionality: An Empirical Study of Generalization,W. Ronny Huang;Zeyad Emam;Micah Goldblum;Liam Fowl;Justin K. Terry;Furong Huang;Tom Goldstein,wrhuang@umd.edu;zeyad@math.umd.edu;goldblum@math.umd.edu;lfowl@math.umd.edu;jkterry@cs.umd.edu;furongh@cs.umd.edu;tomg@cs.umd.edu,3;1;3,I have published one or two papers in this area.:I carefully checked the experiments.:I read the paper thoroughly.:I carefully checked the derivations and theory.;I have published one or two papers in this area.:I carefully checked the experiments.:I read the paper thoroughly.:I carefully checked the derivations and theory.;I do not know much about this area.:I carefully checked the experiments.:I read the paper thoroughly.:I assessed the sensibility of the derivations and theory.,Withdrawn,0,0,,yes,9/25/19,"University of Maryland, College Park;University of Maryland, College Park;University of Maryland, College Park;University of Maryland, College Park;University of Maryland, College Park;University of Maryland, College Park;University of Maryland, College Park",12;12;12;12;12;12;12,91;91;91;91;91;91;91,
2020,Strong Baseline Defenses Against Clean-Label Poisoning Attacks,Neal Gupta;W. Ronny Huang;Liam Fowl;Chen Zhu;Soheil Feizi;Tom Goldstein;John Dickerson,ngupta@cs.umd.edu;wronnyhuang@gmail.com;lhfowl@gmail.com;chenzhu@cs.umd.edu;sfeizi@cs.umd.edu;tomg@cs.umd.edu;john@cs.umd.edu,3;3;1,I have published in this field for several years.:I carefully checked the experiments.:I read the paper thoroughly.:I carefully checked the derivations and theory.;I have published in this field for several years.:I assessed the sensibility of the experiments.:I read the paper thoroughly.:I assessed the sensibility of the derivations and theory.;I have read many papers in this area.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:I assessed the sensibility of the derivations and theory.,Withdrawn,0,3,,yes,9/25/19,"University of Maryland, College Park;University of Maryland, College Park;University of Maryland, College Park;University of Maryland, College Park;University of Maryland, College Park;University of Maryland, College Park;University of Maryland, College Park",12;12;12;12;12;12;12,91;91;91;91;91;91;91,4;4;4
2020,MetaPoison:   Learning to craft adversarial poisoning examples via meta-learning,W. Ronny Huang;Jonas Geiping;Liam Fowl;Gavin Taylor;Tom Goldstein,wronnyhuang@gmail.com;jonas.geiping@uni-siegen.de;lfowl@math.umd.edu;taylor@usna.edu;tomg@cs.umd.edu,3;3;1,I do not know much about this area.:I did not assess the experiments.:I made a quick assessment of this paper.:N/A;I do not know much about this area.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:I assessed the sensibility of the derivations and theory.;I have published one or two papers in this area.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:I assessed the sensibility of the derivations and theory.,Withdrawn,0,3,,yes,9/25/19,"University of Maryland, College Park;University of Siegen;University of Maryland, College Park;University of Arizona;University of Maryland, College Park",12;323;12;172;12,91;570;91;103;91,4;4;6
2020,Domain-Relevant Embeddings for Question Similarity,Clara McCreery;Namit Katariya;Anitha Kannan;Manish Chablani;Xavier Amatriain,mccreery@stanford.edu;namit@curai.com;anitha@curai.com;manish@curai.com;xavier@curai.com,3;3;1,I have published one or two papers in this area.:I carefully checked the experiments.:I read the paper thoroughly.:I carefully checked the derivations and theory.;I have published one or two papers in this area.:I carefully checked the experiments.:I read the paper thoroughly.:I carefully checked the derivations and theory.;I have published in this field for several years.:I assessed the sensibility of the experiments.:I read the paper thoroughly.:N/A,Withdrawn,0,0,,yes,9/25/19,Stanford University;Curai;Curai;Curai;Curai,4;233;233;233;233,4;-1;-1;-1;-1,
2020,Divide-and-Conquer Adversarial Learning for High-Resolution Image Enhancement,Zhiwu Huang;Danda Pani Paudel;Guanju Li;Jiqing Wu;Radu Timofte;Luc Van Gool,zhiwu.huang@vision.ee.ethz.ch;paudel@vision.ee.ethz.ch;ligua@student.ethz.ch;jwu@vision.ee.ethz.ch;radu.timofte@vision.ee.ethz.ch;vangool@vision.ee.ethz.ch,3;3;3,I have read many papers in this area.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:I assessed the sensibility of the derivations and theory.;I have published in this field for several years.:I assessed the sensibility of the experiments.:N/A:I assessed the sensibility of the derivations and theory.;I have read many papers in this area.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:I assessed the sensibility of the derivations and theory.,Withdrawn,0,3,,yes,9/25/19,Swiss Federal Institute of Technology;Swiss Federal Institute of Technology;Swiss Federal Institute of Technology;Swiss Federal Institute of Technology;Swiss Federal Institute of Technology;Swiss Federal Institute of Technology,10;10;10;10;10;10,13;13;13;13;13;13,4;5;5
2020,Learning Out-of-distribution Detection without Out-of-distribution Data,Yen-Chang Hsu;Yilin Shen;Hongxia Jin;Zsolt Kira,yenchang.hsu@gatech.edu;yilin.shen@samsung.com;hongxia.jin@samsung.com;zkira@gatech.edu,3;3;1,I have published in this field for several years.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:I assessed the sensibility of the derivations and theory.;I have published one or two papers in this area.:I carefully checked the experiments.:I read the paper thoroughly.:I carefully checked the derivations and theory.;I have published one or two papers in this area.:I assessed the sensibility of the experiments.:I read the paper thoroughly.:I carefully checked the derivations and theory.,Withdrawn,3,1,,yes,9/25/19,Georgia Institute of Technology;Samsung;Samsung;Georgia Institute of Technology,13;-1;-1;13,38;-1;-1;38,
2020,Domain Adaptation Through Label Propagation: Learning Clustered and Aligned Features,Changhwa Park;Jaeyoon Yoo;Youngjun Hong;Sungroh Yoon,omega6464@snu.ac.kr;yjy765@snu.ac.kr;youngjun.hong@enerzai.com;sryoon@snu.ac.kr,3;3;3,I have published in this field for several years.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:I carefully checked the derivations and theory.;I have published in this field for several years.:I carefully checked the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:I assessed the sensibility of the derivations and theory.;I have published one or two papers in this area.:I assessed the sensibility of the experiments.:I made a quick assessment of this paper.:I assessed the sensibility of the derivations and theory.,Withdrawn,1,10,,yes,9/25/19,Seoul National University;Seoul National University;Enerzai;Seoul National University,41;41;-1;41,64;64;-1;64,1
2020,ManiGAN: Text-Guided Image Manipulation,Bowen Li;Xiaojuan Qi;Thomas Lukasiewicz;Philip H. S. Torr,bowen.li@cs.ox.ac.uk;xiaojuan.qi@eng.ox.ac.uk;thomas.lukasiewicz@cs.ox.ac.uk;philip.torr@eng.ox.ac.uk,1;6;6,I have read many papers in this area.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:N/A;I have read many papers in this area.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:I assessed the sensibility of the derivations and theory.;I have published in this field for several years.:I carefully checked the experiments.:I read the paper thoroughly.:I carefully checked the derivations and theory.,Withdrawn,0,3,,yes,9/25/19,University of Oxford;University of Oxford;University of Oxford;University of Oxford,50;50;50;50,1;1;1;1,4;5;5
2020,Empirical observations pertaining to learned priors for deep latent variable models,Rogan Morrow;Wei-Chen Chiu,rogan.o.morrow@gmail.com;walon@cs.nctu.edu.tw,3;1;3,I have published one or two papers in this area.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:I assessed the sensibility of the derivations and theory.;I have read many papers in this area.:I assessed the sensibility of the experiments.:I made a quick assessment of this paper.:N/A;I have published one or two papers in this area.:I carefully checked the experiments.:I read the paper thoroughly.:I carefully checked the derivations and theory.,Withdrawn,0,4,,yes,9/25/19,National Chiao Tung University;National Chiao Tung University,143;143,564;564,2;4;5
2020,Variational inference of latent hierarchical dynamical systems in neuroscience: an application to calcium imaging data,Luke Y. Prince;Blake A. Richards,luke.prince@utoronto.ca;blake.richards@mcgill.ca,3;3;3,I have read many papers in this area.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:I assessed the sensibility of the derivations and theory.;I have published in this field for several years.:I carefully checked the experiments.:I read the paper thoroughly.:I carefully checked the derivations and theory.;I do not know much about this area.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:I assessed the sensibility of the derivations and theory.,Withdrawn,0,0,,yes,9/25/19,Toronto University;McGill University,18;86,18;42,
2020,Characterizing convolutional neural networks with one-pixel signature,Shanjiaoyang Huang;Weiqi Peng;Zhuowen Tu,shh236@ucsd.edu;wep012@ucsd.edu;ztu@ucsd.edu,3;3;3,I do not know much about this area.:I assessed the sensibility of the experiments.:I made a quick assessment of this paper.:I assessed the sensibility of the derivations and theory.;I have published one or two papers in this area.:I carefully checked the experiments.:I read the paper thoroughly.:I carefully checked the derivations and theory.;I have published in this field for several years.:I carefully checked the experiments.:I read the paper thoroughly.:I carefully checked the derivations and theory.,Withdrawn,0,3,,yes,9/25/19,"University of California, San Diego;University of California, San Diego;University of California, San Diego",11;11;11,31;31;31,4;4
2020,Increasing batch size through instance repetition improves generalization,Elad Hoffer;Tal Ben-Nun;Itay Hubara;Niv Giladi;Torsten Hoefler;Daniel Soudry,elad.hoffer@gmail.com;talbn@inf.ethz.ch;itayhubara@gmail.com;giladiniv@campus.technion.ac.il;htor@inf.ethz.ch;daniel.soudry@gmail.com,3;3;6,I have published one or two papers in this area.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:N/A;I have published one or two papers in this area.:I assessed the sensibility of the experiments.:I read the paper thoroughly.:I assessed the sensibility of the derivations and theory.;I have published one or two papers in this area.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:I assessed the sensibility of the derivations and theory.,Withdrawn,2,3,,yes,9/25/19,Technion;Swiss Federal Institute of Technology;;Technion;Swiss Federal Institute of Technology;Technion,26;10;-1;26;10;26,412;13;-1;412;13;412,1
2020,"Mix & Match: training convnets with mixed image sizes for improved accuracy, speed and scale resiliency",Elad Hoffer;Berry Weinstein;Itay Hubara;Tal Ben-Nun;Torsten Hoefler;Daniel Soudry,elad.hoffer@gmail.com;bweinstein@habana.ai;itayhubara@gmail.com;talbn@inf.ethz.ch;htor@inf.ethz.ch;daniel.soudry@gmail.com,6;3;3,I do not know much about this area.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:N/A;I do not know much about this area.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:N/A;I have read many papers in this area.:I carefully checked the experiments.:I read the paper thoroughly.:N/A,Withdrawn,0,3,,yes,9/25/19,Technion;interdisciplinary center herzliya;;Swiss Federal Institute of Technology;Swiss Federal Institute of Technology;Technion,26;-1;-1;10;10;26,412;-1;-1;13;13;412,1
2020,Revisit Knowledge Distillation: a Teacher-free Framework,Li Yuan;Francis EH Tay;Guilin Li;Tao Wang;Jiashi Feng,ylustcnus@gmail.com;mpetayeh@nus.edu.sg;liguilin2@huawei.com;twangnh@gmail.com;elefjia@nus.edu.sg,6;3;3,I have published one or two papers in this area.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:I assessed the sensibility of the derivations and theory.;I have published one or two papers in this area.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:I carefully checked the derivations and theory.;I have published one or two papers in this area.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:I assessed the sensibility of the derivations and theory.,Withdrawn,0,5,,yes,9/25/19,National University of Singapore;National University of Singapore;Huawei Technologies Ltd.;National University of Singapore;National University of Singapore,16;16;-1;16;16,25;25;-1;25;25,1
2020,On learning visual odometry errors,Andrea De Maio;Simon Lacroix,andrea.de-maio@laas.fr;simon.lacroix@laas.fr,1;3;3,I have read many papers in this area.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:I assessed the sensibility of the derivations and theory.;I have read many papers in this area.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:I assessed the sensibility of the derivations and theory.;I have read many papers in this area.:I carefully checked the experiments.:I read the paper thoroughly.:I assessed the sensibility of the derivations and theory.,Withdrawn,0,4,,yes,9/25/19,LAAS / CNRS;LAAS / CNRS,-1;-1,-1;-1,1
2020,Mitigating Posterior Collapse in Strongly Conditioned Variational Autoencoders,Mohammad Sadegh Aliakbarian;Fatemeh Sadat Saleh;Mathieu Salzmann;Lars Petersson;Stephen Gould,sadegh.aliakbarian@anu.edu.au;fatemehsadat.saleh@anu.edu.au;mathieu.salzmann@epfl.ch;lars.petersson@data61.csiro.au;stephen.gould@anu.edu.au,3;1;1,I have published one or two papers in this area.:I assessed the sensibility of the experiments.:I read the paper thoroughly.:I carefully checked the derivations and theory.;I have published one or two papers in this area.:I carefully checked the experiments.:I read the paper thoroughly.:I carefully checked the derivations and theory.;I have published in this field for several years.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:I assessed the sensibility of the derivations and theory.,Withdrawn,0,4,,yes,9/25/19,"Australian National University;Australian National University;Swiss Federal Institute of Technology Lausanne;, CSIRO;Australian National University",108;108;481;233;108,50;50;38;-1;50,5;5
2020,Unsupervised  Video-to-Video Translation via Self-Supervised Learning,Kangning Liu;Shuhang Gu;Radu Timofte,kl3141@nyu.edu;shuhang.gu@vision.ee.ethz.ch;radu.timofte@vision.ee.ethz.ch,3;3;3,I have read many papers in this area.:I carefully checked the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:N/A;I have published one or two papers in this area.:I assessed the sensibility of the experiments.:I read the paper thoroughly.:I carefully checked the derivations and theory.;I have published one or two papers in this area.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:I assessed the sensibility of the derivations and theory.,Withdrawn,0,4,,yes,9/25/19,New York University;Swiss Federal Institute of Technology;Swiss Federal Institute of Technology,25;10;10,29;13;13,
2020,ROBUST SINGLE-STEP ADVERSARIAL TRAINING,B.S. Vivek;R. Venkatesh Babu,svivek@iisc.ac.in;venky@iisc.ac.in,3;3;3,I have published in this field for several years.:I carefully checked the experiments.:I read the paper thoroughly.:N/A;I have published in this field for several years.:I carefully checked the experiments.:I read the paper thoroughly.:I assessed the sensibility of the derivations and theory.;I have published one or two papers in this area.:I assessed the sensibility of the experiments.:I read the paper thoroughly.:N/A,Withdrawn,0,3,,yes,9/25/19,Indian Institute of Science;Indian Institute of Science,95;95,301;301,2;4;4
2020,Attentive Weights Generation for Few Shot Learning via Information Maximization,Yiluan Guo;Ngai-Man Cheung,guoyl1990@outlook.com;ngaiman_cheung@sutd.edu.sg,1;6;6,I have published in this field for several years.:I carefully checked the experiments.:I read the paper thoroughly.:I assessed the sensibility of the derivations and theory.;I have published one or two papers in this area.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:I assessed the sensibility of the derivations and theory.;I have published one or two papers in this area.:I assessed the sensibility of the experiments.:I read the paper thoroughly.:I assessed the sensibility of the derivations and theory.,Withdrawn,0,5,,yes,9/25/19,Singapore University of Technology and Design;Singapore University of Technology and Design,481;481,1397;1397,1;6
2020,DropGrad: Gradient Dropout Regularization for Meta-Learning,Hung-Yu Tseng;Yi-Wen Chen;Yi-Hsuan Tsai;Sifei Liu;Yen-Yu Lin;Ming-Hsuan Yang,htseng6@ucmerced.edu;ychen319@ucmerced.edu;wasidennis@gmail.com;sifeil@nvidia.com;lin@cs.nctu.edu.tw;mhyang@ucmerced.edu,3;3;3,I have read many papers in this area.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:I carefully checked the derivations and theory.;I have published one or two papers in this area.:I carefully checked the experiments.:I read the paper thoroughly.:I carefully checked the derivations and theory.;I have published one or two papers in this area.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:N/A,Withdrawn,0,0,,yes,9/25/19,University of California at Merced;University of California at Merced;NEC-Labs;NVIDIA;National Chiao Tung University;University of California at Merced,481;481;-1;-1;143;481,354;354;-1;-1;564;354,1;6;6
2020,Hierarchical Image-to-image Translation with Nested Distributions Modeling,Shishi Qiao;Ruiping Wang;Shiguang Shan;Xilin Chen,qiaoshishi14@mails.ucas.ac.cn;wangruiping@ict.ac.cn;sgshan@ict.ac.cn;xlchen@ict.ac.cn,3;3;3,I have published one or two papers in this area.:I carefully checked the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:I carefully checked the derivations and theory.;I have published one or two papers in this area.:I carefully checked the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:I assessed the sensibility of the derivations and theory.;I have published one or two papers in this area.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:I carefully checked the derivations and theory.,Withdrawn,0,0,,yes,9/25/19,"Chinese Academy of Sciences;Institute of Computing Technology, Chinese Academy of Sciences;Institute of Computing Technology, Chinese Academy of Sciences;Institute of Computing Technology, Chinese Academy of Sciences",59;59;59;59,1397;1397;1397;1397,
2020,Deep Neural Forests: An Architecture for Tabular Data,Ami Abutbul;Gal Elidan;Liran Katzir;Ran El-Yaniv,amramabutbul@cs.technion.ac.il;elidan@google.com;lirank@google.com;elyaniv@google.com,3;3;3;3,I have read many papers in this area.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:I assessed the sensibility of the derivations and theory.;I have read many papers in this area.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:I assessed the sensibility of the derivations and theory.;I have read many papers in this area.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:I assessed the sensibility of the derivations and theory.;I have published one or two papers in this area.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:N/A,Withdrawn,0,4,,yes,9/25/19,Technion;Google;Google;Google,26;-1;-1;-1,412;-1;-1;-1,
2020,Is my Deep Learning Model Learning more than I want it to?,Naveen Panwar;Tarun Tater;Anush Sankaran;Senthil Mani,naveen.panwar@in.ibm.com;anussank@in.ibm.com;taruntater3@gmail.com;sentmani@in.ibm.com,3;1;1,I have read many papers in this area.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:I assessed the sensibility of the derivations and theory.;I do not know much about this area.:I assessed the sensibility of the experiments.:I made a quick assessment of this paper.:N/A;I have published one or two papers in this area.:I carefully checked the experiments.:I read the paper thoroughly.:I carefully checked the derivations and theory.,Withdrawn,0,0,,yes,9/25/19,International Business Machines;International Business Machines;International Business Machines;International Business Machines,-1;-1;-1;-1,-1;-1;-1;-1,1
2020,Mixing Up Real Samples and Adversarial Samples for Semi-Supervised Learning,Yun Ma;Xudong Mao;Yangbin Chen;Qing Li,mayun371@gmail.com;xudong.xdmao@gmail.com;robinchen2-c@my.cityu.edu.hk;qing-prof.li@polyu.edu.hk,1;3;1,I have published one or two papers in this area.:I carefully checked the experiments.:I read the paper thoroughly.:I carefully checked the derivations and theory.;I have published one or two papers in this area.:I carefully checked the experiments.:I read the paper thoroughly.:I carefully checked the derivations and theory.;I have published in this field for several years.:I carefully checked the experiments.:N/A:N/A,Withdrawn,0,1,,yes,9/25/19,The Hong Kong Polytechnic University;The Hong Kong Polytechnic University;City University of Hong Kong;The Hong Kong Polytechnic University,172;172;92;172,171;171;35;171,4
2020,ADASAMPLE: ADAPTIVE SAMPLING OF HARD POSITIVES FOR DESCRIPTOR LEARNING,Xin-Yu Zhang;Jia-Wang Bian;Le Zhang;Zao-Yi Zheng;Yun Liu;Ming-Ming Cheng;Ian Reid,xinyuzhang@mail.nankai.edu.cn;jiawang.bian@gmail.com;zhangleuestc@gmail.com;roymarssss@gmail.com;nk12csly@mail.nankai.edu.cn;cmm@nankai.edu.cn;ian.reid@adelaide.edu.au,3;6;3,I do not know much about this area.:I carefully checked the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:I assessed the sensibility of the derivations and theory.;I have read many papers in this area.:I carefully checked the experiments.:I read the paper thoroughly.:I carefully checked the derivations and theory.;I have published one or two papers in this area.:I carefully checked the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:I assessed the sensibility of the derivations and theory.,Withdrawn,0,5,,yes,9/25/19,Nankai University;The University of Adelaide;A*STAR;;Nankai University;Nankai University;The University of Adelaide,481;128;-1;-1;481;481;128,366;120;-1;-1;366;366;120,
2020,Better Optimization for Neural Architecture Search with Mixed-Level Reformulation,Chaoyang He;Haishan Ye;Tong Zhang,chaoyang.he@usc.edu;yhs12354123@163.com;tongzhang@tongzhang-ml.org,3;3;1,I have read many papers in this area.:I assessed the sensibility of the experiments.:I read the paper thoroughly.:I assessed the sensibility of the derivations and theory.;I have published one or two papers in this area.:I carefully checked the experiments.:I read the paper thoroughly.:I carefully checked the derivations and theory.;I have published one or two papers in this area.:I carefully checked the experiments.:I read the paper thoroughly.:I carefully checked the derivations and theory.,Withdrawn,0,0,,yes,9/25/19,University of Southern California;163;The Hong Kong University of Science and Technology,31;-1;39,62;-1;47,
2020,Amharic Light Stemmer,Girma Neshir;Andeas Rauber;and Solomon Atnafu,girma1978@gmail.com;rauber@ifs.tuwien.ac.at;solomon.atnafu@aau.edu.et,1;1;1,I do not know much about this area.:I carefully checked the experiments.:I read the paper thoroughly.:N/A;I have published one or two papers in this area.:I assessed the sensibility of the experiments.:I made a quick assessment of this paper.:N/A;I have read many papers in this area.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:I did not assess the derivations or theory.,Withdrawn,0,0,,yes,9/25/19,Addis Ababa University;TU Wien Vienna University of Technology;Addis Ababa University,481;100;481,1397;360;1397,1
2020,Neural Reverse Engineering of Stripped Binaries,Yaniv David;Uri Alon;Eran Yahav,yanivd@cs.technion.ac.il;urialon@cs.technion.ac.il;yahave@cs.technion.ac.il,6;3;3,I have published one or two papers in this area.:I carefully checked the experiments.:N/A:N/A;I have published in this field for several years.:I assessed the sensibility of the experiments.:I read the paper thoroughly.:N/A;I have read many papers in this area.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:I assessed the sensibility of the derivations and theory.,Withdrawn,0,7,,yes,9/25/19,Technion;Technion;Technion,26;26;26,412;412;412,
2020,Cost-Effective Interactive Neural Attention Learning,Jay Heo;Junhyeon Park;Hyewon Jeong;Wuhyun Shin;Kwang Joon Kim;juho Lee;Eunho Yang;Sung Ju Hwang,jayheo@kaist.ac.kr;pjh2941@kaist.ac.kr;jhw162@kaist.ac.kr;wuhyun.shin@kaist.ac.kr;preppie@yuhs.ac.kr;juho@aitrics.com;eunhoy@kaist.ac.kr;sjhwang82@kaist.ac.kr,3;3;3;1,I have read many papers in this area.:I carefully checked the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:I assessed the sensibility of the derivations and theory.;I have published one or two papers in this area.:I assessed the sensibility of the experiments.:I read the paper thoroughly.:I assessed the sensibility of the derivations and theory.;I do not know much about this area.:I assessed the sensibility of the experiments.:I made a quick assessment of this paper.:I did not assess the derivations or theory.;I have published in this field for several years.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:I assessed the sensibility of the derivations and theory.,Withdrawn,0,4,,yes,9/25/19,Korea Advanced Institute of Science and Technology;Korea Advanced Institute of Science and Technology;Korea Advanced Institute of Science and Technology;Korea Advanced Institute of Science and Technology;Kyung Hee;AITRICS;Korea Advanced Institute of Science and Technology;Korea Advanced Institute of Science and Technology,481;481;481;481;481;-1;481;481,110;110;110;110;319;-1;110;110,
2020,Gated Channel Transformation for Visual Recognition,Zongxin Yang;Linchao Zhu;Yu Wu;Yi Yang,zongxin.yang@student.uts.edu.au;zhulinchao7@gmail.com;yu.wu-3@student.uts.edu.au;yi.yang@uts.edu.au,3;1;6,I have read many papers in this area.:I carefully checked the experiments.:I read the paper thoroughly.:I carefully checked the derivations and theory.;I have published in this field for several years.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:N/A;I have read many papers in this area.:I carefully checked the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:I assessed the sensibility of the derivations and theory.,Withdrawn,0,3,,yes,9/25/19,University of Technology Sydney;University of Technology Sydney;University of Technology Sydney;University of Technology Sydney,108;108;108;108,193;193;193;193,2;2
2020,Masked Translation Model,Arne Nix;Yunsu Kim;Jan Rosendahl;Shahram Khadivi;Hermann Ney,nix@i6.informatik.rwth-aachen.de;kim@i6.informatik.rwth-aachen.de;rosendahl@i6.informatik.rwth-aachen.de;skhadivi@ebay.com;ney@i6.informatik.rwth-aachen.de,3;3;3,I do not know much about this area.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:I carefully checked the derivations and theory.;I have published one or two papers in this area.:I carefully checked the experiments.:I read the paper thoroughly.:I assessed the sensibility of the derivations and theory.;I have published in this field for several years.:I carefully checked the experiments.:I read the paper thoroughly.:I carefully checked the derivations and theory.,Withdrawn,1,1,,yes,9/25/19,RWTH Aachen University;RWTH Aachen University;RWTH Aachen University;eBay;RWTH Aachen University,95;95;95;-1;95,98;98;98;-1;98,3
2020,Target-directed Atomic Importance Estimation via Reverse Self-attention,Gyoung S. Na;Hyun Woo Kim,ngs0726@gmail.com;ahwk@krict.re.kr,1;1;3,I have published one or two papers in this area.:I carefully checked the experiments.:I read the paper thoroughly.:I assessed the sensibility of the derivations and theory.;I have published in this field for several years.:I carefully checked the experiments.:I read the paper thoroughly.:N/A;I have read many papers in this area.:I carefully checked the experiments.:I read the paper thoroughly.:I carefully checked the derivations and theory.,Withdrawn,0,3,,yes,9/25/19,POSTECH;,118;-1,146;-1,
2020,ProxNet: End-to-End Learning of  Structured Representation by Proximal Mapping,Mao Li;Yingyi Ma;Xinhua Zhang,mli206@uic.edu;yma36@uic.edu;zhangx@uic.edu,3;1;3,I have published one or two papers in this area.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:I assessed the sensibility of the derivations and theory.;I have published one or two papers in this area.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:I assessed the sensibility of the derivations and theory.;I have published one or two papers in this area.:I carefully checked the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:I assessed the sensibility of the derivations and theory.,Withdrawn,0,2,,yes,9/25/19,"University of Illinois, Chicago;University of Illinois, Chicago;University of Illinois, Chicago",56;56;56,254;254;254,1;4
2020,Measure by Measure: Automatic Music Composition with Traditional Western Music Notation,Yujia Yan;Zhiyao Duan,yujia.yan.w@gmail.com;zhiyao.duan@rochester.edu,1;1;1,I have read many papers in this area.:I carefully checked the experiments.:I read the paper thoroughly.:N/A;I have published one or two papers in this area.:I assessed the sensibility of the experiments.:I read the paper thoroughly.:I carefully checked the derivations and theory.;I have published in this field for several years.:I carefully checked the experiments.:I read the paper thoroughly.:N/A,Withdrawn,0,1,,yes,9/25/19,University of Rochester;University of Rochester,100;100,173;173,
2020,When Do Variational Autoencoders Know  What They Don't Know?,Bin Dai;David Wipf,daib13@mails.tsinghua.edu.cn;davidwipf@gmail.com,8;6;8,I have read many papers in this area.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:I assessed the sensibility of the derivations and theory.;I have published in this field for several years.:I assessed the sensibility of the experiments.:I read the paper thoroughly.:I assessed the sensibility of the derivations and theory.;I have published in this field for several years.:I carefully checked the experiments.:I read the paper thoroughly.:I assessed the sensibility of the derivations and theory.,Withdrawn,0,1,,yes,9/25/19,Tsinghua University;Microsoft,8;-1,23;-1,5;5;5
2020,Irrationality can help reward inference,Lawrence Chan;Andrew Critch;Anca Dragan,chanlaw@berkeley.edu;critch@berkeley.edu;anca@berkeley.edu,3;3;3,I do not know much about this area.:I assessed the sensibility of the experiments.:I made a quick assessment of this paper.:I assessed the sensibility of the derivations and theory.;I have published one or two papers in this area.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:I assessed the sensibility of the derivations and theory.;I have read many papers in this area.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:I assessed the sensibility of the derivations and theory.,Withdrawn,0,3,,yes,9/25/19,University of California Berkeley;University of California Berkeley;University of California Berkeley,5;5;5,13;13;13,
2020,Teaching GAN to generate per-pixel annotation,Danil Galeev;Konstantin Sofiyuk;Danila Rukhovich;Anton Konushin;Mikhail Romanov,denemmy@gmail.com;ksofiyuk@gmail.com;danrukh@gmail.com;a.konushin@samsung.com;m.romanov@samsung.com,3;1;1,I have published in this field for several years.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:N/A;I have read many papers in this area.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:I assessed the sensibility of the derivations and theory.;I do not know much about this area.:I assessed the sensibility of the experiments.:I made a quick assessment of this paper.:I assessed the sensibility of the derivations and theory.,Withdrawn,0,0,,yes,9/25/19,Samsung;Samsung;Lomonosov Moscow State University;Samsung;Samsung,-1;-1;-1;-1;-1,-1;-1;-1;-1;-1,2;5
2020,One Generation Knowledge Distillation by Utilizing Peer Samples,Xingjian Li;Haozhe An;Haoyi Xiong;Jun Huan;Dejing Dou;Chengzhong Xu,1762778193@qq.com;haozhe.an@yahoo.com,1;3;3,I have published one or two papers in this area.:I did not assess the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:I assessed the sensibility of the derivations and theory.;I have read many papers in this area.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:I assessed the sensibility of the derivations and theory.;I have published one or two papers in this area.:I carefully checked the experiments.:I read the paper thoroughly.:I carefully checked the derivations and theory.,Withdrawn,0,3,,yes,9/25/19,;Baidu,-1;-1,-1;-1,1
2020,Guided variational autoencoder for disentanglement learning,Zheng Ding;Yifan Xu;Weijian Xu;Yang Yang;Max Welling;Zhuowen Tu,dingz16@mails.tsinghua.edu.cn;yix081@ucsd.edu;wex041@eng.ucsd.edu;yyangy@qti.qualcomm.com;welling.max@gmail.com;ztu@ucsd.edu,1;3;3,I have read many papers in this area.:I carefully checked the experiments.:I read the paper thoroughly.:N/A;I have published one or two papers in this area.:I carefully checked the experiments.:I read the paper thoroughly.:I carefully checked the derivations and theory.;I have read many papers in this area.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:I assessed the sensibility of the derivations and theory.,Withdrawn,0,1,,yes,9/25/19,"Tsinghua University;University of California, San Diego;University of California, San Diego;Qualcomm Inc, QualComm;University of California - Irvine;University of California, San Diego",8;11;11;-1;35;11,23;31;31;-1;96;31,1;4;5;5;5
2020,Learning Sparsity and Quantization Jointly and Automatically for Neural Network Compression via Constrained Optimization,Haichuan Yang;Shupeng Gui;Yuhao Zhu;Ji Liu,h.yang@rochester.edu;sgui2@ur.rochester.edu;yzhu@rochester.edu;ji.liu.uwisc@gmail.com,3;6;3,I have published one or two papers in this area.:I carefully checked the experiments.:I read the paper thoroughly.:I assessed the sensibility of the derivations and theory.;I have published one or two papers in this area.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:I assessed the sensibility of the derivations and theory.;I have published one or two papers in this area.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:I assessed the sensibility of the derivations and theory.,Withdrawn,0,0,,yes,9/25/19,University of Rochester;University of Rochester;University of Rochester;University of Rochester,100;100;100;100,173;173;173;173,
2020,FairFace: A Novel Face Attribute Dataset for Bias Measurement and Mitigation,Kimmo Kärkkäinen;Jungseock Joo,kimmo@cs.ucla.edu;jjoo@comm.ucla.edu,3;1;1,I have published in this field for several years.:I carefully checked the experiments.:I read the paper thoroughly.:I carefully checked the derivations and theory.;I have published one or two papers in this area.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:I did not assess the derivations or theory.;I have read many papers in this area.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:N/A,Withdrawn,0,3,,yes,9/25/19,"University of California, Los Angeles;University of California, Los Angeles",20;20,17;17,2
2020,Pruning Depthwise Separable Convolutions for Extra Efficiency Gain of Lightweight Models,Cheng-Hao Tu;Jia-Hong Lee;Yi-Ming Chan;Chu-Song Chen,andytu28@iis.sinica.edu.tw;honghenry.lee@iis.sinica.edu.tw;yiming@iis.sinica.edu.tw;song@iis.sinica.edu.tw,3;3;3,I have published one or two papers in this area.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:N/A;I have read many papers in this area.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:N/A;I have read many papers in this area.:I carefully checked the experiments.:I read the paper thoroughly.:I assessed the sensibility of the derivations and theory.,Withdrawn,1,0,,yes,9/25/19,Academia Sinica;Academia Sinica;Academia Sinica;Academia Sinica,-1;-1;-1;-1,-1;-1;-1;-1,1
2020,Benchmarking Adversarial Robustness,Yinpeng Dong;Qi-An Fu;Xiao Yang;Tianyu Pang;Hang Su;Jun Zhu,dyp17@mails.tsinghua.edu.cn;fqa19@mails.tsinghua.edu.cn;yangxiao19@mails.tsinghua.edu.cn;pty17@mails.tsinghua.edu.cn;suhangss@mail.tsinghua.edu.cn;dcszj@mail.tsinghua.edu.cn,1;3;1,I have published in this field for several years.:I carefully checked the experiments.:I read the paper thoroughly.:N/A;I have published one or two papers in this area.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:I assessed the sensibility of the derivations and theory.;I have published in this field for several years.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:N/A,Withdrawn,0,0,,yes,9/25/19,Tsinghua University;Tsinghua University;Tsinghua University;Tsinghua University;Tsinghua University;Tsinghua University,8;8;8;8;8;8,23;23;23;23;23;23,4;4
2020,Unsupervised Learning from Video with Deep Neural Embeddings,Chengxu Zhuang;Tianwei She;Alex Andonian;Daniel Yamins,chengxuz@stanford.edu;shetw@stanford.edu;aandonia@mit.edu;yamins@stanford.edu,3;3;3,I have published in this field for several years.:I carefully checked the experiments.:I read the paper thoroughly.:I assessed the sensibility of the derivations and theory.;I have published one or two papers in this area.:I carefully checked the experiments.:I read the paper thoroughly.:N/A;I have published one or two papers in this area.:I assessed the sensibility of the experiments.:N/A:N/A,Withdrawn,0,0,,yes,9/25/19,Stanford University;Stanford University;Massachusetts Institute of Technology;Stanford University,4;4;2;4,4;4;5;4,
2020,Towards Unifying Neural Architecture Space Exploration and Generalization,Kartikeya Bhardwaj;Radu Marculescu,bhardwajkartikeya@gmail.com;radum@cmu.edu,3;1,I do not know much about this area.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:I assessed the sensibility of the derivations and theory.;I have read many papers in this area.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:I assessed the sensibility of the derivations and theory.,Withdrawn,0,0,,yes,9/25/19,arm;Carnegie Mellon University,-1;1,-1;27,
2020,IEG: Robust neural net training with severe label noises,Zizhao Zhang;Han Zhang;Sercan Arik;Honglak Lee;Tomas Pfister,zizhaoz@google.com;zhanghan@google.com;soarik@google.com;honglak@google.com;tpfister@google.com,1;3;3,I have published in this field for several years.:I assessed the sensibility of the experiments.:I read the paper thoroughly.:I assessed the sensibility of the derivations and theory.;I have published in this field for several years.:I assessed the sensibility of the experiments.:I read the paper thoroughly.:I assessed the sensibility of the derivations and theory.;I have published in this field for several years.:I carefully checked the experiments.:I read the paper thoroughly.:I carefully checked the derivations and theory.,Withdrawn,0,6,,yes,9/25/19,Google;Google;Google;Google;Google,-1;-1;-1;-1;-1,-1;-1;-1;-1;-1,
2020,Stochastic Geodesic Optimization for Neural Networks,Zana Rashidi;Aijun An;Xiaogang Wang,zrashidi@eecs.yorku.ca;aan@cse.yorku.ca;stevenw@mathstat.yorku.ca,1;3;3,I have read many papers in this area.:I did not assess the experiments.:I read the paper thoroughly.:I carefully checked the derivations and theory.;I have published one or two papers in this area.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:I assessed the sensibility of the derivations and theory.;I have published in this field for several years.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:I carefully checked the derivations and theory.,Withdrawn,0,1,,yes,9/25/19,York University;York University;York University,172;172;172,416;416;416,1;5
2020,WEEGNET: an wavelet based Convnet for Brain-computer interfaces,Mouad Riyad;Mohammed Khalil;Abdellah Adib,riyadmouad1@gmail.com;medkhalil87@gmail.com;adib@fstm.ma,1;3;1,I have published in this field for several years.:I assessed the sensibility of the experiments.:I read the paper thoroughly.:N/A;I have published in this field for several years.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:I assessed the sensibility of the derivations and theory.;I have published in this field for several years.:I carefully checked the experiments.:N/A:N/A,Withdrawn,0,0,,yes,9/25/19,Faculty of Sciences and Technologies -Mohammedia;;,-1;-1;-1,-1;-1;-1,
2020,Classification as Decoder: Trading Flexibility for Control in Multi Domain Dialogue,Sam Shleifer;Manish Chablani;Namit Katariya;Anitha Kannan;Xavier Amatriain,sshleifer@gmail.com;manish@curai.com;namit@curai.com;anitha@curai.com;xavier@curai.com,1;3;1,I have published one or two papers in this area.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:N/A;I have published one or two papers in this area.:I carefully checked the experiments.:I read the paper thoroughly.:I carefully checked the derivations and theory.;I have published one or two papers in this area.:I assessed the sensibility of the experiments.:I read the paper thoroughly.:N/A,Withdrawn,0,3,,yes,9/25/19,Stanford University;Curai;Curai;Curai;Curai,4;233;233;233;233,4;-1;-1;-1;-1,1;5
2020,Anomaly Detection and Localization in Images using Guided Attention,Shashanka Venkataramanan;Rajat Vikram Singh;Kuan-Chuan Peng,shashankv@knights.ucf.edu;singh.rajat@siemens.com;kp388@cornell.edu,6;3;3,I have published one or two papers in this area.:I carefully checked the experiments.:I read the paper thoroughly.:I carefully checked the derivations and theory.;I do not know much about this area.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:I assessed the sensibility of the derivations and theory.;I have published one or two papers in this area.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:I assessed the sensibility of the derivations and theory.,Withdrawn,0,5,,yes,9/25/19,University of Central Florida;Siemens Corporate Research;Cornell University,77;-1;7,609;-1;19,2;4;5;5
2020,In-training Matrix Factorization for Parameter-frugal Neural Machine Translation,Zachary Kaden;Teven Le Scao;Raphael Olivier,kadenzack@gmail.com;tlescao@andrew.cmu.edu;rolivier@cs.cmu.edu,1;3;3,I have read many papers in this area.:I assessed the sensibility of the experiments.:I read the paper thoroughly.:N/A;I have published one or two papers in this area.:I assessed the sensibility of the experiments.:I read the paper thoroughly.:N/A;I have published in this field for several years.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:N/A,Withdrawn,0,0,,yes,9/25/19,;Carnegie Mellon University;Carnegie Mellon University,-1;1;1,-1;27;27,3
2020,Dataset Distillation,Tongzhou Wang;Jun-Yan Zhu;Antonio Torralba;Alexei A. Efros,tongzhou.wang.1994@gmail.com;junyanz@mit.edu;torralba@mit.edu;efros@eecs.berkeley.edu,6;3;3,I have read many papers in this area.:I assessed the sensibility of the experiments.:I read the paper thoroughly.:I carefully checked the derivations and theory.;I have read many papers in this area.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:I assessed the sensibility of the derivations and theory.;I have published one or two papers in this area.:I carefully checked the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:I assessed the sensibility of the derivations and theory.,Withdrawn,2,11,,yes,9/25/19,Massachusetts Institute of Technology;Massachusetts Institute of Technology;Massachusetts Institute of Technology;University of California Berkeley,2;2;2;5,5;5;5;13,
2020,Spatial Information is Overrated for Image Classification,Yue Fan;Yongqin Xian;Max Maria Losch;Bernt Schiele,yfan@mpi-inf.mpg.de;yxian@mpi-inf.mpg.de;mlosch@mpi-inf.mpg.de;schiele@mpi-inf.mpg.de,6;1;1,I have read many papers in this area.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:I assessed the sensibility of the derivations and theory.;I have published in this field for several years.:I assessed the sensibility of the experiments.:I read the paper thoroughly.:I assessed the sensibility of the derivations and theory.;I have published one or two papers in this area.:I carefully checked the experiments.:I read the paper thoroughly.:I carefully checked the derivations and theory.,Withdrawn,0,1,,yes,9/25/19,"Saarland Informatics Campus, Max-Planck Institute;Saarland Informatics Campus, Max-Planck Institute;Saarland Informatics Campus, Max-Planck Institute;Saarland Informatics Campus, Max-Planck Institute",-1;-1;-1;-1,-1;-1;-1;-1,
2020,GMM-UNIT: Unsupervised Multi-Domain and Multi-Modal Image-to-Image Translation via Attribute Gaussian Mixture Modelling,Yahui Liu;Marco De Nadai;Jian Yao;Nicu Sebe;Bruno Lepri;Xavier Alameda-Pineda,yahui.liu@unitn.it;denadai@fbk.eu;jian.yao@whu.edu.cn;niculae.sebe@unitn.it;lepri@fbk.eu;xavier.alameda-pineda@inria.fr,6;3;1,I do not know much about this area.:I carefully checked the experiments.:I read the paper thoroughly.:N/A;I have published one or two papers in this area.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:I carefully checked the derivations and theory.;I do not know much about this area.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:I carefully checked the derivations and theory.,Withdrawn,0,0,,yes,9/25/19,University of Trento;Fondazione Bruno Kessler;Wuhan University;University of Trento;Fondazione Bruno Kessler;INRIA,18;-1;266;18;-1;-1,307;-1;354;307;-1;-1,
2020,Information lies in the eye of the beholder: The effect of representations on observed mutual information,Julian Zilly;Lorenz Hetzel;Andrea Censi;Emilio Frazzoli,jzilly@ethz.ch;hetzell@ethz.ch;acensi@ethz.ch;emilio.frazzoli@idsc.mavt.ethz.ch,3;1;1,I do not know much about this area.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:I assessed the sensibility of the derivations and theory.;I have published one or two papers in this area.:I did not assess the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:I carefully checked the derivations and theory.;I have published in this field for several years.:I assessed the sensibility of the experiments.:I read the paper thoroughly.:I carefully checked the derivations and theory.,Withdrawn,0,2,,yes,9/25/19,Swiss Federal Institute of Technology;Swiss Federal Institute of Technology;Swiss Federal Institute of Technology;Swiss Federal Institute of Technology,10;10;10;10,13;13;13;13,
2020,Quantitatively Disentangling and Understanding Part Information in CNNs,Quanshi Zhang;Yu Yang;Haotian Ma;Ying Nian Wu,zqs1022@sjtu.edu.cn;yy19970901@ucla.edu;11612807@mail.sustc.edu.cn;ywu@stat.ucla.edu,6;3;3,I have read many papers in this area.:I did not assess the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:I assessed the sensibility of the derivations and theory.;I have read many papers in this area.:I carefully checked the experiments.:I read the paper thoroughly.:I carefully checked the derivations and theory.;I have read many papers in this area.:I assessed the sensibility of the experiments.:I made a quick assessment of this paper.:I assessed the sensibility of the derivations and theory.,Withdrawn,0,0,,yes,9/25/19,"Shanghai Jiao Tong University;University of California, Los Angeles;University of Science and Technology of China;University of California, Los Angeles",53;20;481;20,157;17;80;17,
2020,Graph-based motion planning networks,Tai Hoang;Ngo Anh Vien,thobotics@gmail.com;v.ngo@qub.ac.uk,1;3;3,I have published one or two papers in this area.:I carefully checked the experiments.:I read the paper thoroughly.:N/A;I have published in this field for several years.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:N/A;I have read many papers in this area.:I carefully checked the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:N/A,Withdrawn,0,0,,yes,9/25/19,VNG Corporation;Queen's University Belfast,-1;266,-1;204,
2020,Bridging ELBO objective and MMD,Talip Ucar,pilatracu@gmail.com,1;1;1,I have published one or two papers in this area.:I assessed the sensibility of the experiments.:I read the paper thoroughly.:I carefully checked the derivations and theory.;I have read many papers in this area.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:I carefully checked the derivations and theory.;I have read many papers in this area.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:I assessed the sensibility of the derivations and theory.,Withdrawn,0,3,,yes,9/25/19,University College London,50,15,5;5;5
2020,Deep 3D-Zoom Net: Unsupervised Learning of Photo-Realistic 3D-Zoom,Juan Luis Gonzalez Bello;Munchurl Kim,juanluisgb@kaist.ac.kr;mkimee@kaist.ac.kr,3;3;3,I have read many papers in this area.:I carefully checked the experiments.:I read the paper thoroughly.:I carefully checked the derivations and theory.;I have read many papers in this area.:I carefully checked the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:I carefully checked the derivations and theory.;I have published one or two papers in this area.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:I assessed the sensibility of the derivations and theory.,Withdrawn,0,0,,yes,9/25/19,Korea Advanced Institute of Science and Technology;Korea Advanced Institute of Science and Technology,481;481,110;110,6
2020,Through the Lens of Neural Network: Analyzing Neural QA Models via Quantized Latent Representation,Tsung-Han Wu;Chun-Cheng Hsieh;Yen-Hao Chen;Hung-yi Lee,ynnekuw@gmail.com;syasyunjyo@gmail.com;r07921112@ntu.edu.tw;hungyilee@ntu.edu.tw,3;3;1,I have published one or two papers in this area.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:N/A;I have published one or two papers in this area.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:N/A;I do not know much about this area.:I carefully checked the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:N/A,Withdrawn,0,0,,yes,9/25/19,National Taiwan University;;National Taiwan University;National Taiwan University,86;-1;86;86,120;-1;120;120,5
2020,Hierarchical Complement Objective Training,Hao-Yun Chen;Li-Huang Tsai;Shih-Chieh Chang;Jia-Yu Pan;Yu-Ting Chen;Wei Wei;Da-Cheng Juan,haoyunchen@gapp.nthu.edu.tw;lihuangtsai@gapp.nthu.edu.tw;scchang@cs.nthu.edu.tw;jypan@google.com;yutingchen@google.com;wewei@google.com;dacheng@google.com,3;3;3,I have read many papers in this area.:I assessed the sensibility of the experiments.:I made a quick assessment of this paper.:I assessed the sensibility of the derivations and theory.;I have published one or two papers in this area.:I carefully checked the experiments.:I read the paper thoroughly.:N/A;I have read many papers in this area.:I carefully checked the experiments.:I read the paper thoroughly.:I carefully checked the derivations and theory.,Withdrawn,0,3,,yes,9/25/19,National Tsing Hua University;National Tsing Hua University;National Tsing Hua University;Google;Google;Google;Google,172;172;172;-1;-1;-1;-1,365;365;365;-1;-1;-1;-1,2
2020,Anomalous Pattern Detection in Activations and Reconstruction Error of Autoencoders,Celia Cintas;Skyler Speakman;Victor Akinwande;Srihari Sridharan;William Ogallo;Edward McFowland III,celia.cintas@ibm.com;skyler@ke.ibm.com;victor.akinwande1@ibm.com;sriharis.sridharan@ke.ibm.com;william.ogallo@ibm.com;mcfowland@umn.edu,3;1;1,I have published one or two papers in this area.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:N/A;I have published in this field for several years.:I carefully checked the experiments.:I read the paper thoroughly.:I assessed the sensibility of the derivations and theory.;I do not know much about this area.:I assessed the sensibility of the experiments.:I read the paper thoroughly.:I did not assess the derivations or theory.,Withdrawn,0,3,,yes,9/25/19,"International Business Machines;International Business Machines;International Business Machines;International Business Machines;International Business Machines;University of Minnesota, Minneapolis",-1;-1;-1;-1;-1;59,-1;-1;-1;-1;-1;79,1;4;5
2020,Dynamically Balanced Value Estimates for Actor-Critic Methods,Nicolai Dorka;Joschka Boedecker;Wolfram Burgard,dorka@cs.uni-freiburg.de;jboedeck@cs.uni-freiburg.de;burgard@cs.uni-freiburg.de,3;1;3,I have published one or two papers in this area.:I carefully checked the experiments.:I read the paper thoroughly.:I carefully checked the derivations and theory.;I have published one or two papers in this area.:I carefully checked the experiments.:I read the paper thoroughly.:N/A;I have published one or two papers in this area.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:N/A,Withdrawn,0,0,,yes,9/25/19,Universität Freiburg;Universität Freiburg;Universität Freiburg,118;118;118,85;85;85,
2020,Incorporating Perceptual Prior to Improve Model's Adversarial Robustness,B.S. Vivek;Arya Baburaj;Ashutosh B Sathe;R. Venkatesh Babu,svivek@iisc.ac.in;aryababuraj@iisc.ac.in;satheab16.mech@coep.ac.in;venky@iisc.ac.in,1;1;1,I have published one or two papers in this area.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:N/A;I have published in this field for several years.:I carefully checked the experiments.:I read the paper thoroughly.:N/A;I have published in this field for several years.:I carefully checked the experiments.:I read the paper thoroughly.:N/A,Withdrawn,0,5,,yes,9/25/19,"Indian Institute of Science;Indian Institute of Science;College of Engineering, Pune;Indian Institute of Science",95;95;-1;95,301;301;-1;301,1;2;2;4;4
2020,MultiGrain: a unified image embedding for classes and instances,Maxim Berman;Hervé Jégou;Andrea Vedaldi;Iasonas Kokkinos;Matthijs Douze,maxim.berman@esat.kuleuven.be;rvj@fb.com;vedaldi@fb.com;iasonas.kokkinos@gmail.com;matthijs@fb.com,3;3;3,I have published one or two papers in this area.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:I assessed the sensibility of the derivations and theory.;I have published one or two papers in this area.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:I carefully checked the derivations and theory.;I do not know much about this area.:I assessed the sensibility of the experiments.:I made a quick assessment of this paper.:I did not assess the derivations or theory.,Withdrawn,0,4,,yes,9/25/19,KU Leuven;Facebook;Facebook;Ariel AI;Facebook,118;-1;-1;-1;-1,45;-1;-1;-1;-1,1
2020,A Simple Geometric Proof for the Benefit of Depth in ReLU Networks,Asaf Amrami;Yoav Goldberg,asaf.amrami@gmail.com;yoav.goldberg@gmail.com,3;3;1,I do not know much about this area.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:I assessed the sensibility of the derivations and theory.;I have read many papers in this area.:I carefully checked the experiments.:I read the paper thoroughly.:I assessed the sensibility of the derivations and theory.;I have read many papers in this area.:N/A:I made a quick assessment of this paper.:I assessed the sensibility of the derivations and theory.,Withdrawn,0,0,,yes,9/25/19,;Bar-Ilan University,-1;95,-1;513,
2020,How does Lipschitz Regularization Influence GAN Training?,Yipeng Qin;Niloy Mitra;Peter Wonka,qinyipeng1991@gmail.com;niloym@gmail.com;pwonka@gmail.com,3;3;3,I have read many papers in this area.:I assessed the sensibility of the experiments.:I read the paper thoroughly.:I carefully checked the derivations and theory.;I have published one or two papers in this area.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:I assessed the sensibility of the derivations and theory.;I have published in this field for several years.:I carefully checked the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:I assessed the sensibility of the derivations and theory.,Withdrawn,0,1,,yes,9/25/19,Cardiff University;University College London;KAUST,172;50;128,196;15;1397,5
2020,SIMULTANEOUS ATTRIBUTED NETWORK EMBEDDING AND CLUSTERING,Lazhar labiod;Mohamed Nadif,lazhar.labiod@parisdescartes.fr;mohamed.nadif@parisdescartes.fr,1;1;1,I have published in this field for several years.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:I assessed the sensibility of the derivations and theory.;I have published in this field for several years.:I carefully checked the experiments.:I read the paper thoroughly.:I carefully checked the derivations and theory.;I have read many papers in this area.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:I assessed the sensibility of the derivations and theory.,Withdrawn,0,0,,yes,9/25/19,University Paris Descartes;University Paris Descartes,-1;-1,-1;-1,
2020,Tree-structured Attention Module for Image Classification,Gyungin Shin;Sung-Ho Bae;and Yong-Jae Moon,gishin@khu.ac.kr;shbae@khu.ac.kr;moonyj@khu.ac.kr,3;3;3,I do not know much about this area.:I assessed the sensibility of the experiments.:I read the paper thoroughly.:I assessed the sensibility of the derivations and theory.;I have published one or two papers in this area.:I carefully checked the experiments.:I read the paper thoroughly.:I carefully checked the derivations and theory.;I have read many papers in this area.:I assessed the sensibility of the experiments.:I made a quick assessment of this paper.:N/A,Withdrawn,0,3,,yes,9/25/19,Kyung Hee University;Kyung Hee University;Kyung Hee University,481;481;481,319;319;319,1;2
2020,Task Level Data Augmentation for Meta-Learning,Jialin Liu;Fei Chao;Chih-Min Lin,31520171153232@stu.xmu.edu.cn;fchao@xmu.edu.cn;cml@saturn.yzu.edu.tw,3;3;6,I have published one or two papers in this area.:I carefully checked the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:I carefully checked the derivations and theory.;I have read many papers in this area.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:N/A;I do not know much about this area.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:N/A,Withdrawn,0,1,,yes,9/25/19,"Xiamen University;Xiamen University;Department of Computer Science and Engineering, Yuan Ze University",64;64;-1,8;8;-1,6;6
2020,Learning Semantic Correspondences from Noisy Data-text Pairs by Local-to-Global Alignments,Feng Nie;Jinpeng Wang;Rong Pan;Chin-Yew Lin,fengniesysu@gmail.com;jinpwa@microsoft.com;panr@sysu.edu.cn;cyl@microsoft.com,3;8,I do not know much about this area.:I did not assess the experiments.:I made a quick assessment of this paper.:N/A;I do not know much about this area.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:I assessed the sensibility of the derivations and theory.,Withdrawn,0,0,,yes,9/25/19,SUN YAT-SEN UNIVERSITY;Microsoft;SUN YAT-SEN UNIVERSITY;Microsoft,481;-1;481;-1,299;-1;299;-1,1;3
2020,VideoEpitoma: Efficient Recognition of Long-range Actions,Noureldien Hussein;Babak Ehteshami Bejnordi;Mihir Jain,nhussein@uva.nl;behtesha@qti.qualcomm.com;mijain@qti.qualcomm.com,1;3;1,I have published in this field for several years.:I carefully checked the experiments.:I read the paper thoroughly.:I carefully checked the derivations and theory.;I have published in this field for several years.:I carefully checked the experiments.:I read the paper thoroughly.:N/A;I have read many papers in this area.:I assessed the sensibility of the experiments.:I made a quick assessment of this paper.:I carefully checked the derivations and theory.,Withdrawn,0,3,,yes,9/25/19,"University of Amsterdam;Qualcomm Inc, QualComm;Qualcomm Inc, QualComm",172;-1;-1,62;-1;-1,
2020,StacNAS: Towards Stable and Consistent  Optimization for Differentiable  Neural Architecture Search,Li Guilin;Zhang Xing;Wang Zitong;Li Zhenguo;Zhang Tong,hiliguilin@gmail.com;zhang.xing1@huawei.com;ztwang@math.cuhk.edu.hk;li.zhenguo@huawei.com;tongzhang@tongzhang-ml.org,6;3;3,I have read many papers in this area.:I assessed the sensibility of the experiments.:I made a quick assessment of this paper.:N/A;I have published one or two papers in this area.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:I did not assess the derivations or theory.;I have read many papers in this area.:I carefully checked the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:I carefully checked the derivations and theory.,Withdrawn,1,3,,yes,9/25/19,;Huawei Technologies Ltd.;The Chinese University of Hong Kong;Huawei Technologies Ltd.;The Hong Kong University of Science and Technology,-1;-1;59;-1;39,-1;-1;35;-1;47,
2020,Construction of Macro Actions for Deep Reinforcement Learning,"Yi-Hsiang Chang;Kuan-Yu	Chang;Henry Kuo;Chun-Yi Lee",shawn420@gapp.nthu.edu.tw;kychang@elsa.cs.nthu.edu.tw;hkuo@college.harvard.edu;cylee@gapp.nthu.edu.tw,1;1;3,I have published in this field for several years.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:N/A;I do not know much about this area.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:I assessed the sensibility of the derivations and theory.;I have read many papers in this area.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:N/A,Withdrawn,0,1,,yes,9/25/19,National Tsing Hua University;National Tsing Hua University;Harvard University;National Tsing Hua University,172;172;39;172,365;365;7;365,
2020,Towards Understanding Generalization in Gradient-Based Meta-Learning,Simon Guiroy;Vikas Verma;Christopher J. Pal,simon.guiroy@umontreal.ca;vikasverma.iitm@gmail.com;christopher.pal@polymtl.ca,3;3;3,I have published one or two papers in this area.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:N/A;I have read many papers in this area.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:N/A;I have published one or two papers in this area.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:I assessed the sensibility of the derivations and theory.,Withdrawn,0,0,,yes,9/25/19,University of Montreal;;Polytechnique Montreal,128;-1;390,85;-1;1397,6
2020,Structural Multi-agent Learning,Kaiqian Han;Liangliang Ren;Jiwen Lu;Jie Zhou,hkg16@mails.tsinghua.edu.cn;renll16@mails.tsinghua.edu.cn;lujiwen@tsinghua.edu.cn;jzhou@tsinghua.edu.cn,1;3;6,I have published one or two papers in this area.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:N/A;I have published one or two papers in this area.:I assessed the sensibility of the experiments.:I read the paper thoroughly.:I assessed the sensibility of the derivations and theory.;I have read many papers in this area.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:I assessed the sensibility of the derivations and theory.,Withdrawn,0,4,,yes,9/25/19,Tsinghua University;Tsinghua University;Tsinghua University;Tsinghua University,8;8;8;8,23;23;23;23,
2020,AdamT: A Stochastic Optimization with Trend Correction Scheme,Bingxin Zhou;Xuebin Zheng;Junbin Gao,bzho3923@uni.sydney.edu.au;xzhe2914@uni.sydney.edu.au;junbin.gao@sydney.edu.au,3;3;1,I have read many papers in this area.:I carefully checked the experiments.:I read the paper thoroughly.:I assessed the sensibility of the derivations and theory.;I have published in this field for several years.:I carefully checked the experiments.:I read the paper thoroughly.:I carefully checked the derivations and theory.;I have published in this field for several years.:I assessed the sensibility of the experiments.:I made a quick assessment of this paper.:I assessed the sensibility of the derivations and theory.,Withdrawn,0,0,,yes,9/25/19,University of Sydney;University of Sydney;University of Sydney,86;86;86,60;60;60,
2020,Elastic-InfoGAN: Unsupervised Disentangled Representation Learning in Imbalanced Data,Utkarsh Ojha;Krishna Kumar Singh;Cho-Jui Hsieh;Yong Jae Lee,uojha@ucdavis.edu;krsingh@ucdavis.edu;chohsieh@cs.ucla.edu;yongjaelee@ucdavis.edu,3;3;3,I have published one or two papers in this area.:I assessed the sensibility of the experiments.:I read the paper thoroughly.:I assessed the sensibility of the derivations and theory.;I have read many papers in this area.:I assessed the sensibility of the experiments.:I read the paper thoroughly.:I carefully checked the derivations and theory.;I have read many papers in this area.:I assessed the sensibility of the experiments.:I read the paper thoroughly.:I carefully checked the derivations and theory.,Withdrawn,0,0,,yes,9/25/19,"University of California, Davis;University of California, Davis;University of California, Los Angeles;University of California, Davis",79;79;20;79,55;55;17;55,5;5
2020,Generalizing Deep Multi-task Learning with Heterogeneous Structured Networks,Ming Hou;Xinqi Chen;Shifeng Huang;Shengli Xie;Guoxu Zhou;Qibin Zhao,ming.hou@riken.jp;xinqicham@gmail.com;sfengmmin@163.com;shlxie@gdut.edu.cn;gx.zhou@gdut.edu.cn;qibin.zhao@riken.jp,3;1;3,I have published in this field for several years.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:I assessed the sensibility of the derivations and theory.;I have published in this field for several years.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:I carefully checked the derivations and theory.;I have read many papers in this area.:I carefully checked the experiments.:I read the paper thoroughly.:N/A,Withdrawn,0,0,,yes,9/25/19,RIKEN;South China University of Technology;163;South China University of Technology;South China University of Technology;RIKEN,-1;481;-1;481;481;-1,-1;501;-1;501;501;-1,
2020,Rethinking Data Augmentation: Self-Supervision and Self-Distillation,Hankook Lee;Sung Ju Hwang;Jinwoo Shin,hankook.lee@kaist.ac.kr;sjhwang82@kaist.ac.kr;jinwoos@kaist.ac.kr,1;3;3,I have published one or two papers in this area.:I carefully checked the experiments.:I made a quick assessment of this paper.:I did not assess the derivations or theory.;I have published one or two papers in this area.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:N/A;I have published one or two papers in this area.:I carefully checked the experiments.:I read the paper thoroughly.:I carefully checked the derivations and theory.,Withdrawn,0,2,,yes,9/25/19,Korea Advanced Institute of Science and Technology;Korea Advanced Institute of Science and Technology;Korea Advanced Institute of Science and Technology,481;481;481,110;110;110,6
2020,Dynamical Clustering of Time Series Data Using Multi-Decoder RNN Autoencoder,Daisuke Kaji;Kazuho Watanabe;Masahiro Kobayashi,daisuke.kaji.j3a@jp.denso.com;wkazuho@cs.tut.ac.jp;kobayashi@lisl.cs.tut.ac.jp,3;3;1,I have published one or two papers in this area.:I carefully checked the experiments.:I read the paper thoroughly.:I assessed the sensibility of the derivations and theory.;I have published in this field for several years.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:I assessed the sensibility of the derivations and theory.;I have published one or two papers in this area.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:I assessed the sensibility of the derivations and theory.,Withdrawn,0,3,,yes,9/25/19,"Jp.denso;Toyohashi University of Technology,;Toyohashi University of Technology,",-1;-1;-1,-1;-1;-1,
2020,Regularizing Predictions via Class-wise Self-knowledge Distillation,Sukmin Yun;Jongjin Park;Kimin Lee;Jinwoo Shin,sukmin.yun@kaist.ac.kr;jongjin.park@kaist.ac.kr;kiminlee@kaist.ac.kr;jinwoos@kaist.ac.kr,3;1;6,I have read many papers in this area.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:N/A;I have read many papers in this area.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:I assessed the sensibility of the derivations and theory.;I have read many papers in this area.:I assessed the sensibility of the experiments.:I made a quick assessment of this paper.:N/A,Withdrawn,0,1,,yes,9/25/19,Korea Advanced Institute of Science and Technology;Korea Advanced Institute of Science and Technology;Korea Advanced Institute of Science and Technology;Korea Advanced Institute of Science and Technology,481;481;481;481,110;110;110;110,1
2020,Imbalanced Classification via Adversarial Minority Over-sampling,Jaehyung Kim;Jongheon Jeong;Jinwoo Shin,jaehyungkim@kaist.ac.kr;jongheonj@kaist.ac.kr;jinwoos@kaist.ac.kr,3;3;3,I have read many papers in this area.:I carefully checked the experiments.:I read the paper thoroughly.:I assessed the sensibility of the derivations and theory.;I do not know much about this area.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:N/A;I have published in this field for several years.:I carefully checked the experiments.:I read the paper thoroughly.:I carefully checked the derivations and theory.,Withdrawn,0,1,,yes,9/25/19,Korea Advanced Institute of Science and Technology;Korea Advanced Institute of Science and Technology;Korea Advanced Institute of Science and Technology,481;481;481,110;110;110,1;3;4
2020,Neuron ranking - an informed way to compress convolutional neural networks,Kamil Adamczewski;Mijung Park,kamil.m.adamczewski@gmail.com;mijung.park@tuebingen.mpg.de,1;3;1,I have read many papers in this area.:I assessed the sensibility of the experiments.:I made a quick assessment of this paper.:I did not assess the derivations or theory.;I do not know much about this area.:I assessed the sensibility of the experiments.:I made a quick assessment of this paper.:I assessed the sensibility of the derivations and theory.;I have read many papers in this area.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:I carefully checked the derivations and theory.,Withdrawn,0,0,,yes,9/25/19,"Max Planck Institute for Intelligent Systems, Max-Planck Institute;Max Planck Institute for Intelligent Systems, Max-Planck Institute",-1;-1,-1;-1,
2020,Compressing Deep Neural Networks With Learnable Regularization,Yoojin Choi;Mostafa El-Khamy;Jungwon Lee,yoojin.c@samsung.com;mostafa.e@samsung.com;jungwon2.lee@samsung.com,3;6;3;3,I have published in this field for several years.:I carefully checked the experiments.:I read the paper thoroughly.:I carefully checked the derivations and theory.;I have read many papers in this area.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:N/A;I have published one or two papers in this area.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:I assessed the sensibility of the derivations and theory.;I have read many papers in this area.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:I assessed the sensibility of the derivations and theory.,Withdrawn,0,1,,yes,9/25/19,Samsung;Samsung;Samsung,-1;-1;-1,-1;-1;-1,
2020,Image Classification Through Top-Down Image Pyramid Traversal,Athanasios Papadopoulos;Pawel Korus;Nasir Memon,ap4094@nyu.edu;pkorus@nyu.edu;memon@nyu.edu,3;1;3,I have published in this field for several years.:I carefully checked the experiments.:I read the paper thoroughly.:I carefully checked the derivations and theory.;I have published in this field for several years.:I carefully checked the experiments.:I read the paper thoroughly.:N/A;I have published one or two papers in this area.:I carefully checked the experiments.:I read the paper thoroughly.:I assessed the sensibility of the derivations and theory.,Withdrawn,0,4,,yes,9/25/19,New York University;New York University;New York University,25;25;25,29;29;29,
2020,PAC-Bayes Few-shot Meta-learning with Implicit Learning of Model Prior Distribution,Cuong Nguyen;Thanh-Toan Do;Gustavo Carneiro,cuong.nguyen@adelaide.edu.au;thanh-toan.do@liverpool.ac.uk;gustavo.carneiro@adelaide.edu.au,6;1;1,I have read many papers in this area.:I carefully checked the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:I assessed the sensibility of the derivations and theory.;I have published one or two papers in this area.:I assessed the sensibility of the experiments.:I read the paper thoroughly.:I carefully checked the derivations and theory.;I have published in this field for several years.:I assessed the sensibility of the experiments.:I read the paper thoroughly.:I assessed the sensibility of the derivations and theory.,Withdrawn,0,0,,yes,9/25/19,The University of Adelaide;University of Liverpool;The University of Adelaide,128;-1;128,120;-1;120,5;6;6
2020,CRAP: Semi-supervised Learning via Conditional Rotation Angle Prediction,Hai-Ming Xu;Lingqiao Liu,hai-ming.xu@adelaide.edu.au;lingqiao.liu@adelaide.edu.au,3;3;3,I have published one or two papers in this area.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:N/A;I have read many papers in this area.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:I assessed the sensibility of the derivations and theory.;I do not know much about this area.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:I did not assess the derivations or theory.,Withdrawn,0,2,,yes,9/25/19,The University of Adelaide;The University of Adelaide,128;128,120;120,
2020,A novel text representation which enables image classifiers to perform text classification,Stephen M. Petrie;T'Mir D. Julius,spetrie@swin.edu.au;tdjempire@gmail.com,1;1;1,I have read many papers in this area.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:I assessed the sensibility of the derivations and theory.;I do not know much about this area.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:N/A;I have published one or two papers in this area.:I carefully checked the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:N/A,Withdrawn,0,0,,yes,9/25/19,Swinburne University of Technology;,-1;-1,-1;-1,3
2020,FACE SUPER-RESOLUTION GUIDED BY 3D FACIAL PRIORS,xiaobin hu;wenqi ren;jiaolong yang;xiaochun cao;Xiaoming Li;John LaMaster;Bjoern Menze;wei liu,xiaobin.hu@tum.de;rwq.renwenqi@gmail.com;jiaoyan@microsoft.com;caoxiaochun@iie.ac.cn;hit.xmshr@gmail.com;jlamaste@gmail.com;bjoern.menze@tum.de;wl2223@columbia.edu,3;3;3,I have published in this field for several years.:I carefully checked the experiments.:I read the paper thoroughly.:I carefully checked the derivations and theory.;I have read many papers in this area.:I carefully checked the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:I carefully checked the derivations and theory.;I have published in this field for several years.:I carefully checked the experiments.:I read the paper thoroughly.:I carefully checked the derivations and theory.,Withdrawn,0,0,,yes,9/25/19,"Technical University Munich;Institute of information engineering, CAS;Microsoft;Institute of information engineering, CAS;Harbin Institute of Technology;Technical University Munich;Technical University Munich;Columbia University",53;-1;-1;-1;172;53;53;15,43;-1;-1;-1;424;43;43;16,
2020,Doubly Normalized Attention,Nan Ding;Xinjie Fan;Zhenzhong Lan;Dale Schuurmans;Radu Soricut,dingnan@google.com;fan.xinjiebuaa@gmail.com;lanzhzh@google.com;schuurmans@google.com;rsoricut@google.com,3;1;1,I have published one or two papers in this area.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:I assessed the sensibility of the derivations and theory.;I have published one or two papers in this area.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:I assessed the sensibility of the derivations and theory.;I have published one or two papers in this area.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:I carefully checked the derivations and theory.,Withdrawn,0,3,,yes,9/25/19,"Google;University of Texas, Austin;Google;Google;Google",-1;22;-1;-1;-1,-1;38;-1;-1;-1,1
2020,Correctness Verification of Neural Network,Yichen Yang;Martin Rinard,yicheny@csail.mit.edu;rinard@csail.mit.edu,1;3;1,I do not know much about this area.:I did not assess the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:I assessed the sensibility of the derivations and theory.;I have published one or two papers in this area.:I carefully checked the experiments.:I read the paper thoroughly.:I carefully checked the derivations and theory.;I have published in this field for several years.:I assessed the sensibility of the experiments.:I read the paper thoroughly.:I assessed the sensibility of the derivations and theory.,Withdrawn,0,3,,yes,9/25/19,Massachusetts Institute of Technology;Massachusetts Institute of Technology,2;2,5;5,
2020,Diversely Stale Parameters for Efficient Training of Deep Convolutional Networks,An Xu;Zhouyuan Huo;Heng Huang,an.xu@pitt.edu;zhouyuan.huo@pitt.edu;heng.huang@pitt.edu,3;1;3,I have published one or two papers in this area.:I carefully checked the experiments.:I read the paper thoroughly.:I assessed the sensibility of the derivations and theory.;I have read many papers in this area.:I carefully checked the experiments.:I read the paper thoroughly.:I assessed the sensibility of the derivations and theory.;I do not know much about this area.:I carefully checked the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:I did not assess the derivations or theory.,Withdrawn,0,0,,yes,9/25/19,University of Pittsburgh;University of Pittsburgh;University of Pittsburgh,79;79;79,113;113;113,1
2020,WHAT DATA IS USEFUL FOR MY DATA: TRANSFER LEARNING WITH A MIXTURE OF SELF-SUPERVISED EXPERTS,Xi Yan;David Acuna;Sanja Fidler,xi.yan@mail.utoronto.ca;davidj@cs.toronto.edu;fidler@cs.toronto.edu,1;3;3,I have published one or two papers in this area.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:I assessed the sensibility of the derivations and theory.;I have read many papers in this area.:I assessed the sensibility of the experiments.:I made a quick assessment of this paper.:I did not assess the derivations or theory.;I have read many papers in this area.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:I assessed the sensibility of the derivations and theory.,Withdrawn,0,0,,yes,9/25/19,"Toronto University;Department of Computer Science, University of Toronto;Department of Computer Science, University of Toronto",18;18;18,18;18;18,1;2;2;6
2020,Classification Logit Two-sample Testing by Neural Networks,Xiuyuan Cheng;Alexander Cloninger,xiuyuan.cheng@duke.edu;acloninger@ucsd.edu,3;3;3,I have published in this field for several years.:I carefully checked the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:I assessed the sensibility of the derivations and theory.;I do not know much about this area.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:I did not assess the derivations or theory.;I have read many papers in this area.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:I assessed the sensibility of the derivations and theory.,Withdrawn,0,1,,yes,9/25/19,"Duke University;University of California, San Diego",47;11,20;31,1;4;5
2020,Frontal low-rank random tensors for high-order feature representation,Yan Zhang;Krikamol Muandet;Qianli Ma;Heiko Neumann;Siyu Tang,yan.zhang@tuebingen.mpg.de;krikamol@tuebingen.mpg.de;qianli.ma@tue.mpg.de;heiko.neumann@uni-ulm.de;stang@tuebingen.mpg.de,6;3;3;3,I have read many papers in this area.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:I assessed the sensibility of the derivations and theory.;I have published one or two papers in this area.:I assessed the sensibility of the experiments.:I read the paper thoroughly.:I assessed the sensibility of the derivations and theory.;I have published one or two papers in this area.:I assessed the sensibility of the experiments.:I made a quick assessment of this paper.:I did not assess the derivations or theory.;I have published in this field for several years.:I assessed the sensibility of the experiments.:I made a quick assessment of this paper.:I assessed the sensibility of the derivations and theory.,Withdrawn,0,1,,yes,9/25/19,"Max Planck Institute for Intelligent Systems, Max-Planck Institute;Max Planck Institute for Intelligent Systems, Max-Planck Institute;Max Planck Institute for Intelligent Systems, Max-Planck Institute;Ulm University;Max Planck Institute for Intelligent Systems, Max-Planck Institute",-1;-1;-1;172;-1,-1;-1;-1;416;-1,1;2
2020,Interpretability Evaluation Framework for Deep Neural Networks,Junxiang Wang;Liang Zhao;Yanfang Ye and Houman Homayoun,jwang40@gmu.edu;lzhao9@gmu.edu;yanfang.ye@mail.wvu.edu;hhomayou@gmu.edu,1;3;3,I have read many papers in this area.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:I assessed the sensibility of the derivations and theory.;I have read many papers in this area.:I assessed the sensibility of the experiments.:I made a quick assessment of this paper.:I did not assess the derivations or theory.;I have read many papers in this area.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:I assessed the sensibility of the derivations and theory.,Withdrawn,0,1,,yes,9/25/19,George Mason University;George Mason University;West Virginia University;George Mason University,100;100;-1;100,282;282;-1;282,1
2020,CWAE-IRL: Formulating a supervised approach to Inverse Reinforcement Learning problem,Arpan Kusari,arpan.kusari@gmail.com,3;1;1,I have read many papers in this area.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:I assessed the sensibility of the derivations and theory.;I have published in this field for several years.:I assessed the sensibility of the experiments.:I made a quick assessment of this paper.:I assessed the sensibility of the derivations and theory.;I have published in this field for several years.:I carefully checked the experiments.:I read the paper thoroughly.:I carefully checked the derivations and theory.,Withdrawn,0,0,,yes,9/25/19,,,,5;5
2020,"Study of a Simple, Expressive and Consistent Graph Feature Representation",Pineau Edouard,pineau.edouard@gmail.com,1;3;3,I have published in this field for several years.:I carefully checked the experiments.:I read the paper thoroughly.:I carefully checked the derivations and theory.;I do not know much about this area.:I carefully checked the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:I did not assess the derivations or theory.;I have read many papers in this area.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:I assessed the sensibility of the derivations and theory.,Withdrawn,0,1,,yes,9/25/19,Télécom ParisTech,481,187,
2020,Input Alignment along Chaotic directions increases Stability in Recurrent Neural Networks,Priyadarshini Panda;Kaushik Roy,priya.panda@yale.edu;kaushik@purdue.edu,6;1;1,I have read many papers in this area.:I assessed the sensibility of the experiments.:I read the paper thoroughly.:I carefully checked the derivations and theory.;I have published one or two papers in this area.:I assessed the sensibility of the experiments.:I made a quick assessment of this paper.:I assessed the sensibility of the derivations and theory.;I have read many papers in this area.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:I assessed the sensibility of the derivations and theory.,Withdrawn,0,0,,yes,9/25/19,Yale University;Purdue University,64;27,8;88,
2020,All Neural Networks are Created Equal,Guy Hacohen;Leshem Choshen;Daphna Weinshall,guy.hacohen@mail.huji.ac.il;leshem.choshen@mail.huji.ac.il;daphna@cs.huji.ac.il,3;3;1,I have read many papers in this area.:I assessed the sensibility of the experiments.:I read the paper thoroughly.:N/A;I do not know much about this area.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:I carefully checked the derivations and theory.;I have read many papers in this area.:I assessed the sensibility of the experiments.:I made a quick assessment of this paper.:N/A,Withdrawn,0,1,,yes,9/25/19,Hebrew University of Jerusalem;Hebrew University of Jerusalem;Hebrew University of Jerusalem,67;67;67,216;216;216,
2020,Hyperbolic Image Embeddings,Valentin Khrulkov;Leyla Mirvakhabova;Evgeniya Ustinova;Ivan Oseledets;Victor Lempitsky,khrulkov.v@gmail.com;leyla.mirvakhabova@skoltech.ru;evgeniya.ustinova@skoltech.ru;i.oseledets@skoltech.ru;v.lempitsky@samsung.com,1;3;3,I have read many papers in this area.:I carefully checked the experiments.:I read the paper thoroughly.:I carefully checked the derivations and theory.;I have read many papers in this area.:I carefully checked the experiments.:I read the paper thoroughly.:I assessed the sensibility of the derivations and theory.;I have read many papers in this area.:I assessed the sensibility of the experiments.:I made a quick assessment of this paper.:I assessed the sensibility of the derivations and theory.,Withdrawn,0,1,,yes,9/25/19,Skolkovo Institute of Science and Technology;Skolkovo Institute of Science and Technology;Skolkovo Institute of Science and Technology;Skolkovo Institute of Science and Technology;Samsung,-1;-1;-1;-1;-1,-1;-1;-1;-1;-1,2;6
2020,Instant Quantization of Neural Networks using Monte Carlo Methods,Gonçalo Mordido;Matthijs Van Keirsbilck;Alexander Keller,goncalo.mordido@hpi.de;matthijsv@nvidia.com;akeller@nvidia.com,3;3;3,I have published one or two papers in this area.:I carefully checked the experiments.:I read the paper thoroughly.:N/A;I have published one or two papers in this area.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:I assessed the sensibility of the derivations and theory.;I do not know much about this area.:I did not assess the experiments.:I made a quick assessment of this paper.:I did not assess the derivations or theory.,Withdrawn,0,0,,yes,9/25/19,Hasso Plattner Institute;NVIDIA;NVIDIA,266;-1;-1,1397;-1;-1,
2020,Gating Revisited: Deep Multi-layer RNNs That Can Be Trained,Mehmet Ozgur Turkoglu;Stefano D'Aronco;Jan Dirk Wegner;Konrad Schindler,ozgur.turkoglu@geod.baug.ethz.ch;stefano.daronco@geod.baug.ethz.ch;jan.wegner@geod.baug.ethz.ch;schindler@geod.baug.ethz.ch,1;3;3,I have read many papers in this area.:I assessed the sensibility of the experiments.:I read the paper thoroughly.:I carefully checked the derivations and theory.;I have published in this field for several years.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:I carefully checked the derivations and theory.;I have read many papers in this area.:I carefully checked the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:I assessed the sensibility of the derivations and theory.,Withdrawn,0,0,,yes,9/25/19,Swiss Federal Institute of Technology;Swiss Federal Institute of Technology;Swiss Federal Institute of Technology;Swiss Federal Institute of Technology,10;10;10;10,13;13;13;13,1
2020,ILS-SUMM: Iterated Local Search for Unsupervised Video Summarization,Yair Shemer;Daniel Rotman;Nahum Shimkin,sy@campus.technion.ac.il;danieln@il.ibm.com;shimkin@ee.technion.ac.il,1;3;6,I have published one or two papers in this area.:I carefully checked the experiments.:I read the paper thoroughly.:I assessed the sensibility of the derivations and theory.;I have read many papers in this area.:I carefully checked the experiments.:I read the paper thoroughly.:I carefully checked the derivations and theory.;I have published in this field for several years.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:I assessed the sensibility of the derivations and theory.,Withdrawn,0,1,,yes,9/25/19,Technion;International Business Machines;Technion,26;-1;26,412;-1;412,1
2020,Quadratic GCN for graph classification,Omer Nagar;Yoram Louzoun,ovednagar@hotmail.com;louzouy@math.biu.ac.il,1;1;1,I have published one or two papers in this area.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:I assessed the sensibility of the derivations and theory.;I have published in this field for several years.:I carefully checked the experiments.:I read the paper thoroughly.:I carefully checked the derivations and theory.;I have read many papers in this area.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:I assessed the sensibility of the derivations and theory.,Withdrawn,0,0,,yes,9/25/19,;Bar Ilan University,-1;95,-1;513,
2020,Topological based classification using graph convolutional networks,Roy Abel;Idan Benami;Yoram Louzoun,royabel10@gmail.com;louzouy@math.biu.ac.il,3;1;1,I have published in this field for several years.:I carefully checked the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:I carefully checked the derivations and theory.;I have read many papers in this area.:I carefully checked the experiments.:I read the paper thoroughly.:I assessed the sensibility of the derivations and theory.;I have published one or two papers in this area.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:N/A,Withdrawn,0,0,,yes,9/25/19,Bar Ilan University;Bar Ilan University,95;95,513;513,1
2020,Quantifying Layerwise Information Discarding of Neural Networks and Beyond,Haotian Ma;Yinqing Zhang;Fan Zhou;Quanshi Zhang,11612807@mail.sustc.edu.cn;zhangyinqing@sjtu.edu.cn;zhoufan98@sjtu.edu.cn;zqs1022@sjtu.edu.cn,3;3;3,I do not know much about this area.:I carefully checked the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:I assessed the sensibility of the derivations and theory.;I have read many papers in this area.:I assessed the sensibility of the experiments.:I read the paper thoroughly.:I assessed the sensibility of the derivations and theory.;I do not know much about this area.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:I did not assess the derivations or theory.,Withdrawn,0,3,,yes,9/25/19,University of Science and Technology of China;Shanghai Jiao Tong University;Shanghai Jiao Tong University;Shanghai Jiao Tong University,481;53;53;53,80;157;157;157,
2020,Real or Fake: An Empirical Study and Improved Model for Fake Face Detection,Zhengzhe Liu;Xiaojuan Qi;Jiaya Jia;Philip H. S. Torr,liuzhengzhelzz@gmail.com;xiaojuan.qi@eng.ox.ac.uk;leojia@cse.cuhk.edu.hk;philip.torr@eng.ox.ac.uk,3;3;3,I have read many papers in this area.:I did not assess the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:I assessed the sensibility of the derivations and theory.;I have read many papers in this area.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:N/A;I have published in this field for several years.:I assessed the sensibility of the experiments.:I read the paper thoroughly.:I carefully checked the derivations and theory.,Withdrawn,0,3,,yes,9/25/19,;University of Oxford;The Chinese University of Hong Kong;University of Oxford,-1;50;59;50,-1;1;35;1,5
2020,Minimizing Change in Classifier Likelihood to Mitigate Catastrophic Forgetting,Ashish Gaurav;Sachin Vernekar;Sean Sedwards;Jaeyoung Lee;Vahdat Abdelzad;Krzysztof Czarnecki,ashish.gaurav@uwaterloo.ca;sachin.vernekar@uwaterloo.ca;sean.sedwards@uwaterloo.ca;jaeyoung.lee@uwaterloo.ca;vabdelza@gsd.uwaterloo.ca;kczarnec@gsd.uwaterloo.ca,3;3;3,I have published one or two papers in this area.:I carefully checked the experiments.:I read the paper thoroughly.:I assessed the sensibility of the derivations and theory.;I have read many papers in this area.:I carefully checked the experiments.:I read the paper thoroughly.:I did not assess the derivations or theory.;I have read many papers in this area.:I carefully checked the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:I assessed the sensibility of the derivations and theory.,Withdrawn,1,1,,yes,9/25/19,University of Waterloo;University of Waterloo;University of Waterloo;University of Waterloo;University of Waterloo;University of Waterloo,28;28;28;28;28;28,235;235;235;235;235;235,1
2020,A Memory-augmented Neural Network by Resembling Human Cognitive Process of Memorization,Dongjing Shan;Xiongwei Zhang;Chao Zhang;Limin Wang,shandongjing@pku.edu.cn;xwzhang9898@163.com;chzhang@cis.pku.edu.cn;07wanglimin@gmail.com,3;3;1,I have read many papers in this area.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:I assessed the sensibility of the derivations and theory.;I have published one or two papers in this area.:I carefully checked the experiments.:I read the paper thoroughly.:I assessed the sensibility of the derivations and theory.;I have published one or two papers in this area.:I carefully checked the experiments.:I read the paper thoroughly.:I assessed the sensibility of the derivations and theory.,Withdrawn,0,0,,yes,9/25/19,Peking University;163;Peking University;Zhejiang University,22;-1;22;56,24;-1;24;107,
2020,Molecule Property Prediction and Classification with Graph Hypernetworks,Eliya Nachmani;Lior Wolf,enk100@gmail.com;wolf@fb.com,1;6;3,I have published one or two papers in this area.:I carefully checked the experiments.:I read the paper thoroughly.:I assessed the sensibility of the derivations and theory.;I have published one or two papers in this area.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:I assessed the sensibility of the derivations and theory.;I have published in this field for several years.:I assessed the sensibility of the experiments.:I read the paper thoroughly.:I assessed the sensibility of the derivations and theory.,Withdrawn,0,0,,yes,9/25/19,Facebook;Facebook,-1;-1,-1;-1,
2020, Sparsity Learning in Deep Neural Networks,Amirsina Torfi;Rouzbeh A. Shirvani;Sobhan Soleymani;Nasser M. Nasrabadi,atorfi@vt.edu;rouzbeh.asghari@gmail.com;ssoleyma@mix.wvu.edu;nasser.nasrabadi@mail.wvu.edu,3;1;1,I have published one or two papers in this area.:I carefully checked the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:I carefully checked the derivations and theory.;I have read many papers in this area.:I carefully checked the experiments.:I read the paper thoroughly.:I carefully checked the derivations and theory.;I have read many papers in this area.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:N/A,Withdrawn,0,0,,yes,9/25/19,Virginia Tech;;West Virginia University;West Virginia University,79;-1;-1;-1,240;-1;-1;-1,
2020,A Harmonic Structure-Based Neural Network Model for Musical Pitch Detection,Xian Wang;Lingqiao Liu;Qinfeng Shi,xian.wang01@adelaide.edu.au;lingqiao.liu@adelaide.edu.au;javen.shi@adelaide.edu.au,3;3;3,I have published in this field for several years.:I carefully checked the experiments.:I read the paper thoroughly.:I carefully checked the derivations and theory.;I have published in this field for several years.:I carefully checked the experiments.:I read the paper thoroughly.:I assessed the sensibility of the derivations and theory.;I have published in this field for several years.:I carefully checked the experiments.:N/A:N/A,Withdrawn,0,0,,yes,9/25/19,The University of Adelaide;The University of Adelaide;The University of Adelaide,128;128;128,120;120;120,
2020,SEERL : Sample Efficient Ensemble Reinforcement Learning,Rohan Saphal;Balaraman Ravindran;Dheevatsa Mudigere;Sasikanth Avancha;Bharat Kaul,rohansaphal@gmail.com;ravi@cse.iitm.ac.in;dheevatsa@fb.com;sasikanth.avancha@intel.com;bharat.kaul@intel.com,1;1;3,I have published in this field for several years.:I carefully checked the experiments.:I read the paper thoroughly.:I carefully checked the derivations and theory.;I have published in this field for several years.:I carefully checked the experiments.:I read the paper thoroughly.:N/A;I have read many papers in this area.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:N/A,Withdrawn,0,0,,yes,9/25/19,University of Oxford;Indian Institute of Technology Madras;Facebook;Intel;Intel,50;154;-1;-1;-1,1;641;-1;-1;-1,1
2020,Exploring by Exploiting Bad Models in Model-Based Reinforcement Learning,Yixin Lin;Sarah Bechtle;Ludovic Righetti;Akshara Rai;Franziska Meier,yixinlin@fb.com;sbechtle@tuebingen.mpg.de;ludovic.righetti@nyu.edu;akshararai@fb.com;fmeier@fb.com,3;1;1,I have published in this field for several years.:I carefully checked the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:I assessed the sensibility of the derivations and theory.;I have read many papers in this area.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:N/A;I have published in this field for several years.:I carefully checked the experiments.:I read the paper thoroughly.:N/A,Withdrawn,0,0,,yes,9/25/19,"Facebook;Max Planck Institute for Intelligent Systems, Max-Planck Institute;New York University;Facebook;Facebook",-1;-1;25;-1;-1,-1;-1;29;-1;-1,1
2020,Defensive Quantization Layer For Convolutional Network Against Adversarial Attack,Sirui Song;Qinglong Wang;Derek Yang;Yan Song;Xue Liu;Tong Zhang,siruisong97@gmail.com;qinglong.wang@mail.mcgill.ca;dyang1206@gmail.com;songyan@chuangxin.com;xueliu@cs.mcgill.ca;tongzhang0@gmail.com,3;3;1,I have read many papers in this area.:I assessed the sensibility of the experiments.:N/A:N/A;I have read many papers in this area.:I carefully checked the experiments.:I read the paper thoroughly.:I assessed the sensibility of the derivations and theory.;I have published one or two papers in this area.:I assessed the sensibility of the experiments.:I read the paper thoroughly.:I carefully checked the derivations and theory.,Withdrawn,0,1,,yes,9/25/19,"Tsinghua University;McGill University;University of California, San Diego;Sinovation Ventures;McGill University;The Hong Kong University of Science and Technology",8;86;11;-1;86;39,23;42;31;-1;42;47,1;4;4
2020,Learnable Higher-order Representation for Action Recognition,Kai Hu;Bhiksha Raj,kaihu@cmu.edu;bhiksha@cs.cmu.edu,3;3;3,I have published in this field for several years.:I carefully checked the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:I assessed the sensibility of the derivations and theory.;I have published one or two papers in this area.:I carefully checked the experiments.:I read the paper thoroughly.:I assessed the sensibility of the derivations and theory.;I have published in this field for several years.:I carefully checked the experiments.:I read the paper thoroughly.:N/A,Withdrawn,0,1,,yes,9/25/19,Carnegie Mellon University;Carnegie Mellon University,1;1,27;27,1
2020,Meta Module Network for Compositional Visual Reasoning,Wenhu Chen;Zhe Gan;Linjie Li;Yu Cheng;William Wang;Jingjing Liu,wenhuchen@ucsb.edu;zhe.gan@microsoft.com;lindsey.li@microsoft.com;yu.cheng@microsoft.com;william@cs.ucsb.edu;jingjl@microsoft.com,3;3;3,I have read many papers in this area.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:N/A;I have read many papers in this area.:I carefully checked the experiments.:I read the paper thoroughly.:I did not assess the derivations or theory.;I have read many papers in this area.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:I carefully checked the derivations and theory.,Withdrawn,0,1,,yes,9/25/19,UC Santa Barbara;Microsoft;Microsoft;Microsoft;UC Santa Barbara;Microsoft,38;-1;-1;-1;38;-1,57;-1;-1;-1;57;-1,1
2020,Multi-Task Adapters for On-Device Audio Inference,M. Tagliasacchi;F. de Chaumont Quitry;D. Roblek,mtagliasacchi@google.com;fcq@google.com;droblek@google.com,3;3;3,I have published in this field for several years.:I carefully checked the experiments.:I read the paper thoroughly.:I carefully checked the derivations and theory.;I have read many papers in this area.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:I assessed the sensibility of the derivations and theory.;I have read many papers in this area.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:N/A,Withdrawn,0,0,,yes,9/25/19,Google;Google;Google,-1;-1;-1,-1;-1;-1,
2020,Learning audio representations with self-supervision,M. Tagliasacchi;B. Gfeller;F. de Chaumont Quitry;D. Roblek,mtagliasacchi@google.com;beatg@google.com;fcq@google.com;droblek@google.com,3;3;3,I have read many papers in this area.:I carefully checked the experiments.:I read the paper thoroughly.:N/A;I have read many papers in this area.:I assessed the sensibility of the experiments.:I read the paper thoroughly.:N/A;I have read many papers in this area.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:I assessed the sensibility of the derivations and theory.,Withdrawn,0,0,,yes,9/25/19,Google;Google;Google;Google,-1;-1;-1;-1,-1;-1;-1;-1,
2020,Scholastic-Actor-Critic For Multi Agent Reinforcement Learning,Weiying Chen，Ruize Hou,dissolution@126.com;fsszns@163.com,1;1;1;1,I have published one or two papers in this area.:I assessed the sensibility of the experiments.:I made a quick assessment of this paper.:N/A;I have published one or two papers in this area.:I carefully checked the experiments.:I read the paper thoroughly.:I carefully checked the derivations and theory.;I have published one or two papers in this area.:I carefully checked the experiments.:I read the paper thoroughly.:I carefully checked the derivations and theory.;I have published one or two papers in this area.:I assessed the sensibility of the experiments.:I read the paper thoroughly.:I assessed the sensibility of the derivations and theory.,Withdrawn,0,4,,yes,9/25/19,Netaji Subhas Institute of Technology;Peking University,-1;22,-1;24,
2020,Non-Gaussian processes and neural networks at finite widths,Sho Yaida,shoyaida@fb.com,3;3;3,I have read many papers in this area.:I carefully checked the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:I assessed the sensibility of the derivations and theory.;I have published one or two papers in this area.:I assessed the sensibility of the experiments.:N/A:I did not assess the derivations or theory.;I have published one or two papers in this area.:I carefully checked the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:I assessed the sensibility of the derivations and theory.,Withdrawn,0,1,,yes,9/25/19,Facebook,-1,-1,
2020,Uncertainty-aware Variational-Recurrent Imputation Network for Clinical Time Series,Ahmad Wisnu Mulyadi;Eunji Jun;Heung-Il Suk,wisnumulyadi@korea.ac.kr;ejjun92@korea.ac.kr;hisuk@korea.ac.kr,1;3;6;1,I have published one or two papers in this area.:I assessed the sensibility of the experiments.:I made a quick assessment of this paper.:I assessed the sensibility of the derivations and theory.;I have published one or two papers in this area.:I assessed the sensibility of the experiments.:I read the paper thoroughly.:I assessed the sensibility of the derivations and theory.;I have read many papers in this area.:I carefully checked the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:I carefully checked the derivations and theory.;I have published one or two papers in this area.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:I assessed the sensibility of the derivations and theory.,Withdrawn,0,0,,yes,9/25/19,Korea University;Korea University;Korea University,323;323;323,179;179;179,5
2020,An Information Theoretic Perspective on Disentangled Representation Learning,Xiaojiang Yang;Wendong Bi;Yu Cheng;Junchi Yan,yangxiaojiang@sjtu.edu.cn;biwendong1997@gmail.com;yu.cheng@microsoft.com;yanjunchi@sjtu.edu.cn,1;1;3,I have published one or two papers in this area.:I did not assess the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:I assessed the sensibility of the derivations and theory.;I have published in this field for several years.:I carefully checked the experiments.:I read the paper thoroughly.:I carefully checked the derivations and theory.;I have read many papers in this area.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:I carefully checked the derivations and theory.,Withdrawn,0,4,,yes,9/25/19,Shanghai Jiao Tong University;Microsoft;Microsoft;Shanghai Jiao Tong University,53;-1;-1;53,157;-1;-1;157,1;5
2020,Towards a Unified Evaluation of Explanation Methods without Ground Truth,Hao Zhang;Jiayi Chen;Haotian Xue;Quanshi Zhang,1603023-zh@sjtu.edu.cn;miracle3310@sjtu.edu.cn;xavihart@sjtu.edu.cn;zqs1022@sjtu.edu.cn,3;1;6,I have published in this field for several years.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:I assessed the sensibility of the derivations and theory.;I have published one or two papers in this area.:I carefully checked the experiments.:I read the paper thoroughly.:I assessed the sensibility of the derivations and theory.;I have read many papers in this area.:I carefully checked the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:I assessed the sensibility of the derivations and theory.,Withdrawn,0,3,,yes,9/25/19,Shanghai Jiao Tong University;Shanghai Jiao Tong University;Shanghai Jiao Tong University;Shanghai Jiao Tong University,53;53;53;53,157;157;157;157,
2020,Fast Sparse ConvNets,Erich Elsen;Marat Dukhan;Trevor Gale;Karen Simonyan,eriche@google.com;maratek@google.com;tgale@google.com;simonyan@google.com,3;6;3,I have published one or two papers in this area.:I carefully checked the experiments.:I read the paper thoroughly.:I carefully checked the derivations and theory.;I do not know much about this area.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:I did not assess the derivations or theory.;I have read many papers in this area.:I assessed the sensibility of the experiments.:N/A:N/A,Withdrawn,0,3,,yes,9/25/19,Google;Google;Google;Google,-1;-1;-1;-1,-1;-1;-1;-1,1
2020,Locally adaptive activation functions with slope recovery term for deep and physics-informed neural networks,Ameya D. Jagtap;Kenji Kawaguchi;George Em Karniadakis,ameya_jagtap@brown.edu;kawaguch@mit.edu;george_karniadakis@brown.edu,1;3;3,I have published one or two papers in this area.:I assessed the sensibility of the experiments.:I made a quick assessment of this paper.:I did not assess the derivations or theory.;I have published one or two papers in this area.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:I did not assess the derivations or theory.;I have read many papers in this area.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:I did not assess the derivations or theory.,Withdrawn,0,0,,yes,9/25/19,Brown University;Massachusetts Institute of Technology;Brown University,67;2;67,53;5;53,1
2020,GumbelClip: Off-Policy Actor-Critic Using Experience Replay,Norman Tasfi;Miriam Capretz,ntasfi@gmail.com,1;3;3,I have published one or two papers in this area.:I assessed the sensibility of the experiments.:I read the paper thoroughly.:I carefully checked the derivations and theory.;I have published one or two papers in this area.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:N/A;I have published in this field for several years.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:I assessed the sensibility of the derivations and theory.,Withdrawn,0,1,,yes,9/25/19,University of Western Ontario,-1,-1,
2020,Adversarial Neural Pruning,Divyam Madaan;Jinwoo Shin;Sung Ju Hwang,dmadaan@kaist.ac.kr;jinwoos@kaist.ac.kr;sjhwang82@kaist.ac.kr,1;3;3,I have read many papers in this area.:I carefully checked the experiments.:I read the paper thoroughly.:I carefully checked the derivations and theory.;I have published one or two papers in this area.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:I assessed the sensibility of the derivations and theory.;I have read many papers in this area.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:I assessed the sensibility of the derivations and theory.,Withdrawn,0,3,,yes,9/25/19,Korea Advanced Institute of Science and Technology;Korea Advanced Institute of Science and Technology;Korea Advanced Institute of Science and Technology,481;481;481,110;110;110,1;4
2020,Auto-Encoding Explanatory Examples,César Ojeda;David Biesner;Ramses Sanchez;Kostadin Cvejoski;Jannis Schuecker;Christian Bauckhage;Bodgan Georgiev,cesarali07@gmail.com;david.biesner@iais.fraunhofer.de;sanchez@bit.uni-bonn.de;kostadin.cvejoski@iais.fraunhofer.de;jannis.schuecker@iais.fraunhofer.de;christian.bauckhage@iais.fraunhofer.de;bogdan.georgiev@iais.fraunhofer.de,3;3;1,I have read many papers in this area.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:I did not assess the derivations or theory.;I have published one or two papers in this area.:I assessed the sensibility of the experiments.:I read the paper thoroughly.:I assessed the sensibility of the derivations and theory.;I have published one or two papers in this area.:I assessed the sensibility of the experiments.:I read the paper thoroughly.:I assessed the sensibility of the derivations and theory.,Withdrawn,0,1,,yes,9/25/19,Fraunhofer IIS;Fraunhofer IIS;University of Bonn;Fraunhofer IIS;Fraunhofer IIS;Fraunhofer IIS;Fraunhofer IIS,-1;-1;128;-1;-1;-1;-1,-1;-1;106;-1;-1;-1;-1,
2020,Affine Self Convolution,Nichita Diaconu;Daniel E. Worrall,diacon995@gmail.com;d.e.worrall@uva.nl,1;1;3,I have published one or two papers in this area.:I carefully checked the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:I carefully checked the derivations and theory.;I have published one or two papers in this area.:I carefully checked the experiments.:I read the paper thoroughly.:I assessed the sensibility of the derivations and theory.;I have read many papers in this area.:I carefully checked the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:I assessed the sensibility of the derivations and theory.,Withdrawn,0,0,,yes,9/25/19,University of Amsterdam;University of Amsterdam,172;172,62;62,1
2020,Universal Source-Free Domain Adaptation,Jogendra Nath Kundu;Naveen Venkat;Rahul M V;R. Venkatesh Babu,jogendrak@iisc.ac.in;nav.naveenvenkat@gmail.com;rmvenkat@andrew.cmu.edu;venky@iisc.ac.in,3;3;3,I have published in this field for several years.:I carefully checked the experiments.:I read the paper thoroughly.:I carefully checked the derivations and theory.;I have published one or two papers in this area.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:N/A;I do not know much about this area.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:I did not assess the derivations or theory.,Withdrawn,0,4,,yes,9/25/19,Indian Institute of Science;Indian Institute of Science;Carnegie Mellon University;Indian Institute of Science,95;95;1;95,301;301;27;301,4;5
2020,Learning an off-policy predictive state representation for deep reinforcement learning for vision-based steering in autonomous driving,Daniel Graves,dgraves@ualberta.ca,1;3;3,I have published one or two papers in this area.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:N/A;I have read many papers in this area.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:I assessed the sensibility of the derivations and theory.;I have read many papers in this area.:I assessed the sensibility of the experiments.:I read the paper thoroughly.:N/A,Withdrawn,0,4,,yes,9/25/19,University of Alberta,100,136,
2020,$\textrm{D}^2$GAN: A Few-Shot Learning Approach with Diverse and Discriminative Feature Synthesis,Kai Li;Yulun Zhang;Kunpeng Li;Yun Fu,li.kai.gml@gmail.com;yulun100@gmail.com;kunpengli@ece.neu.edu;yunfu@ece.neu.edu,1;6;3,I have published in this field for several years.:I carefully checked the experiments.:I read the paper thoroughly.:N/A;I have published one or two papers in this area.:I assessed the sensibility of the experiments.:I read the paper thoroughly.:I assessed the sensibility of the derivations and theory.;I have published one or two papers in this area.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:I assessed the sensibility of the derivations and theory.,Withdrawn,0,0,,yes,9/25/19,Northeastern University;Northeastern University;Northeastern University;Northeastern University,16;16;16;16,906;906;906;906,4;5;5;6
2020,Hardware-aware One-Shot Neural Architecture Search in Coordinate Ascent Framework,Li Lyna Zhang;Yuqing Yang;Yuhang Jiang;Wenwu Zhu;Yunxin Liu,lzhani@microsoft.com;yuqing.yang@microsoft.com;jyh17@mails.tsinghua.edu.cn;wwzhu@tsinghua.edu.cn;yunxin.liu@microsoft.com,3;1;6,I have read many papers in this area.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:I assessed the sensibility of the derivations and theory.;I have read many papers in this area.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:I assessed the sensibility of the derivations and theory.;I have published one or two papers in this area.:I assessed the sensibility of the experiments.:N/A:I assessed the sensibility of the derivations and theory.,Withdrawn,0,0,,yes,9/25/19,Microsoft;Microsoft;Tsinghua University;Tsinghua University;Microsoft,-1;-1;8;8;-1,-1;-1;23;23;-1,
2020,Multi-task Network Embedding with Adaptive Loss Weighting,Fatemeh Salehi Rizi;Michael Granitzer,fatemeh.salehirizi@uni-passau.de;michael.granitzer@uni-passau.de,3;1;3,I have published in this field for several years.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:I assessed the sensibility of the derivations and theory.;I have published one or two papers in this area.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:I assessed the sensibility of the derivations and theory.;I do not know much about this area.:I did not assess the experiments.:I made a quick assessment of this paper.:I assessed the sensibility of the derivations and theory.,Withdrawn,0,0,,yes,9/25/19,University of Passau;University of Passau,233;233,146;146,5
2020,Perception-Driven Curiosity with Bayesian Surprise,Bernadette Bucher;Anton Arapin;Ramanan Sekar;Marc Badger;Feifei Duan;Oleh Rybkin;Kostas Daniilidis,bucherb@seas.upenn.edu;aarapin@fandm.edu;ramanans@seas.upenn.edu;mbadger@seas.upenn.edu;feifeid@seas.upenn.edu;oleh@seas.upenn.edu;kostas@seas.upenn.edu,1;3;1,I have published one or two papers in this area.:I carefully checked the experiments.:I read the paper thoroughly.:I assessed the sensibility of the derivations and theory.;I have read many papers in this area.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:I did not assess the derivations or theory.;I have published one or two papers in this area.:I carefully checked the experiments.:I read the paper thoroughly.:I assessed the sensibility of the derivations and theory.,Withdrawn,0,0,,yes,9/25/19,University of Pennsylvania;Franklin & Marshall College;University of Pennsylvania;University of Pennsylvania;University of Pennsylvania;University of Pennsylvania;University of Pennsylvania,19;-1;19;19;19;19;19,11;-1;11;11;11;11;11,1
2020,Global reasoning network for image super-resolution,Jiahui Zhang;Bin Zhou;Qingchang Tao;Deqiang Wang,jhzhang988@gmail.com;binzhou@sdu.edu.cn;taoqingchang@mail.tsinghua.edu.cn;wdq_sdu@sdu.edu.cn,1;3;3,I have published one or two papers in this area.:I assessed the sensibility of the experiments.:N/A:N/A;I have read many papers in this area.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:I did not assess the derivations or theory.;I have read many papers in this area.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:N/A,Withdrawn,1,2,,yes,9/25/19,Shandong University;Shandong University;Tsinghua University;Shandong University,154;154;8;154,658;658;23;658,1
2020,MUSE: Multi-Scale Attention Model for Sequence to Sequence Learning,Guangxiang Zhao;Xu Sun;Jingjing Xu;Zhiyuan Zhang;Liangchen Luo,1701214310@pku.edu.cn;xusun@pku.edu.cn;jingjingxu@pku.edu.cn;zzy1210@pku.edu.cn;luolc@pku.edu.cn,3;3;3,I have published in this field for several years.:I carefully checked the experiments.:N/A:N/A;I have published in this field for several years.:I carefully checked the experiments.:I read the paper thoroughly.:N/A;I have published one or two papers in this area.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:I assessed the sensibility of the derivations and theory.,Withdrawn,0,6,,yes,9/25/19,Peking University;Peking University;Peking University;Peking University;Peking University,22;22;22;22;22,24;24;24;24;24,1;3
2020,Utility Analysis of Network Architectures for 3D Point Cloud Processing,Shikun Huang;Binbin Zhang;Wen Shen;Zhihua Wei;Quanshi Zhang,hsk@tongji.edu.cn;0206zbb@tongji.edu.cn;1810068@tongji.edu.cn;zhihua_wei@tongji.edu.cn;zqs1022@sjtu.edu.cn,6;3;1,I do not know much about this area.:I assessed the sensibility of the experiments.:I made a quick assessment of this paper.:N/A;I have read many papers in this area.:I carefully checked the experiments.:I read the paper thoroughly.:I carefully checked the derivations and theory.;I have published one or two papers in this area.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:I assessed the sensibility of the derivations and theory.,Withdrawn,0,3,,yes,9/25/19,Tsinghua University;Tsinghua University;Tsinghua University;Tsinghua University;Shanghai Jiao Tong University,8;8;8;8;53,23;23;23;23;157,1;4
2020,Reducing Sentiment Bias in Language Models via Counterfactual Evaluation,Po-Sen Huang;Huan Zhang;Ray Jiang;Robert Stanforth;Johannes Welbl;Jack Rae;Vishal Maini;Dani Yogatama;Pushmeet Kohli,posenhuang@google.com;huan@huan-zhang.com;rayjiang@google.com;stanforth@google.com;j.welbl@cs.ucl.ac.uk;jwrae@google.com;vmaini@google.com;dyogatama@google.com;pushmeet@google.com,3;3;3,I have published in this field for several years.:I carefully checked the experiments.:I read the paper thoroughly.:I carefully checked the derivations and theory.;I have published in this field for several years.:I carefully checked the experiments.:I read the paper thoroughly.:I assessed the sensibility of the derivations and theory.;I have read many papers in this area.:I carefully checked the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:I carefully checked the derivations and theory.,Withdrawn,0,6,,yes,9/25/19,"Google;University of California, Los Angeles;Google;Google;University College London;Google;Google;Google;Google",-1;20;-1;-1;50;-1;-1;-1;-1,-1;17;-1;-1;15;-1;-1;-1;-1,1;3
2020,BERT for Sequence-to-Sequence Multi-Label Text Classification,Ramil Yarullin;Pavel Serdyukov,ramly@ya.ru;pavel.serdyukov@gmail.com,3;3;1,I have published in this field for several years.:I carefully checked the experiments.:I read the paper thoroughly.:I carefully checked the derivations and theory.;I have read many papers in this area.:I carefully checked the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:N/A;I have published one or two papers in this area.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:N/A,Withdrawn,0,4,,yes,9/25/19,Yandex;,-1;-1,-1;-1,
2020,Boosting Generative Models by Leveraging Cascaded Meta-Models,Fan Bao;Hang Su;Jun Zhu,bf19@mails.tsinghua.edu.cn;suhangss@mail.tsinghua.edu.cn;dcszj@mail.tsinghua.edu.cn,1;6;1,I have read many papers in this area.:I assessed the sensibility of the experiments.:I read the paper thoroughly.:I assessed the sensibility of the derivations and theory.;I have read many papers in this area.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:I assessed the sensibility of the derivations and theory.;I have published one or two papers in this area.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:I assessed the sensibility of the derivations and theory.,Withdrawn,0,0,,yes,9/25/19,Tsinghua University;Tsinghua University;Tsinghua University,8;8;8,23;23;23,1;5
2020,RAT-SQL: Relation-Aware Schema Encoding and Linking for Text-to-SQL Parsers,Bailin Wang*;Richard Shin*;Xiaodong Liu;Oleksandr Polozov;Matthew Richardson,bailin.wang@ed.ac.uk;ricshin@cs.berkeley.edu;xiaodl@microsoft.com;polozov@microsoft.com;mattri@microsoft.com,6;1;3,I have read many papers in this area.:I assessed the sensibility of the experiments.:I read the paper thoroughly.:N/A;I have read many papers in this area.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:I assessed the sensibility of the derivations and theory.;I have read many papers in this area.:I assessed the sensibility of the experiments.:I read the paper thoroughly.:I carefully checked the derivations and theory.,Withdrawn,0,4,,yes,9/25/19,University of Edinburgh;University of California Berkeley;Microsoft;Microsoft;Microsoft,33;5;-1;-1;-1,30;13;-1;-1;-1,1
2020,Shape Features Improve General Model Robustness,Chaowei Xiao;Mingjie Sun;Haonan Qiu;Han Liu;Mingyan Liu;Bo Li,xiaocw@umich.edu;mingjies@andrew.cmu.edu;haonanqiu@link.cuhk.edu.cn;hanliu@northwestern.edu;mingyan@umich.ed;lxbosky@gmail.com,1;1;6,I have read many papers in this area.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:I assessed the sensibility of the derivations and theory.;I have published in this field for several years.:I carefully checked the experiments.:I read the paper thoroughly.:N/A;I have published one or two papers in this area.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:I assessed the sensibility of the derivations and theory.,Withdrawn,0,0,,yes,9/25/19,University of Michigan;Carnegie Mellon University;Tsinghua University;Northwestern University;;University of California Berkeley,8;1;8;44;-1;5,21;27;23;22;-1;13,1;4;4;4;5;5
2020,The Secret Revealer: Generative Model Inversion Attacks Against Deep Neural Networks,Yuheng Zhang;Ruoxi Jia;Hengzhi Pei;Wenxiao Wang;Bo Li;Dawn Song,16307130075@fudan.edu.cn;ruoxijia@berkeley.edu;hzpei16@fudan.edu.cn;wangwx16@mails.tsinghua.edu.cn;lxbosky@gmail.com,6;1;3,I have published one or two papers in this area.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:I assessed the sensibility of the derivations and theory.;I have published one or two papers in this area.:I carefully checked the experiments.:I read the paper thoroughly.:I carefully checked the derivations and theory.;I have published in this field for several years.:I carefully checked the experiments.:I read the paper thoroughly.:I assessed the sensibility of the derivations and theory.,Withdrawn,0,0,,yes,9/25/19,Fudan University;University of California Berkeley;Fudan University;Tsinghua University;University of California Berkeley,79;5;79;8;5,109;13;109;23;13,1;4;4;5;5
2020,Common sense and Semantic-Guided Navigation via Language in Embodied Environments,Dian Yu;Chandra Khatri;Alexandros Papangelis;Mahdi Namazifar;Andrea Madotto;Huaixiu Zheng;Gokhan Tur,dian.yu@uber.com;chandrak@uber.com;apapangelis@uber.com;mahdin@uber.com;amadotto@connect.ust.hk;huaixiu.zheng@uber.com;gokhan@uber.com,1;1;3,I have published in this field for several years.:I carefully checked the experiments.:I read the paper thoroughly.:I carefully checked the derivations and theory.;I have published one or two papers in this area.:I assessed the sensibility of the experiments.:I read the paper thoroughly.:N/A;I have published one or two papers in this area.:I carefully checked the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:N/A,Withdrawn,0,0,,yes,9/25/19,Uber;Uber;Uber;Uber;The Hong Kong University of Science and Technology;Uber;Uber,-1;-1;-1;-1;39;-1;-1,-1;-1;-1;-1;47;-1;-1,1
2020,TransINT: Embedding Implication Rules in Knowledge Graphs with Isomorphic Intersections of Linear Subspaces,So Yeon Min;Preethi Raghavan;Peter Szolovits,symin95@mit.edu;praghav@us.ibm.com;psz@mit.edu,3;3;1,I do not know much about this area.:I did not assess the experiments.:I made a quick assessment of this paper.:I did not assess the derivations or theory.;I have read many papers in this area.:I assessed the sensibility of the experiments.:I made a quick assessment of this paper.:I did not assess the derivations or theory.;I have published in this field for several years.:I carefully checked the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:I assessed the sensibility of the derivations and theory.,Withdrawn,2,3,,yes,9/25/19,Massachusetts Institute of Technology;International Business Machines;Massachusetts Institute of Technology,2;-1;2,5;-1;5,
2020,Meta Label Correction for Learning with Weak Supervision,Guoqing Zheng;Ahmed Hassan Awadallah;Susan Dumais,zheng@microsoft.com;hassanam@microsoft.com;sdumais@microsoft.com,3;3;8;1,I have published one or two papers in this area.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:I assessed the sensibility of the derivations and theory.;I have published one or two papers in this area.:I assessed the sensibility of the experiments.:I read the paper thoroughly.:I carefully checked the derivations and theory.;I have read many papers in this area.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:I assessed the sensibility of the derivations and theory.;I have published one or two papers in this area.:I carefully checked the experiments.:I read the paper thoroughly.:N/A,Withdrawn,0,1,,yes,9/25/19,Microsoft;Microsoft;Microsoft,-1;-1;-1,-1;-1;-1,1;6
2020,Towards Effective and Efficient Zero-shot Learning by Fine-tuning with  Task Descriptions,Tian Jin*;Zhun Liu*;Shengjia Yan;Alexandre Eichenberger;Louis-Philippe Morency,tian.jin1@ibm.com;zhunl@andrew.cmu.edu;sjyan@nyu.edu;alexe@us.ibm.com;morency@cs.cmu.edu,3;1;3,I have published in this field for several years.:I carefully checked the experiments.:I read the paper thoroughly.:I carefully checked the derivations and theory.;I have published one or two papers in this area.:I carefully checked the experiments.:I read the paper thoroughly.:I carefully checked the derivations and theory.;I have published one or two papers in this area.:I carefully checked the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:I assessed the sensibility of the derivations and theory.,Withdrawn,0,0,,yes,9/25/19,International Business Machines;Carnegie Mellon University;New York University;International Business Machines;Carnegie Mellon University,-1;1;25;-1;1,-1;27;29;-1;27,
2020,Multi-hop Question Answering via Reasoning Chains,Jifan Chen;Shih-ting Lin;Greg Durrett,jfchen@cs.utexas.edu;j0717lin@gmail.com;gdurrett@cs.utexas.edu,6;3;3,I have read many papers in this area.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:I assessed the sensibility of the derivations and theory.;I have published in this field for several years.:I carefully checked the experiments.:I read the paper thoroughly.:I carefully checked the derivations and theory.;I have published one or two papers in this area.:I carefully checked the experiments.:I read the paper thoroughly.:N/A,Withdrawn,0,4,,yes,9/25/19,"University of Texas, Austin;;University of Texas, Austin",22;-1;22,38;-1;38,
2020,Factorized Multimodal Transformer for Multimodal Sequential Learning,Amir Zadeh;Chengfeng Mao;Jiaxin Shi;Yiwei Zhang;Paul Pu Liang;Soujanya Poria;Louis-Philippe Morency,abagherz@andrew.cmu.edu;chengfem@andrew.cmu.edu;jiaxins1@andrew.cmu.edu;yiweizh2@andrew.cmu.edu;pliang@cs.cmu.edu;sporia@ntu.edu.sg;morency@cs.cmu.edu,1;3;3,I do not know much about this area.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:N/A;I have published one or two papers in this area.:I assessed the sensibility of the experiments.:I made a quick assessment of this paper.:I assessed the sensibility of the derivations and theory.;I have published one or two papers in this area.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:I assessed the sensibility of the derivations and theory.,Withdrawn,0,0,,yes,9/25/19,Carnegie Mellon University;Carnegie Mellon University;Carnegie Mellon University;Carnegie Mellon University;Carnegie Mellon University;National Taiwan University;Carnegie Mellon University,1;1;1;1;1;86;1,27;27;27;27;27;120;27,
2020,Faster and Just As Accurate: A Simple Decomposition for Transformer Models,Qingqing Cao;Harsh Trivedi;Aruna Balasubramanian;Niranjan Balasubramanian,qicao@cs.stonybrook.edu;hjtrivedi@cs.stonybrook.edu;arunab@cs.stonybrook.edu;niranjan@cs.stonybrook.edu,6;3;3,I have published one or two papers in this area.:I carefully checked the experiments.:I read the paper thoroughly.:I carefully checked the derivations and theory.;I have published one or two papers in this area.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:N/A;I have published one or two papers in this area.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:I carefully checked the derivations and theory.,Withdrawn,1,3,,yes,9/25/19,"State University of New York, Stony Brook;State University of New York, Stony Brook;State University of New York, Stony Brook;State University of New York, Stony Brook",41;41;41;41,304;304;304;304,3
2020,Learning Function-Specific Word Representations,Daniela Gerz;Ivan Vulić;Marek Rei;Roi Reichart;Anna Korhonen,dsg40@cam.ac.uk;iv250@cam.ac.uk;marek.rei@cl.cam.ac.uk;roiri@technion.ac.il;alk23@cam.ac.uk,3;6;3,I have published one or two papers in this area.:I carefully checked the experiments.:I read the paper thoroughly.:I carefully checked the derivations and theory.;I do not know much about this area.:I assessed the sensibility of the experiments.:I read the paper thoroughly.:I assessed the sensibility of the derivations and theory.;I have published one or two papers in this area.:I assessed the sensibility of the experiments.:I made a quick assessment of this paper.:I assessed the sensibility of the derivations and theory.,Withdrawn,0,0,,yes,9/25/19,University of Cambridge;University of Cambridge;University of Cambridge;Technion;University of Cambridge,71;71;71;26;71,3;3;3;412;3,
2020,Attention over Parameters for Dialogue Systems,Andrea Madotto;Zhaojiang Lin;Chien-Sheng Wu;Jamin Shin;Pascale Fung,amadotto@connect.ust.hk;zlinao@connect.ust.hk;wu.jason@salesforce.com;jay.shin@connect.ust.hk;pascale@ece.ust.hk,1;3;1,I have published in this field for several years.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:I assessed the sensibility of the derivations and theory.;I have read many papers in this area.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:I assessed the sensibility of the derivations and theory.;I have published one or two papers in this area.:I carefully checked the experiments.:I read the paper thoroughly.:I carefully checked the derivations and theory.,Withdrawn,0,3,,yes,9/25/19,The Hong Kong University of Science and Technology;The Hong Kong University of Science and Technology;SalesForce.com;The Hong Kong University of Science and Technology;The Hong Kong University of Science and Technology,39;39;-1;39;39,47;47;-1;47;47,
2020,"RL-ST: Reinforcing Style, Fluency and Content Preservation for Unsupervised Text Style Transfer",Bhargav Upadhyay;Akhilesh Sudhakar;Arjun Maheswaran,bhargav@agaralabs.com;akhilesh@agaralabs.com;arjun@agaralabs.com,3;3;1,I have read many papers in this area.:I assessed the sensibility of the experiments.:I read the paper thoroughly.:N/A;I have published one or two papers in this area.:I carefully checked the experiments.:N/A:N/A;I have published one or two papers in this area.:I carefully checked the experiments.:I read the paper thoroughly.:I carefully checked the derivations and theory.,Withdrawn,0,0,,yes,9/25/19,Agara;Agara;Agara,-1;-1;-1,-1;-1;-1,3
2020,Extreme Language Model Compression with Optimal Subwords and Shared Projections,Sanqiang Zhao;Raghav Gupta;Yang Song;Denny Zhou,sanqiang.zhao@pitt.edu;raghavgupta@google.com;yangso@google.com;dennyzhou@google.com,3;3;3,I have published one or two papers in this area.:I assessed the sensibility of the experiments.:I made a quick assessment of this paper.:I assessed the sensibility of the derivations and theory.;I have published one or two papers in this area.:I carefully checked the experiments.:I read the paper thoroughly.:N/A;I have read many papers in this area.:I carefully checked the experiments.:I read the paper thoroughly.:N/A,Withdrawn,0,3,,yes,9/25/19,University of Pittsburgh;Google;Google;Google,79;-1;-1;-1,113;-1;-1;-1,3
2020,Distilling the Knowledge of BERT for Text Generation,Yen-Chun Chen;Zhe Gan;Yu Cheng;Jingzhou Liu;Jingjing Liu,yen-chun.chen@microsoft.com;zhe.gan@microsoft.com;yu.cheng@microsoft.com;jingzhol@andrew.cmu.edu;jingjl@microsoft.com,1;6;3,I have published one or two papers in this area.:I carefully checked the experiments.:I read the paper thoroughly.:I carefully checked the derivations and theory.;I have published one or two papers in this area.:I carefully checked the experiments.:I read the paper thoroughly.:I carefully checked the derivations and theory.;I have published in this field for several years.:I carefully checked the experiments.:I read the paper thoroughly.:I carefully checked the derivations and theory.,Withdrawn,0,0,,yes,9/25/19,Microsoft;Microsoft;Microsoft;Carnegie Mellon University;Microsoft,-1;-1;-1;1;-1,-1;-1;-1;27;-1,1;3;3
2020,DCTD: Deep Conditional Target Densities for Accurate Regression,Fredrik K. Gustafsson;Martin Danelljan;Goutam Bhat;Thomas B. Schön,fredrik.gustafsson@it.uu.se;martin.danelljan@vision.ee.ethz.ch;goutam.bhat@vision.ee.ethz.ch;thomas.schon@it.uu.se,3;6;1,I do not know much about this area.:I carefully checked the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:I carefully checked the derivations and theory.;I have published one or two papers in this area.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:I carefully checked the derivations and theory.;I have read many papers in this area.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:I carefully checked the derivations and theory.,Withdrawn,0,0,,yes,9/25/19,Uppsala University;Swiss Federal Institute of Technology;Swiss Federal Institute of Technology;Uppsala University,154;10;10;154,102;13;13;102,1;2;2
2020,A Gradient-based Architecture HyperParameter Optimization Approach,Zechun Liu;Xiangyu Zhang;Zhe Li;Yichen Wei;Kwang-Ting Cheng;Jian Sun,zliubq@connect.ust.hk;zhangxiangyu@megvii.com;lizhe@megvii.com;weiyichen@megvii.com;timcheng@ust.hk;sunjian@megvii.com,3;1;3,I have published one or two papers in this area.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:I assessed the sensibility of the derivations and theory.;I have published one or two papers in this area.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:I assessed the sensibility of the derivations and theory.;I have read many papers in this area.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:I did not assess the derivations or theory.,Withdrawn,0,0,,yes,9/25/19,The Hong Kong University of Science and Technology;Megvii Technology Inc.;Megvii Technology Inc.;Megvii Technology Inc.;The Hong Kong University of Science and Technology;Megvii Technology Inc.,39;-1;-1;-1;39;-1,47;-1;-1;-1;47;-1,
2020,Generalizing Natural Language Analysis through Span-relation Representations,Zhengbao Jiang;Wei Xu;Jun Araki;Graham Neubig,zhengbaj@cs.cmu.edu;weixu@cse.ohio-state.edu;jun.araki@us.bosch.com;gneubig@cs.cmu.edu,3;3;6,I have published in this field for several years.:I carefully checked the experiments.:I read the paper thoroughly.:I carefully checked the derivations and theory.;I have published one or two papers in this area.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:I carefully checked the derivations and theory.;I have published in this field for several years.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:N/A,Withdrawn,0,1,,yes,9/25/19,Carnegie Mellon University;;Bosch;Carnegie Mellon University,1;-1;-1;1,27;-1;-1;27,3
2020,On the Distribution of Penultimate Activations of Classification Networks,Minkyo Seo;Yoonho Lee;Suha Kwak,mkseo@postech.ac.kr;einet89@gmail.com;suha.kwak@postech.ac.kr,1;3;3,I have published in this field for several years.:I assessed the sensibility of the experiments.:I read the paper thoroughly.:I carefully checked the derivations and theory.;I have read many papers in this area.:I assessed the sensibility of the experiments.:I read the paper thoroughly.:I carefully checked the derivations and theory.;I have read many papers in this area.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:I assessed the sensibility of the derivations and theory.,Withdrawn,0,0,,yes,9/25/19,POSTECH;;POSTECH,118;-1;118,146;-1;146,5
2020,Learning to Sit: Synthesizing Human-Chair Interactions via Hierarchical Control,Yu-Wei Chao;Jimei Yang;Weifeng Chen;Jia Deng,ychao@nvidia.com;jimyang@adobe.com;wfchen@umich.edu;jiadeng@princeton.edu,3;3;1,I have published one or two papers in this area.:I carefully checked the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:N/A;I have published one or two papers in this area.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:N/A;I have published in this field for several years.:I assessed the sensibility of the experiments.:I read the paper thoroughly.:I assessed the sensibility of the derivations and theory.,Withdrawn,0,0,,yes,9/25/19,NVIDIA;Adobe Systems;University of Michigan;Princeton University,-1;-1;8;31,-1;-1;21;6,
2020,"Unsupervised Few-shot Object Recognition by Integrating Adversarial, Self-supervision, and Deep Metric Learning of Latent Parts",Khoi Nguyen;Sinisa Todorovic,nguyenkh@oregonstate.edu;sinisa@oregonstate.edu,1;1;3,I have published one or two papers in this area.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:I assessed the sensibility of the derivations and theory.;I have read many papers in this area.:I assessed the sensibility of the experiments.:I read the paper thoroughly.:I assessed the sensibility of the derivations and theory.;I have read many papers in this area.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:N/A,Withdrawn,0,0,,yes,9/25/19,Oregon State University;Oregon State University,77;77,373;373,4;5;6
2020,BERT Wears GloVes: Distilling Static Embeddings from Pretrained Contextual Representations,Rishi Bommasani;Kelly Davis;Claire Cardie,rb724@cornell.edu;kdavis@mozilla.com;cardie@cs.cornell.edu,3;3;3,I have read many papers in this area.:I carefully checked the experiments.:I read the paper thoroughly.:N/A;I have published in this field for several years.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:I assessed the sensibility of the derivations and theory.;I have read many papers in this area.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:I assessed the sensibility of the derivations and theory.,Withdrawn,0,0,,yes,9/25/19,Cornell University;Mozilla;Cornell University,7;-1;7,19;-1;19,3
2020,Mixed Setting Training Methods for Incremental Slot-Filling Tasks,Daniel C. Michelin;Jonathan K. Kummerfeld;Kevin Leach;Stefan Larson;Yunqi Zhang;Joeseph J. Peper,daniel@clinc.com;jkk@clinc.com;kevin.leach@clinc.com;slars@clinc.com;yunqi@clinc.com;joe@clinc.com,1;1;1,I have published one or two papers in this area.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:N/A;I have published in this field for several years.:I carefully checked the experiments.:I read the paper thoroughly.:N/A;I have published in this field for several years.:I carefully checked the experiments.:I read the paper thoroughly.:I assessed the sensibility of the derivations and theory.,Withdrawn,0,0,,yes,9/25/19,Clinc;Clinc;Clinc;Clinc;Clinc;Clinc,233;233;233;233;233;233,-1;-1;-1;-1;-1;-1,
2020,PLEX: PLanner and EXecutor for Embodied Learning in Navigation,Gil Avraham;Yan Zuo;Tom Drummond,gil.avraham@monash.edu;yan.zuo@monash.edu;tom.drummond@monash.edu,3;1;1,I have published in this field for several years.:I carefully checked the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:I assessed the sensibility of the derivations and theory.;I have published one or two papers in this area.:I carefully checked the experiments.:I read the paper thoroughly.:I assessed the sensibility of the derivations and theory.;I have read many papers in this area.:I carefully checked the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:I assessed the sensibility of the derivations and theory.,Withdrawn,0,0,,yes,9/25/19,Monash University;Monash University;Monash University,118;118;118,75;75;75,1
2020,UniLoss: Unified Surrogate Loss by Adaptive Interpolation,Lanlan Liu;Mingzhe Wang;Jia Deng,llanlan@umich.edu;mingzhew@cs.princeton.edu;jiadeng@princeton.edu,3;3;3,I have published one or two papers in this area.:I carefully checked the experiments.:I read the paper thoroughly.:I carefully checked the derivations and theory.;I have read many papers in this area.:I carefully checked the experiments.:I read the paper thoroughly.:I assessed the sensibility of the derivations and theory.;I have published one or two papers in this area.:I carefully checked the experiments.:I read the paper thoroughly.:I assessed the sensibility of the derivations and theory.,Withdrawn,0,1,,yes,9/25/19,University of Michigan;Princeton University;Princeton University,8;31;31,21;6;6,
2020,MobileBERT: Task-Agnostic Compression of BERT by Progressive Knowledge Transfer,Zhiqing Sun;Hongkun Yu;Xiaodan Song;Renjie Liu;Yiming Yang;Denny Zhou,zhiqings@andrew.cmu.edu;hongkuny@google.com;xiaodansong@google.com;renjieliu@google.com;yiming@cs.cmu.edu;dennyzhou@google.com,6;3;3;3,I have read many papers in this area.:I carefully checked the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:N/A;I have read many papers in this area.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:I assessed the sensibility of the derivations and theory.;I have read many papers in this area.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:I assessed the sensibility of the derivations and theory.;I have published one or two papers in this area.:I assessed the sensibility of the experiments.:I read the paper thoroughly.:I assessed the sensibility of the derivations and theory.,Withdrawn,0,8,,yes,9/25/19,Carnegie Mellon University;Google;Google;Google;Carnegie Mellon University;Google,1;-1;-1;-1;1;-1,27;-1;-1;-1;27;-1,3;3
2020,Interactive Classification by Asking Informative Questions,Lili Yu;Howard Chen;Sida I. Wang;Yoav Artzi and Tao Lei,liliyu@asapp.com;hchen@asapp.com;sidaw@cs.princeton.edu;yoav@cs.cornell.edu;tao@asapp.com,6;1;3,I have published one or two papers in this area.:I assessed the sensibility of the experiments.:I read the paper thoroughly.:I assessed the sensibility of the derivations and theory.;I have published in this field for several years.:I assessed the sensibility of the experiments.:I read the paper thoroughly.:I did not assess the derivations or theory.;I have published one or two papers in this area.:I carefully checked the experiments.:I read the paper thoroughly.:I carefully checked the derivations and theory.,Withdrawn,0,0,,yes,9/25/19,ASAPP Inc;ASAPP Inc;Princeton University;Cornell University;ASAPP Inc,-1;-1;31;7;-1,-1;-1;6;19;-1,
2020,Cross-Lingual Vision-Language Navigation,An Yan;Xin Wang;Jiangtao Feng;Lei Li;William Wang,ayan@ucsd.edu;xwang@cs.ucsb.edu;fengjiangtao@bytedance.com;lileilab@bytedance.com;william@cs.ucsb.edu,6;3;1,I do not know much about this area.:I did not assess the experiments.:I made a quick assessment of this paper.:I did not assess the derivations or theory.;I have published one or two papers in this area.:I carefully checked the experiments.:I read the paper thoroughly.:I carefully checked the derivations and theory.;I have published one or two papers in this area.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:I assessed the sensibility of the derivations and theory.,Withdrawn,0,0,,yes,9/25/19,"University of California, San Diego;UC Santa Barbara;Bytedance;Bytedance;UC Santa Barbara",11;38;-1;-1;38,31;57;-1;-1;57,1;4
2020,Single Deep Counterfactual Regret Minimization,Eric Steinberger,ericsteinberger.est@gmail.com,3;6;1,I have published one or two papers in this area.:I carefully checked the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:I assessed the sensibility of the derivations and theory.;I have read many papers in this area.:I carefully checked the experiments.:I read the paper thoroughly.:I assessed the sensibility of the derivations and theory.;I have published one or two papers in this area.:I carefully checked the experiments.:I read the paper thoroughly.:I assessed the sensibility of the derivations and theory.,Withdrawn,0,1,,yes,9/25/19,Massachusetts Institute of Technology,2,5,
2020,I love your chain mail! Making knights smile in a fantasy game world,Shrimai Prabhumoye;Margaret Li;Jack Urbanek;Emily Dinan;Douwe Kiela;Jason Weston;Arthur Szlam,sprabhum@cs.cmu.edu;margaretli@fb.com;jju@fb.com;edinan@fb.com;dkiela@fb.com;jase@fb.com;aszlam@fb.com,3;1;3,I have published one or two papers in this area.:I carefully checked the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:N/A;I have published one or two papers in this area.:I carefully checked the experiments.:I read the paper thoroughly.:N/A;I do not know much about this area.:I carefully checked the experiments.:I read the paper thoroughly.:N/A,Withdrawn,0,0,,yes,9/25/19,Carnegie Mellon University;Facebook;Facebook;Facebook;Facebook;Facebook;Facebook,1;-1;-1;-1;-1;-1;-1,27;-1;-1;-1;-1;-1;-1,
2020,DOUBLE-HARD DEBIASING: TAILORING WORD EMBEDDINGS FOR GENDER BIAS MITIGATION,Tianlu Wang;Xi Victoria Lin;Nazneen Fatema Rajani;Vicente Ordonez;Caimng Xiong,tianlu@virginia.edu;xilin@salesforce.com;nazneen.rajani@salesforce.com;vicente@virginia.edu;cxiong@salesforce.com,3;3;3,I have read many papers in this area.:I assessed the sensibility of the experiments.:I made a quick assessment of this paper.:N/A;I have published one or two papers in this area.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:N/A;I have read many papers in this area.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:I did not assess the derivations or theory.,Withdrawn,0,0,,yes,9/25/19,University of Virginia;SalesForce.com;SalesForce.com;University of Virginia;SalesForce.com,59;-1;-1;59;-1,107;-1;-1;107;-1,
2020,Joint text classification on multiple levels with multiple labels,Miruna Pîslar;Marek Rei,miruna.pislar@gmail.com;marek.rei@cl.cam.ac.uk,1;3;1,I have published one or two papers in this area.:I carefully checked the experiments.:I read the paper thoroughly.:I carefully checked the derivations and theory.;I have read many papers in this area.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:I assessed the sensibility of the derivations and theory.;I have read many papers in this area.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:I assessed the sensibility of the derivations and theory.,Withdrawn,0,3,,yes,9/25/19,University of Cambridge;University of Cambridge,71;71,3;3,
2020,Discrete Transformer,Jambay Kinley;Yuntian Deng;Alexander M. Rush,j_kinley@college.harvard.edu;dengyuntian@seas.harvard.edu;arush@cornell.edu,3;3;1,I do not know much about this area.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:N/A;I have published in this field for several years.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:N/A;I have published one or two papers in this area.:I carefully checked the experiments.:I read the paper thoroughly.:I carefully checked the derivations and theory.,Withdrawn,0,1,,yes,9/25/19,Harvard University;Harvard University;Cornell University,39;39;7,7;7;19,3;3
2020,Pragmatic Evaluation of Adversarial Examples in Natural Language,John Morris;Eli Lifland;Ji Gao;Jack Lanchantin;Yangfeng Ji;Yanjun Qi,jm8wx@virginia.edu;edl9cy@virginia.edu;jg6yd@virginia.edu;jjl5sw@virginia.edu;yj3fs@virginia.edu;yq2h@virginia.edu,6;3;3,I have published one or two papers in this area.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:I assessed the sensibility of the derivations and theory.;I have read many papers in this area.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:N/A;I have read many papers in this area.:I carefully checked the experiments.:I read the paper thoroughly.:N/A,Withdrawn,1,3,,yes,9/25/19,University of Virginia;University of Virginia;University of Virginia;University of Virginia;University of Virginia;University of Virginia,59;59;59;59;59;59,107;107;107;107;107;107,3;4;4
2020,Question Generation from Paragraphs: A Tale of Two Hierarchical Models,Vishwajeet Kumar;Raktim Chaki;Sai Teja Talluri;Ganesh Ramakrishnan;Yuan-Fang Li;Gholamreza Haffari,vishwajeet@cse.iitb.ac.in;raktimchaki@cse.iitb.ac.in;saiteja.talluri@gmail.com;ganesh@cse.iitb.ac.in;yuanfang.li@monash.edu;gholamreza.haffari@monash.edu,1;1;1,I have published one or two papers in this area.:I carefully checked the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:I carefully checked the derivations and theory.;I have read many papers in this area.:I carefully checked the experiments.:I read the paper thoroughly.:I carefully checked the derivations and theory.;I do not know much about this area.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:I assessed the sensibility of the derivations and theory.,Withdrawn,0,0,,yes,9/25/19,Indian Institute of Technology Bombay;Indian Institute of Technology Bombay;Indian Institute of Technology Bombay;Indian Institute of Technology Bombay;Monash University;Monash University,118;118;118;118;118;118,480;480;480;480;75;75,
2020,Should All Cross-Lingual Embeddings Speak English?,Antonios Anastasopoulos;Graham Neubig,aanastas@andrew.cmu.edu;gneubig@cs.cmu.edu,3;3;3,I have published in this field for several years.:I carefully checked the experiments.:I read the paper thoroughly.:N/A;I have published in this field for several years.:I carefully checked the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:I carefully checked the derivations and theory.;I have published in this field for several years.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:I assessed the sensibility of the derivations and theory.,Withdrawn,0,0,,yes,9/25/19,Carnegie Mellon University;Carnegie Mellon University,1;1,27;27,
2020,Couple-VAE: Mitigating the Encoder-Decoder Incompatibility in Variational Text Modeling with Coupled Deterministic Networks,Chen Wu;Prince Zizhuang Wang;William Yang Wang,wu-c16@mails.tsinghua.edu.cn;zizhuang_wang@ucsb.edu;william@cs.ucsb.edu,3;3;3,I have published one or two papers in this area.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:I assessed the sensibility of the derivations and theory.;I have published one or two papers in this area.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:I assessed the sensibility of the derivations and theory.;I have read many papers in this area.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:I assessed the sensibility of the derivations and theory.,Withdrawn,0,1,,yes,9/25/19,Tsinghua University;UC Santa Barbara;UC Santa Barbara,8;38;38,23;57;57,1;5;5
2020,Task-agnostic Continual Learning via Growing Long-Term Memory Networks,Germán Kruszewski;Ionut Teodor Sorodoc;Tomas Mikolov,germank@gmail.com;ionutteodor.sorodoc@upf.edu;tmikolov@fb.com,6;6;3,I have read many papers in this area.:I carefully checked the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:I assessed the sensibility of the derivations and theory.;I have published one or two papers in this area.:I assessed the sensibility of the experiments.:I read the paper thoroughly.:N/A;I have read many papers in this area.:I carefully checked the experiments.:N/A:N/A,Withdrawn,0,0,,yes,9/25/19,;Universitat Pompeu Fabra;Facebook,-1;481;-1,-1;141;-1,1;3
2020,Exploring the Pareto-Optimality between Quality and Diversity in Text Generation,Jianing Li;Yanyan Lan;Jiafeng Guo;Xueqi Cheng,lijianing@ict.ac.cn;lanyanyan@ict.ac.cn;guojiafeng@ict.ac.cn;cxq@ict.ac.cn,1;3;3,I do not know much about this area.:I did not assess the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:I assessed the sensibility of the derivations and theory.;I have published one or two papers in this area.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:I assessed the sensibility of the derivations and theory.;I have published one or two papers in this area.:I carefully checked the experiments.:I read the paper thoroughly.:I assessed the sensibility of the derivations and theory.,Withdrawn,0,3,,yes,9/25/19,"Institute of Computing Technology, Chinese Academy of Sciences;Institute of Computing Technology, Chinese Academy of Sciences;Institute of Computing Technology, Chinese Academy of Sciences;Institute of Computing Technology, Chinese Academy of Sciences",59;59;59;59,1397;1397;1397;1397,1
2020,An Empirical Study of Encoders and Decoders in Graph-Based Dependency Parsing,Ge Wang;Ziyuan Hu;Zechuan Hu;Kewei Tu,wangge@shanghaitech.edu.cn;huzy@shanghaitech.edu.cn;huzch@shanghaitech.edu.cn;tukw@shanghaitech.edu.cn,3;3,I have read many papers in this area.:I carefully checked the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:I assessed the sensibility of the derivations and theory.;I have read many papers in this area.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:N/A,Withdrawn,0,0,,yes,9/25/19,ShanghaiTech University;ShanghaiTech University;ShanghaiTech University;ShanghaiTech University,-1;-1;-1;-1,-1;-1;-1;-1,
2020,Hierarchical Summary-to-Article Generation,Wangchunshu Zhou;Tao Ge;Ke Xu;Furu Wei;Ming Zhou,v-waz@microsoft.com;tage@microsoft.com;kexu@nlsde.buaa.edu.cn;fuwei@microsoft.com;mingzhou@microsoft.com,3;3;3,I have read many papers in this area.:I carefully checked the experiments.:I read the paper thoroughly.:I carefully checked the derivations and theory.;I have published in this field for several years.:I carefully checked the experiments.:I read the paper thoroughly.:I carefully checked the derivations and theory.;I have published one or two papers in this area.:I carefully checked the experiments.:I read the paper thoroughly.:I carefully checked the derivations and theory.,Withdrawn,0,4,,yes,9/25/19,Microsoft;Microsoft;Beihang University;Microsoft;Microsoft,-1;-1;118;-1;-1,-1;-1;594;-1;-1,1;3
2020,Anomaly Detection by Deep Direct Density Ratio Estimation,Masahiro Abe;Masashi Sugiyama,masahiro.abe@d2c.co.jp;sugi@k.u-tokyo.ac.jp,3;3;3,I have published in this field for several years.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:I assessed the sensibility of the derivations and theory.;I have published one or two papers in this area.:I assessed the sensibility of the experiments.:I read the paper thoroughly.:I carefully checked the derivations and theory.;I have read many papers in this area.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:I carefully checked the derivations and theory.,Withdrawn,0,0,,yes,9/25/19,;The University of Tokyo,-1;56,-1;36,1
2020,Generating Biased Datasets for Neural Natural Language Processing,Alvin Chan;Yi Tay;Yew Soon Ong;Aston Zhang,guoweial001@e.ntu.edu.sg;ytay017@e.ntu.edu.sg;asysong@ntu.edu.sg;astonz@amazon.com,3;3;1,I have published one or two papers in this area.:I carefully checked the experiments.:I read the paper thoroughly.:I assessed the sensibility of the derivations and theory.;I have published one or two papers in this area.:I assessed the sensibility of the experiments.:I read the paper thoroughly.:I assessed the sensibility of the derivations and theory.;I have read many papers in this area.:I carefully checked the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:I assessed the sensibility of the derivations and theory.,Withdrawn,0,0,,yes,9/25/19,National Taiwan University;National Taiwan University;National Taiwan University;Amazon,86;86;86;-1,120;120;120;-1,3;5
2020,3D-SIC: 3D Semantic Instance Completion for RGB-D Scans,Ji Hou;Angela Dai;Matthias Niessner,ji.hou@tum.de;angela.dai@tum.de;niessner@tum.de,6;3;3,I have published one or two papers in this area.:I carefully checked the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:I carefully checked the derivations and theory.;I have read many papers in this area.:I assessed the sensibility of the experiments.:I read the paper thoroughly.:N/A;I have read many papers in this area.:I did not assess the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:N/A,Withdrawn,0,0,,yes,9/25/19,Technical University Munich;Technical University Munich;Technical University Munich,53;53;53,43;43;43,
2020,Towards Holistic and Automatic Evaluation of Open-Domain Dialogue Generation,Bo Pang;Erik Nijkamp;Wenjuan Han;Alex Zhou,bopang@g.ucla.edu;erik.nijkamp@gmail.com;hanwj0309@gmail.com;alexzhou907@gmail.com,1;1;3,I have published in this field for several years.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:I assessed the sensibility of the derivations and theory.;I have published in this field for several years.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:N/A;I have published in this field for several years.:I carefully checked the experiments.:I read the paper thoroughly.:I carefully checked the derivations and theory.,Withdrawn,0,0,,yes,9/25/19,"University of California, Los Angeles;;;",20;-1;-1;-1,17;-1;-1;-1,3
2020,Semi-Supervised Semantic Dependency Parsing Using CRF Autoencoders,Zixia Jia;Youmi Ma;Jiong Cai;Kewei Tu,jiazx@shanghaitech.edu.cn;maym@shanghaitech.edu.cn;caijiong@shanghaitech.edu.cn;tukw@shanghaitech.edu.cn,3;6;3,I have published in this field for several years.:I carefully checked the experiments.:I read the paper thoroughly.:I carefully checked the derivations and theory.;I have read many papers in this area.:I carefully checked the experiments.:I read the paper thoroughly.:I carefully checked the derivations and theory.;I have published one or two papers in this area.:I assessed the sensibility of the experiments.:I read the paper thoroughly.:I assessed the sensibility of the derivations and theory.,Withdrawn,0,0,,yes,9/25/19,ShanghaiTech University;ShanghaiTech University;ShanghaiTech University;ShanghaiTech University,-1;-1;-1;-1,-1;-1;-1;-1,1;5;5
2020,A Syntax-Aware Approach for Unsupervised Text Style Transfer,Yun Ma;Yangbin Chen;Xudong Mao;Qing Li,mayun371@gmail.com;robinchen2-c@my.cityu.edu.hk;xudong.xdmao@gmail.com;qing-prof.li@polyu.edu.hk,3;3;3,I have read many papers in this area.:I assessed the sensibility of the experiments.:I read the paper thoroughly.:N/A;I have published in this field for several years.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:I assessed the sensibility of the derivations and theory.;I have published one or two papers in this area.:I assessed the sensibility of the experiments.:I read the paper thoroughly.:I assessed the sensibility of the derivations and theory.,Withdrawn,0,1,,yes,9/25/19,The Hong Kong Polytechnic University;City University of Hong Kong;The Hong Kong Polytechnic University;The Hong Kong Polytechnic University,172;92;172;172,171;35;171;171,
2020,Contextualized Sparse Representation with Rectified N-Gram Attention for Open-Domain Question Answering,Jinhyuk Lee;Minjoon Seo;Hannaneh Hajishirzi;Jaewoo Kang,jinhyuk_lee@korea.ac.kr;minjoon@cs.washington.edu;hannaneh@washington.edu;kangj@korea.ac.kr,6;3;3,I have published one or two papers in this area.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:N/A;I have read many papers in this area.:I carefully checked the experiments.:I read the paper thoroughly.:I carefully checked the derivations and theory.;I have read many papers in this area.:I assessed the sensibility of the experiments.:I made a quick assessment of this paper.:I assessed the sensibility of the derivations and theory.,Withdrawn,0,4,,yes,9/25/19,Korea University;University of Washington;University of Washington;Korea University,323;6;6;323,179;26;26;179,
2020,Recurrent Layer Attention Network,Eunseok Kim;Inwook Shim,eunseok1117@gmail.com;inugi00@gmail.com,1;3;1,I have read many papers in this area.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:I assessed the sensibility of the derivations and theory.;I have published one or two papers in this area.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:I assessed the sensibility of the derivations and theory.;I have published in this field for several years.:I assessed the sensibility of the experiments.:I read the paper thoroughly.:N/A,Withdrawn,2,1,,yes,9/25/19,Agency for Defense Development;,-1;-1,-1;-1,2
2020,Super-AND: A Holistic Approach to Unsupervised Embedding Learning,Sungwon Han;Yizhan Xu;Sungwon Park;Meeyoung Cha;Cheng-Te Li,lion4151@kaist.ac.kr;re6071020@gs.ncku.edu.tw;psw0416@kaist.ac.kr;mcha@ibs.re.kr;chengte@mail.ncku.edu.tw,1;3;3,I have read many papers in this area.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:I assessed the sensibility of the derivations and theory.;I have published one or two papers in this area.:I assessed the sensibility of the experiments.:I read the paper thoroughly.:I assessed the sensibility of the derivations and theory.;I have read many papers in this area.:I carefully checked the experiments.:I read the paper thoroughly.:N/A,Withdrawn,0,1,,yes,9/25/19,Korea Advanced Institute of Science and Technology;Peking University;Korea Advanced Institute of Science and Technology;Institute for Basic Science;Peking University,481;22;481;-1;22,110;24;110;-1;24,
2020,Natural Language State Representation for Reinforcement Learning,Erez Schwartz;Guy Tennenholtz;Chen Tessler;Shie Mannor,erezschwartz@campus.technion.ac.il;sguyt@campus.technion.ac.il;chen.tessler@gmail.com;shiemannor@gmail.com,1;1;6,I have published one or two papers in this area.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:I did not assess the derivations or theory.;I have published one or two papers in this area.:I assessed the sensibility of the experiments.:I read the paper thoroughly.:N/A;I have read many papers in this area.:I assessed the sensibility of the experiments.:I read the paper thoroughly.:N/A,Withdrawn,0,1,,yes,9/25/19,Technion;Technion;Technion;Technion,26;26;26;26,412;412;412;412,
2020,BEAN: Interpretable Representation Learning with Biologically-Enhanced Artificial Neuronal Assembly Regularization,Yuyang Gao;Giorgio Ascoli;Liang Zhao,ygao13@gmu.edu;ascoli@gmu.edu;lzhao9@gmu.edu,3;1;3,I have published one or two papers in this area.:I assessed the sensibility of the experiments.:I read the paper thoroughly.:N/A;I have published in this field for several years.:I assessed the sensibility of the experiments.:I read the paper thoroughly.:I carefully checked the derivations and theory.;I have read many papers in this area.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:I assessed the sensibility of the derivations and theory.,Withdrawn,0,1,,yes,9/25/19,George Mason University;George Mason University;George Mason University,100;100;100,282;282;282,1
2020,Revisiting Fine-tuning for Few-shot Learning,Akihiro Nakamura;Tatsuya Harada,nakamura@mi.t.u-tokyo.ac.jp;harada@mi.t.u-tokyo.ac.jp,1;3;1,I have published one or two papers in this area.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:I carefully checked the derivations and theory.;I have published one or two papers in this area.:I carefully checked the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:N/A;I have published one or two papers in this area.:I carefully checked the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:I carefully checked the derivations and theory.,Withdrawn,0,0,,yes,9/25/19,The University of Tokyo;The University of Tokyo,56;56,36;36,1;6
2020,Unrestricted Adversarial Attacks For Semantic Segmentation,Guangyu Shen;Chengzhi Mao;Junfeng Yang;Baishakhi Ray,shen447@purdue.edu;cm3797@columbia.edu;junfeng@cs.columbia.edu;rayb@cs.columbia.edu,6;6;1,I have read many papers in this area.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:N/A;I have published one or two papers in this area.:I carefully checked the experiments.:I read the paper thoroughly.:I assessed the sensibility of the derivations and theory.;I have published one or two papers in this area.:I carefully checked the experiments.:I read the paper thoroughly.:I carefully checked the derivations and theory.,Withdrawn,0,0,,yes,9/25/19,Purdue University;Columbia University;Columbia University;Columbia University,27;15;15;15,88;16;16;16,1;2;4;4;5;5
2020,End-to-End Multi-Domain Task-Oriented Dialogue Systems with Multi-level Neural Belief Tracker,Hung Le;Doyen Sahoo;Chenghao Liu;Nancy F. Chen;Steven C.H. Hoi,l.hung1610@gmail.com;dsahoo@salesforce.com;chliu@smu.edu.sg;nfychen@i2r.a-star.edu.sg;shoi@salesforce.com,3;3;3;3,I have published in this field for several years.:I carefully checked the experiments.:I read the paper thoroughly.:I carefully checked the derivations and theory.;I have published one or two papers in this area.:I carefully checked the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:I carefully checked the derivations and theory.;I have published one or two papers in this area.:I carefully checked the experiments.:I read the paper thoroughly.:N/A;I have read many papers in this area.:I carefully checked the experiments.:I read the paper thoroughly.:N/A,Withdrawn,0,0,,yes,9/25/19,Singapore Management University;SalesForce.com;Singapore Management University;A*STAR;SalesForce.com,92;-1;92;-1;-1,1397;-1;1397;-1;-1,
2020,Accelerate DNN Inference  By Inter-Operator Parallelization,Yaoyao Ding;Ligeng Zhu;Zhihao Jia;Song Han,yyding@mit.edu;ligeng@mit.edu;zhihao@cs.stanford.edu;songhan@mit.edu,3;1;3,I do not know much about this area.:I did not assess the experiments.:I made a quick assessment of this paper.:I did not assess the derivations or theory.;I have read many papers in this area.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:N/A;I have published in this field for several years.:I assessed the sensibility of the experiments.:I read the paper thoroughly.:N/A,Withdrawn,0,0,,yes,9/25/19,Massachusetts Institute of Technology;Massachusetts Institute of Technology;Stanford University;Massachusetts Institute of Technology,2;2;4;2,5;5;4;5,1
2020,Posterior Control of Blackbox Generation ,Xiang Lisa Li;Alexander M. Rush,xli150@jhu.edu;srush@seas.harvard.edu,3;3;6,I do not know much about this area.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:I carefully checked the derivations and theory.;I have published one or two papers in this area.:I carefully checked the experiments.:I read the paper thoroughly.:I assessed the sensibility of the derivations and theory.;I do not know much about this area.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:I assessed the sensibility of the derivations and theory.,Withdrawn,0,0,,yes,9/25/19,Johns Hopkins University;Harvard University,73;39,12;7,1;3
2020,Learning to Generate 3D Training Data through Hybrid Gradient,Dawei Yang;Jia Deng,ydawei@umich.edu;jiadeng@princeton.edu,8;3;3,I have read many papers in this area.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:I assessed the sensibility of the derivations and theory.;I have read many papers in this area.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:I assessed the sensibility of the derivations and theory.;I have published in this field for several years.:I carefully checked the experiments.:I read the paper thoroughly.:I carefully checked the derivations and theory.,Withdrawn,0,0,,yes,9/25/19,University of Michigan;Princeton University,8;31,21;6,
2020,Learning to Learn via Gradient Component Corrections,Christian Simon;Piotr Koniusz;Richard Nock;Mehrtash Harandi,christian.simon@anu.edu.au;peter.koniusz@data61.csiro.au;richard.nock@data61.csiro.au;mehrtash.harandi@monash.edu,1;3;3,I do not know much about this area.:I did not assess the experiments.:I made a quick assessment of this paper.:I assessed the sensibility of the derivations and theory.;I have published one or two papers in this area.:I carefully checked the experiments.:I read the paper thoroughly.:I carefully checked the derivations and theory.;I have published one or two papers in this area.:I carefully checked the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:I carefully checked the derivations and theory.,Withdrawn,0,1,,yes,9/25/19,"Australian National University;, CSIRO;, CSIRO;Monash University",108;233;233;118,50;-1;-1;75,1;6;6
2020,Counting the Paths in Deep Neural Networks as a Performance Predictor,Michele Sasdelli;Ian Reid;Gustavo Carneiro,michele.sasdelli@adelaide.edu.au;ian.reid@adelaide.edu.au;gustavo.carneiro@adelaide.edu.au,3;1;3,I have published one or two papers in this area.:I carefully checked the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:I carefully checked the derivations and theory.;I have read many papers in this area.:I assessed the sensibility of the experiments.:I made a quick assessment of this paper.:I assessed the sensibility of the derivations and theory.;I have published in this field for several years.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:I assessed the sensibility of the derivations and theory.,Withdrawn,0,0,,yes,9/25/19,The University of Adelaide;The University of Adelaide;The University of Adelaide,128;128;128,120;120;120,1
2020,VUSFA:Variational Universal Successor Features Approximator ,Shamane Siriwardhana;Rivindu Weerasakera;Denys J.C. Matthies;Suranga Nanayakkara,shamane@ahlab.org;rivindu@ahlab.org;denys@ahlab.org;suranga@ahlab.org,1;1;1,I have published one or two papers in this area.:I carefully checked the experiments.:I read the paper thoroughly.:I assessed the sensibility of the derivations and theory.;I have published one or two papers in this area.:I carefully checked the experiments.:I read the paper thoroughly.:N/A;I have published one or two papers in this area.:I assessed the sensibility of the experiments.:I read the paper thoroughly.:N/A,Withdrawn,0,3,,yes,9/25/19,University of Auckland;;;,266;-1;-1;-1,177;-1;-1;-1,6
2020,Data Annealing Transfer learning Procedure for Informal Language Understanding Tasks,Jing Gu;Yu Zhou,jkgu@ucdavis.edu;joyu@ucdavis.edu,3;3;1;3,I have read many papers in this area.:I assessed the sensibility of the experiments.:I read the paper thoroughly.:I carefully checked the derivations and theory.;I do not know much about this area.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:I assessed the sensibility of the derivations and theory.;I have read many papers in this area.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:I assessed the sensibility of the derivations and theory.;I have published in this field for several years.:I carefully checked the experiments.:I read the paper thoroughly.:I carefully checked the derivations and theory.,Withdrawn,0,0,,yes,9/25/19,"University of California, Davis;University of California, Davis",79;79,55;55,1;3;6
2020,Building Hierarchical Interpretations in Natural Language via Feature Interaction Detection,Hanjie Chen;Guangtao Zheng;Yangfeng Ji,hc9mx@virginia.edu;gz5hp@virginia.edu;yangfeng@virginia.edu,3;1;1,I have published one or two papers in this area.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:I assessed the sensibility of the derivations and theory.;I have published one or two papers in this area.:I carefully checked the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:N/A;I have published one or two papers in this area.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:I carefully checked the derivations and theory.,Withdrawn,0,1,,yes,9/25/19,University of Virginia;University of Virginia;University of Virginia,59;59;59,107;107;107,3
2020,Mem2Mem: Learning to Summarize Long Texts with Memory-to-Memory Transfer,Jaehong Park;Jonathan Pilault;Christopher Pal,jaehong.park@elementai.com;jonathan.pilault@elementai.com;christopher.pal@elementai.com,3;3;3,I have published in this field for several years.:I carefully checked the experiments.:I read the paper thoroughly.:I assessed the sensibility of the derivations and theory.;I have read many papers in this area.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:N/A;I have published one or two papers in this area.:I carefully checked the experiments.:I read the paper thoroughly.:I carefully checked the derivations and theory.,Withdrawn,0,1,,yes,9/25/19,Element AI;Element AI;Element AI,-1;-1;-1,-1;-1;-1,
2020,Improving Neural Abstractive Summarization Using Transfer Learning and Factuality-Based Evaluation: Towards Automating Science Journalism,Rumen Dangovski*;Michelle Shen*;Dawson Byrd*;Li Jing*;Preslav Nakov;Marin Soljacic,rumenrd@mit.edu;mcshen99@mit.edu;dbyrd@exeter.edu;ljing@mit.edu;pnakov@qf.org.qa;soljacic@mit.edu,1;1;1,I have published one or two papers in this area.:I carefully checked the experiments.:I read the paper thoroughly.:I carefully checked the derivations and theory.;I have read many papers in this area.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:I assessed the sensibility of the derivations and theory.;I have published one or two papers in this area.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:I assessed the sensibility of the derivations and theory.,Withdrawn,0,1,,yes,9/25/19,Massachusetts Institute of Technology;Massachusetts Institute of Technology;Phillips Exeter Academy;Massachusetts Institute of Technology;QCRI;Massachusetts Institute of Technology,2;2;-1;2;-1;2,5;5;-1;5;-1;5,1;6
2020,Higher-order Weighted Graph Convolutional Networks,Songtao Liu;Lingwei Chen;Hanze Dong;Zihao Wang;Dinghao Wu;Zengfeng Huang,stliu15@fudan.edu.cn;lvc5613@psu.edu;hdongaj@ust.hk;zzw166@psu.edu;duw12@psu.edu;huangzf@fudan.edu.cn,3;3;3,I have published one or two papers in this area.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:I assessed the sensibility of the derivations and theory.;I have published in this field for several years.:I carefully checked the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:I carefully checked the derivations and theory.;I have published in this field for several years.:I carefully checked the experiments.:I read the paper thoroughly.:I assessed the sensibility of the derivations and theory.,Withdrawn,0,1,,yes,9/25/19,Fudan University;Pennsylvania State University;The Hong Kong University of Science and Technology;Pennsylvania State University;Pennsylvania State University;Fudan University,79;41;39;41;41;79,109;78;47;78;78;109,
2020,Distilling Neural Networks for Faster and Greener Dependency Parsing,Mark Anderson;Carlos Gómez-Rodríguez,mark.anderson.nlp@gmail.com;carlos.gomez@udc.es,3;6;1,I have published in this field for several years.:I assessed the sensibility of the experiments.:I read the paper thoroughly.:I carefully checked the derivations and theory.;I have published one or two papers in this area.:I assessed the sensibility of the experiments.:I read the paper thoroughly.:N/A;I have published in this field for several years.:I carefully checked the experiments.:I read the paper thoroughly.:I carefully checked the derivations and theory.,Withdrawn,0,5,,yes,9/25/19,Universidade da Coruña;Universidade da Coruña,-1;-1,-1;-1,1;3;3
2020,From Here to There: Video Inbetweening Using Direct 3D Convolutions,Yunpeng Li;Dominik Roblek;Marco Tagliasacchi,yunpeng@google.com;droblek@google.com;mtagliasacchi@google.com,3;3;3,I have read many papers in this area.:I carefully checked the experiments.:I read the paper thoroughly.:I carefully checked the derivations and theory.;I have published one or two papers in this area.:I assessed the sensibility of the experiments.:N/A:N/A;I have published one or two papers in this area.:I carefully checked the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:I assessed the sensibility of the derivations and theory.,Withdrawn,0,1,,yes,9/25/19,Google;Google;Google,-1;-1;-1,-1;-1;-1,4
2020,ON SOLVING COOPERATIVE DECENTRALIZED MARL PROBLEMS WITH SPARSE REINFORCEMENTS,Rajiv Ranjan Kumar;Pradeep Varakantham,rajivrk.2017@phdis.smu.edu.sg;pradeepv@smu.edu.sg,1;6;1,I have read many papers in this area.:I carefully checked the experiments.:I read the paper thoroughly.:I carefully checked the derivations and theory.;I do not know much about this area.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:I assessed the sensibility of the derivations and theory.;I have published one or two papers in this area.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:I did not assess the derivations or theory.,Withdrawn,0,0,,yes,9/25/19,Singapore Management University;Singapore Management University,92;92,1397;1397,1
2020,On the Anomalous Generalization of GANs,Jinchen Xuan;Yunchang Yang;Ze Yang;Di He;Liwei Wang,1600012865@pku.edu.cn;1500010650@pku.edu.cn;yangze@pku.edu.cn;dihe@microsoft.com;wanglw@cis.pku.edu.cn,1;3;6,I have published one or two papers in this area.:I assessed the sensibility of the experiments.:I made a quick assessment of this paper.:I assessed the sensibility of the derivations and theory.;I have published in this field for several years.:I carefully checked the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:I assessed the sensibility of the derivations and theory.;I have read many papers in this area.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:I did not assess the derivations or theory.,Withdrawn,0,0,,yes,9/25/19,Peking University;Peking University;Peking University;Microsoft;Peking University,22;22;22;-1;22,24;24;24;-1;24,1;4;5;5
2020,Bridging the domain gap in cross-lingual document classification,Guokun Lai;Barlas Oguz;Yiming Yang;Veselin Stoyanov,guokun@cs.cmu.edu;barlaso@fb.com;yiming@cs.cmu.edu;ves@fb.com,3;3;3,I have published in this field for several years.:I carefully checked the experiments.:I read the paper thoroughly.:I carefully checked the derivations and theory.;I have published in this field for several years.:I carefully checked the experiments.:N/A:N/A;I have read many papers in this area.:I carefully checked the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:I assessed the sensibility of the derivations and theory.,Withdrawn,0,0,,yes,9/25/19,Carnegie Mellon University;Facebook;Carnegie Mellon University;Facebook,1;-1;1;-1,27;-1;27;-1,1;3;3
2020,NAMSG: An Efficient Method for Training Neural Networks,Yushu Chen;Hao Jing;Wenlai Zhao;Zhiqiang Liu;Ouyi Li;Liang Qiao;Haohuan Fu;Wei Xue;Guangwen Yang,yschen11@126.com;jinghao0320@gmail.com;cryinlaugh@gmail.com;gt_liuzq@163.com;18801087946@163.com;qiaoliang6363@163.com;haohuan@tsinghua.edu.cn;xuewei@mail.tsinghua.edu.cn;ygw@mail.tsinghua.edu.cn,3;3;1,I do not know much about this area.:I assessed the sensibility of the experiments.:I made a quick assessment of this paper.:I assessed the sensibility of the derivations and theory.;I do not know much about this area.:I assessed the sensibility of the experiments.:I made a quick assessment of this paper.:I did not assess the derivations or theory.;I have read many papers in this area.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:I did not assess the derivations or theory.,Withdrawn,2,4,,yes,9/25/19,126;;;163;163;163;Tsinghua University;Tsinghua University;Tsinghua University,-1;-1;-1;-1;-1;-1;8;8;8,-1;-1;-1;-1;-1;-1;23;23;23,
2020,INTERPRETING CNN  PREDICTION THROUGH  LAYER - WISE SELECTED DISCERNIBLE NEURONS,Md Tauhid Bin Iqbal;Abdul Muqeet;Sung-Ho Bae,tauhidiq@khu.ac.kr;amuqeet@khu.ac.kr;shbae@khu.ac.kr,1;3;1,I do not know much about this area.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:N/A;I have published one or two papers in this area.:I assessed the sensibility of the experiments.:I read the paper thoroughly.:I assessed the sensibility of the derivations and theory.;I have read many papers in this area.:I assessed the sensibility of the experiments.:I read the paper thoroughly.:I assessed the sensibility of the derivations and theory.,Withdrawn,0,0,,yes,9/25/19,Kyung Hee University;Kyung Hee University;Kyung Hee University,481;481;481,319;319;319,
2020,Toward Controllable Text Content Manipulation,Shuai Lin;Wentao Wang;Zhiting Hu;Zichao Yang;Xiaodan Liang;Haoran Shi;Frank Xu;Eric Xing,shuailin97@gmail.com;wwt.cpp@gmail.com;zhitinghu@gmail.com;yangtze2301@gmail.com;xdliang328@gmail.com;haoranshi97@gmail.com;eric.xing@petuum.com,3;1;6,I have read many papers in this area.:I carefully checked the experiments.:I read the paper thoroughly.:I assessed the sensibility of the derivations and theory.;I have read many papers in this area.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:N/A;I have read many papers in this area.:I assessed the sensibility of the experiments.:I read the paper thoroughly.:N/A,Withdrawn,0,0,,yes,9/25/19,SUN YAT-SEN UNIVERSITY;Peking University;Carnegie Mellon University;;SUN YAT-SEN UNIVERSITY;Carnegie Mellon University;Petuum Inc.,481;22;1;-1;481;1;-1,299;24;27;-1;299;27;-1,
2020,Learning Low-rank Deep Neural Networks via Singular Vector Orthogonality Regularization and Singular Value Sparsification,Huanrui Yang;Minxue Tang;Wei Wen;Feng Yan;Daniel Hu;Ang Li;Hai Li,huanrui.yang@duke.edu;tangmx16@mails.tsinghua.edu.cn;wei.wen@duke.edu;fyan@unr.edu;danielhu2003@gmail.com;ang.li630@duke.edu;hai.li@duke.edu,3;1,I have published one or two papers in this area.:I carefully checked the experiments.:I read the paper thoroughly.:I carefully checked the derivations and theory.;I have published in this field for several years.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:I carefully checked the derivations and theory.,Withdrawn,0,0,,yes,9/25/19,"Duke University;Tsinghua University;Duke University;University of Nevada, Reno;Newport High School;Duke University;Duke University",47;8;47;266;-1;47;47,20;23;20;1397;-1;20;20,1
2020,FAST LEARNING VIA EPISODIC MEMORY: A PERSPECTIVE FROM ANIMAL DECISION-MAKING,Xiaohan Zhang;Lu Liu;Guodong Long;jing jiang;Shenquan Liu,xh1315255662@gmail.com;lu.liu.cs@icloud.com;guodong.long@uts.edu.au;jing.jiang@uts.edu.au;mashqliu@scut.edu.cn,1;1,I have published one or two papers in this area.:I assessed the sensibility of the experiments.:I made a quick assessment of this paper.:I assessed the sensibility of the derivations and theory.;I do not know much about this area.:I assessed the sensibility of the experiments.:I read the paper thoroughly.:N/A,Withdrawn,0,0,,yes,9/25/19,South China University of Technology;University of Technology Sydney;University of Technology Sydney;University of Technology Sydney;South China University of Technology,481;108;108;108;481,501;193;193;193;501,5
2020,Improving and Stabilizing Deep Energy-Based Learning,Lifu Tu;Richard Yuanzhe Pang;Kevin Gimpel,lifu@ttic.edu;yzpang@nyu.edu;kgimpel@ttic.edu,6;1;1,I have published in this field for several years.:I assessed the sensibility of the experiments.:I read the paper thoroughly.:N/A;I have read many papers in this area.:I did not assess the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:N/A;I have published one or two papers in this area.:I carefully checked the experiments.:I read the paper thoroughly.:I carefully checked the derivations and theory.,Withdrawn,0,0,,yes,9/25/19,Toyota Technological Institute at Chicago;New York University;Toyota Technological Institute at Chicago,-1;25;-1,-1;29;-1,1
2020,INTERPRETING CNN COMPRESSION USING INFORMATION BOTTLENECK,Hui Xiang;Feifei Shi;Peng Wang;Qigang Wang;Zhongchao Shi,xianghui1@lenovo.com;shiff3@lenovo.com;wangpeng31@lenovo.com;wangqg1@lenovo.com;shizc2@lenovo.com,1;1;1,I have read many papers in this area.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:I assessed the sensibility of the derivations and theory.;I have read many papers in this area.:I did not assess the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:I did not assess the derivations or theory.;I have read many papers in this area.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:I assessed the sensibility of the derivations and theory.,Withdrawn,0,0,,yes,9/25/19,Lenovo Research;Lenovo Research;Lenovo Research;Lenovo Research;Lenovo Research,-1;-1;-1;-1;-1,-1;-1;-1;-1;-1,1
2020,Conversation Generation with Concept Flow,Houyu Zhang;Zhenghao Liu;Chenyan Xiong;Zhiyuan Liu,houyu_zhang@brown.edu;liu-zh16@mails.tsinghua.edu.cn;chenyan.xiong@microsoft.com;liuzy@tsinghua.edu.cn,6;3;3,I have published one or two papers in this area.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:N/A;I have published in this field for several years.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:N/A;I have published one or two papers in this area.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:N/A,Withdrawn,0,0,,yes,9/25/19,Brown University;Tsinghua University;Microsoft;Tsinghua University,67;8;-1;8,53;23;-1;23,
2020,iSOM-GSN: An Integrative Approach for Transforming Multi-omic Data into Gene Similarity Networks via Self-organizing Maps,Nazia Fatima;Johan Fernandes;Luis Rueda,fatiman@uwindsor.ca;ferna11i@uwindsor.ca;lrueda@uwindsor.ca,3;3;1,I have read many papers in this area.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:I assessed the sensibility of the derivations and theory.;I have read many papers in this area.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:I assessed the sensibility of the derivations and theory.;I have published in this field for several years.:I assessed the sensibility of the experiments.:I read the paper thoroughly.:I carefully checked the derivations and theory.,Withdrawn,0,0,,yes,9/25/19,University of Windsor;University of Windsor;University of Windsor,-1;-1;-1,-1;-1;-1,5
2020,Task-Agnostic Robust Encodings for Combating Adversarial Typos,Erik Jones;Robin Jia;Aditi Raghunathan;Percy Liang,erik.jones313@gmail.com;robinjia@stanford.edu;aditir@stanford.edu;pliang@cs.stanford.edu,3;3;3,I do not know much about this area.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:I assessed the sensibility of the derivations and theory.;I do not know much about this area.:I assessed the sensibility of the experiments.:I made a quick assessment of this paper.:I assessed the sensibility of the derivations and theory.;I have published one or two papers in this area.:I assessed the sensibility of the experiments.:I read the paper thoroughly.:I assessed the sensibility of the derivations and theory.,Withdrawn,0,4,,yes,9/25/19,Stanford University;Stanford University;Stanford University;Stanford University,4;4;4;4,4;4;4;4,1;3;4
2020,Natural Language Adversarial Attack and Defense in Word Level,Xiaosen Wang;Hao Jin;Kun He,xiaosen@hust.edu.cn;mailtojinhao@hust.edu.cn;brooklet60@hust.edu.cn,6;3;3,I have published one or two papers in this area.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:I assessed the sensibility of the derivations and theory.;I have published one or two papers in this area.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:N/A;I have read many papers in this area.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:N/A,Withdrawn,0,2,,yes,9/25/19,Hong Kong University of Science and Technology;Hong Kong University of Science and Technology;Hong Kong University of Science and Technology,39;39;39,47;47;47,1;2;3;3;4;4
2020,Randomness in Deconvolutional Networks for Visual Representation,Kun He;Jingbo Wang;Haochuan Li;Yao Shu;Liwei Wang;John E. Hopcroft,brooklet60@hust.edu.cn;jingbow@usc.edu;lhchuan@pku.edu.cn;shuyao95@gmail.com;wanglw@cis.pku.edu.cn;jeh@cs.cornell.edu,1;3;3,I have published one or two papers in this area.:I assessed the sensibility of the experiments.:I made a quick assessment of this paper.:I did not assess the derivations or theory.;I have read many papers in this area.:I assessed the sensibility of the experiments.:I read the paper thoroughly.:I assessed the sensibility of the derivations and theory.;I have read many papers in this area.:I assessed the sensibility of the experiments.:I made a quick assessment of this paper.:I assessed the sensibility of the derivations and theory.,Withdrawn,0,0,,yes,9/25/19,Hong Kong University of Science and Technology;University of Southern California;Peking University;National University of Singapore;Peking University;Cornell University,39;31;22;16;22;7,47;62;24;25;24;19,5
2020,An Inter-Layer Weight Prediction and Quantization for Deep Neural Networks based on Smoothly Varying Weight Hypothesis,Kang-Ho Lee;JoonHyun Jung;Sung-Ho Bae,ho7719@khu.ac.kr;doublejtoh@khu.ac.kr;shbae@khu.ac.kr,3;1;3,I have published one or two papers in this area.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:I assessed the sensibility of the derivations and theory.;I have published one or two papers in this area.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:I assessed the sensibility of the derivations and theory.;I have published one or two papers in this area.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:I assessed the sensibility of the derivations and theory.,Withdrawn,0,0,,yes,9/25/19,Kyung Hee University;Kyung Hee University;Kyung Hee University,481;481;481,319;319;319,
2020,Generalized Transformation-based Gradient,Anbang Wu,wab@zju.edu.cn,3;1;6,I have published one or two papers in this area.:I assessed the sensibility of the experiments.:I read the paper thoroughly.:I assessed the sensibility of the derivations and theory.;I have published one or two papers in this area.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:I assessed the sensibility of the derivations and theory.;I have read many papers in this area.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:I assessed the sensibility of the derivations and theory.,Withdrawn,0,3,,yes,9/25/19,Zhejiang University,56,107,
2020,Learning Multi-facet Embeddings of Phrases and Sentences using Sparse Coding for Unsupervised Semantic Applications,Haw-Shiuan Chang;Amol Agrawal;Andrew McCallum,hschang@cs.umass.edu;amolagrawal@cs.umass.edu;mccallum@cs.umass.edu,3;3;3,I have read many papers in this area.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:N/A;I have read many papers in this area.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:N/A;I have read many papers in this area.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:N/A,Withdrawn,0,1,,yes,9/25/19,"University of Massachusetts, Amherst;University of Massachusetts, Amherst;University of Massachusetts, Amherst",28;28;28,209;209;209,3
2020,Making DenseNet Interpretable: A Case Study in Clinical Radiology,Kwun Ho Ngan;Artur d'Avila Garcez;Karen M. Knapp;Andy Appelboam;Constantino Carlos Reyes-Aldasoro,kwun-ho.ngan@city.ac.uk;a.garcez@city.ac.uk;k.m.knapp@exeter.ac.uk;andy.appelboam@nhs.net;reyes@city.ac.uk,1;1;3,I have read many papers in this area.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:N/A;I have read many papers in this area.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:I assessed the sensibility of the derivations and theory.;I have read many papers in this area.:I carefully checked the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:I carefully checked the derivations and theory.,Withdrawn,0,1,,yes,9/25/19,"City, University of London;City, University of London;University of Exeter;;City, University of London",-1;-1;390;-1;-1,-1;-1;146;-1;-1,2
2020,Learning Classifier Synthesis for Generalized Few-Shot Learning,Han-Jia Ye;Hexiang Hu;De-Chuan Zhan;Fei Sha,yehj@lamda.nju.edu.cn;hexiang.frank.hu@gmail.com;zhandc@nju.edu.cn;feisha@usc.edu,3;3;1,I have published in this field for several years.:I carefully checked the experiments.:I read the paper thoroughly.:I carefully checked the derivations and theory.;I have read many papers in this area.:I carefully checked the experiments.:I read the paper thoroughly.:I carefully checked the derivations and theory.;I have published one or two papers in this area.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:N/A,Withdrawn,0,1,,yes,9/25/19,Zhejiang University;University of Southern California;Zhejiang University;University of Southern California,56;31;56;31,107;62;107;62,6
2020,Restoration of Video Frames from a Single Blurred Image with Motion Understanding,Dawit Mureja Argaw;Junsik Kim;Francois Rameau;Chaoning Zhang;In so Kweon,dawitmureja@kaist.ac.kr;mibastro@gmail.com;rameau.fr@gmail.com;chaoningzhang1990@gmail.com;iskweon77@kaist.ac.kr,3;6;3,I have published in this field for several years.:I carefully checked the experiments.:I read the paper thoroughly.:I carefully checked the derivations and theory.;I do not know much about this area.:I assessed the sensibility of the experiments.:I read the paper thoroughly.:N/A;I have read many papers in this area.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:I assessed the sensibility of the derivations and theory.,Withdrawn,0,0,,yes,9/25/19,Korea Advanced Institute of Science and Technology;Korea Advanced Institute of Science and Technology;Korea Advanced Institute of Science and Technology;Korea Advanced Institute of Science and Technology;Korea Advanced Institute of Science and Technology,481;481;481;481;481,110;110;110;110;110,
2020,Open-Set Domain Adaptation with Category-Agnostic Clusters,Yingwei Pan;Ting Yao;Yehao Li;Chong-Wah Ngo;Tao Mei,panyw.ustc@gmail.com;tingyao.ustc@gmail.com;yehaoli.sysu@gmail.com;cscwngo@cityu.edu.hk;tmei@live.com,3;3;3,I have published one or two papers in this area.:I carefully checked the experiments.:I read the paper thoroughly.:I carefully checked the derivations and theory.;I have published in this field for several years.:I carefully checked the experiments.:I read the paper thoroughly.:N/A;I have published in this field for several years.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:I assessed the sensibility of the derivations and theory.,Withdrawn,0,0,,yes,9/25/19,JD AI Research;JD AI Research;SUN YAT-SEN UNIVERSITY;City University of Hong Kong;JD AI Research,-1;-1;481;92;-1,-1;-1;299;35;-1,
2020,Understanding Distributional Ambiguity via Non-robust Chance Constraint,Shumin MA;LEUNG Cheuk Hang;Qi WU;Wei Liu,shuminma@cityu.edu.hk;chleung87@cityu.edu.hk;qiwu55@cityu.edu.hk;wl2223@columbia.edu,3;1;3,I do not know much about this area.:I did not assess the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:I assessed the sensibility of the derivations and theory.;I do not know much about this area.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:I carefully checked the derivations and theory.;I do not know much about this area.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:I did not assess the derivations or theory.,Withdrawn,0,0,,yes,9/25/19,City University of Hong Kong;City University of Hong Kong;City University of Hong Kong;Columbia University,92;92;92;15,35;35;35;16,
2020,Simple but effective techniques to reduce dataset biases,Rabeeh Karimi Mahabadi;James Henderson,rkarimi@idiap.ch;james.henderson@idiap.ch,3;6;1,I have read many papers in this area.:I assessed the sensibility of the experiments.:I read the paper thoroughly.:N/A;I have published in this field for several years.:I carefully checked the experiments.:I read the paper thoroughly.:I carefully checked the derivations and theory.;I have published one or two papers in this area.:I carefully checked the experiments.:I read the paper thoroughly.:I carefully checked the derivations and theory.,Withdrawn,0,1,,yes,9/25/19,Idiap Research Institute;Idiap Research Institute,-1;-1,-1;-1,1
2020,EfferenceNets for latent space planning,Hlynur Davíð Hlynsson;Merlin Schüler;Robin Schiewer;Laurenz Wiskott,hlynurd@gmail.com;merlin.schueler@ini.rub.de;robin.schiewer@ini.rub.de;laurenz.wiskott@ini.rub.de,1;1;1,I have published in this field for several years.:I carefully checked the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:I carefully checked the derivations and theory.;I have published in this field for several years.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:N/A;I have published one or two papers in this area.:I assessed the sensibility of the experiments.:N/A:N/A,Withdrawn,0,0,,yes,9/25/19,;Ruhr-Universtät Bochum;Ruhr-Universtät Bochum;Ruhr-Universtät Bochum,-1;-1;-1;-1,-1;-1;-1;-1,
2020,Mining GANs for knowledge transfer to small domains,Yaxing Wang;Abel Gonzalez-Garcia;David Berga;Luis Herranz;Fahad Shahbaz Khan;Joost van de Weijer,yaxing@cvc.uab.es;agonzalez@cvc.uab.es;dberga@cvc.uab.es;lherranz@cvc.uab.es;fahad.khan@liu.se;joost@cvc.uab.es,3;3;3,I have published one or two papers in this area.:I carefully checked the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:N/A;I have published one or two papers in this area.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:I assessed the sensibility of the derivations and theory.;I have read many papers in this area.:I assessed the sensibility of the experiments.:N/A:I assessed the sensibility of the derivations and theory.,Withdrawn,0,0,,yes,9/25/19,"Computer Vision Center, Universitat Autònoma de Barcelona;Computer Vision Center, Universitat Autònoma de Barcelona;Computer Vision Center, Universitat Autònoma de Barcelona;Computer Vision Center, Universitat Autònoma de Barcelona;Linköping University;Computer Vision Center, Universitat Autònoma de Barcelona",-1;-1;-1;-1;481;-1,-1;-1;-1;-1;407;-1,5;5
2020,"EMS: End-to-End Model Search for Network Architecture, Pruning and Quantization",Tianzhe Wang;Kuan Wang;Han Cai;Ji Lin;Yujun Lin;Zhijian Liu;Song Han,usedtobe@mit.edu;wangkuan15@mails.tsinghua.edu.cn;hancai@mit.edu;jilin@mit.edu;yujunlin@mit.edu;zhijian@mit.edu;songhan@mit.edu,3;1;1,I have read many papers in this area.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:N/A;I have published in this field for several years.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:I assessed the sensibility of the derivations and theory.;I have read many papers in this area.:I assessed the sensibility of the experiments.:N/A:I assessed the sensibility of the derivations and theory.,Withdrawn,1,0,,yes,9/25/19,Massachusetts Institute of Technology;Tsinghua University;Massachusetts Institute of Technology;Massachusetts Institute of Technology;Massachusetts Institute of Technology;Massachusetts Institute of Technology;Massachusetts Institute of Technology,2;8;2;2;2;2;2,5;23;5;5;5;5;5,
2020,Deflecting Adversarial Attacks,Yao Qin;Nicholas Frosst;Colin Raffel;Garrison Cottrell;Geoffrey Hinton,yaq007@eng.ucsd.edu;frosst@google.com;craffel@google.com;gary@eng.ucsd.edu;geoffhinton@google.com,3;3;3,I have published in this field for several years.:I carefully checked the experiments.:I read the paper thoroughly.:N/A;I have published in this field for several years.:I assessed the sensibility of the experiments.:I made a quick assessment of this paper.:I assessed the sensibility of the derivations and theory.;I have published in this field for several years.:I carefully checked the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:N/A,Withdrawn,0,2,,yes,9/25/19,"University of California, San Diego;Google;Google;University of California, San Diego;Google",11;-1;-1;11;-1,31;-1;-1;31;-1,4;4
2020,One Demonstration Imitation Learning,Bradly C. Stadie;Siyan Zhao;Qiqi Xu;Bonnie Li;Lunjun Zhang,bstadie@berkeley.edu;siyan.zhao@mail.utoronto.ca;frances.xu@mail.utoronto.ca;bonnieli20010901@gmail.com;lunjun.zhang@mail.utoronto.ca,1;1;3,I have read many papers in this area.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:N/A;I have published in this field for several years.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:N/A;I have published one or two papers in this area.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:I assessed the sensibility of the derivations and theory.,Withdrawn,0,0,,yes,9/25/19,University of California Berkeley;Toronto University;Toronto University;McGill University;Toronto University,5;18;18;86;18,13;18;18;42;18,
2020,SDNet: Contextualized Attention-based Deep Network for Conversational Question Answering,Chenguang Zhu;Michael Zeng;Xuedong Huang,chezhu@microsoft.com;nzeng@microsoft.com;xdh@microsoft.com,3;3;3,I have published one or two papers in this area.:I carefully checked the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:N/A;I have read many papers in this area.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:I assessed the sensibility of the derivations and theory.;I have published one or two papers in this area.:I carefully checked the experiments.:I read the paper thoroughly.:N/A,Withdrawn,0,0,,yes,9/25/19,Microsoft;Microsoft;Microsoft,-1;-1;-1,-1;-1;-1,1
2020,Differentially Private Survival Function Estimation,Lovedeep Gondara;Ke Wang,lgondara@sfu.ca;wang@sfu.ca,1;1;3,I have read many papers in this area.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:I assessed the sensibility of the derivations and theory.;I have published one or two papers in this area.:I carefully checked the experiments.:I read the paper thoroughly.:I carefully checked the derivations and theory.;I have read many papers in this area.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:I assessed the sensibility of the derivations and theory.,Withdrawn,0,1,,yes,9/25/19,Simon Fraser University;Simon Fraser University,64;64,272;272,
2020,GPU Memory Management for Deep Neural Networks Using Deep Q-Network,Shicheng Chen,coder.chen.shi.cheng@gmail.com,3;3;1,I do not know much about this area.:I assessed the sensibility of the experiments.:N/A:N/A;I have published in this field for several years.:I carefully checked the experiments.:I read the paper thoroughly.:I carefully checked the derivations and theory.;I have read many papers in this area.:I carefully checked the experiments.:I read the paper thoroughly.:N/A,Withdrawn,0,0,,yes,9/25/19,,,,
2020,Meta Decision Trees for Explainable Recommendation Systems,Eyal Shulman;Lior Wolf,shulmaneyal@gmail.com;wolf@fb.com,3;8;3,I have read many papers in this area.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:I assessed the sensibility of the derivations and theory.;I have published one or two papers in this area.:I assessed the sensibility of the experiments.:I read the paper thoroughly.:I carefully checked the derivations and theory.;I do not know much about this area.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:I assessed the sensibility of the derivations and theory.,Withdrawn,0,1,,yes,9/25/19,Tel Aviv University;Facebook,35;-1,188;-1,
2020,Parameterized Action Reinforcement Learning for Inverted Index Match Plan Generation,Linfeng Zhao;Lifei Zhu;Qi Chen;Hui Xue;Haidong Wang;Chuanjie Liu;Yuan Liu;Lawson Wong;Lintao Zhang,zhao.linf@husky.neu.edu;v-lifzh@microsoft.com;cheqi@microsoft.com;xuehui@microsoft.com;haidwa@microsoft.com;chuanli@microsoft.com;yuanliu@neu.edu.cn;lawsonlsw@northeastern.edu;lintaoz@microsoft.com,3;3;1,I have published one or two papers in this area.:I carefully checked the experiments.:I read the paper thoroughly.:N/A;I do not know much about this area.:I assessed the sensibility of the experiments.:I made a quick assessment of this paper.:I did not assess the derivations or theory.;I have published in this field for several years.:I assessed the sensibility of the experiments.:I read the paper thoroughly.:I did not assess the derivations or theory.,Withdrawn,0,5,,yes,9/25/19,Northeastern University;Microsoft;Microsoft;Microsoft;Microsoft;Microsoft;Northeastern University;Northeastern University;Microsoft,16;-1;-1;-1;-1;-1;16;16;-1,906;-1;-1;-1;-1;-1;906;906;-1,
2020,Fault Tolerant Reinforcement Learning via A Markov Game of Control and Stopping,David Mguni,davidmguni@hotmail.com,3;1;3,I have read many papers in this area.:N/A:N/A:I assessed the sensibility of the derivations and theory.;I have published one or two papers in this area.:N/A:I read the paper at least twice and used my best judgement in assessing the paper.:I assessed the sensibility of the derivations and theory.;I have read many papers in this area.:N/A:I read the paper at least twice and used my best judgement in assessing the paper.:I assessed the sensibility of the derivations and theory.,Withdrawn,0,0,,yes,9/25/19,Prowler.io,-1,-1,1;4;4
2020,Fuzzing-Based Hard-Label Black-Box Attacks Against Machine Learning Models,Yi Qin;Chuan Yue,yiqin@mines.edu;chuanyue@mines.edu,3;1;1,I have published in this field for several years.:I carefully checked the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:N/A;I have published one or two papers in this area.:I carefully checked the experiments.:I read the paper thoroughly.:I carefully checked the derivations and theory.;I have published in this field for several years.:I carefully checked the experiments.:I read the paper thoroughly.:I carefully checked the derivations and theory.,Withdrawn,0,5,,yes,9/25/19,Colorado School of Mines;Colorado School of Mines,172;172,343;343,4;4
2020,"Read, Highlight and Summarize: A Hierarchical Neural Semantic Encoder-based Approach",Rajeev Bhatt Ambati;Saptarashmi Bandyopadhyay;Prasenjit Mitra,rajeev24811@gmail.com;sbandyo20@gmail.com;pum10@psu.edu,3;1,I have read many papers in this area.:I carefully checked the experiments.:I read the paper thoroughly.:I carefully checked the derivations and theory.;I have published one or two papers in this area.:I assessed the sensibility of the experiments.:I read the paper thoroughly.:I assessed the sensibility of the derivations and theory.,Withdrawn,0,0,,yes,9/25/19,Pennsylvania State University;Pennsylvania State University;Pennsylvania State University,41;41;41,78;78;78,1;3
2020,Generalization Puzzles in Deep Networks,Qianli Liao;Brando Miranda;Lorenzo Rosasco;Andrzej Banburski;Robert Liang;Jack Hidary;Tomaso Poggio,lql@mit.edu;miranda9@illinois.edu;lrosasco@mit.edu;kappa666@mit.edu;bobliang345@gmail.com;hidary@google.com;tp@csail.mit.edu,1;1;6,I have published one or two papers in this area.:I carefully checked the experiments.:I read the paper thoroughly.:I assessed the sensibility of the derivations and theory.;I have published one or two papers in this area.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:N/A;I have published one or two papers in this area.:I assessed the sensibility of the experiments.:I read the paper thoroughly.:I assessed the sensibility of the derivations and theory.,Withdrawn,0,3,,yes,9/25/19,"Massachusetts Institute of Technology;University of Illinois, Urbana Champaign;Massachusetts Institute of Technology;Massachusetts Institute of Technology;;Google;Massachusetts Institute of Technology",2;3;2;2;-1;-1;2,5;48;5;5;-1;-1;5,1
2020,Recurrent Chunking Mechanisms for Conversational Machine Reading Comprehension,Hongyu Gong;Yelong Shen;Dian Yu;Jianshu Chen;Dong Yu,hgong6@illinois.edu;yelongshen@tencent.com;yudian@tencent.com;jianshuchen@tencent.com;dyu@tencent.com,6;3;1,I have read many papers in this area.:I carefully checked the experiments.:I read the paper thoroughly.:I carefully checked the derivations and theory.;I have published one or two papers in this area.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:N/A;I have published one or two papers in this area.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:N/A,Withdrawn,0,8,,yes,9/25/19,"University of Illinois, Urbana Champaign;Tencent AI Lab;Tencent AI Lab;Tencent AI Lab;Tencent AI Lab",3;-1;-1;-1;-1,48;-1;-1;-1;-1,1
2020,Rethinking Generalized Matrix Factorization for Recommendation: The Importance of Multi-hot Encoding,Lei Feng;Hongxin Wei;Qingyu Guo;Zhuoyi Lin;Bo An,feng0093@e.ntu.edu.sg;owenwei@ntu.edu.sg;qguo005@e.ntu.edu.sg;zhuoyi001@e.ntu.edu.sg;boan@ntu.edu.sg,3;3;1,I have published in this field for several years.:I carefully checked the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:N/A;I have published one or two papers in this area.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:I assessed the sensibility of the derivations and theory.;I have published in this field for several years.:I carefully checked the experiments.:I read the paper thoroughly.:I carefully checked the derivations and theory.,Withdrawn,0,0,,yes,9/25/19,National Taiwan University;National Taiwan University;National Taiwan University;National Taiwan University;National Taiwan University,86;86;86;86;86,120;120;120;120;120,
2020,Extractor-Attention Network: A New Attention Network with Hybrid Encoders for Chinese Text Classification,Junhao Qiu;Ronghua Shi;Fangfang Li (the corresponding author);Jinjing Shi;Wangmin Liao,qiujunhao@csu.edu.cn;shirh@csu.edu.cn;lifangfang@csu.edu.cn;shijinjing@csu.edu.cn;0909123117@csu.edu.cn,1;6;1,I have read many papers in this area.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:I assessed the sensibility of the derivations and theory.;I have read many papers in this area.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:I assessed the sensibility of the derivations and theory.;I have read many papers in this area.:I carefully checked the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:I carefully checked the derivations and theory.,Withdrawn,0,0,,yes,9/25/19,SUN YAT-SEN UNIVERSITY;SUN YAT-SEN UNIVERSITY;SUN YAT-SEN UNIVERSITY;SUN YAT-SEN UNIVERSITY;SUN YAT-SEN UNIVERSITY,481;481;481;481;481,299;299;299;299;299,1
2020,Fooling Pre-trained Language Models: An Evolutionary Approach to Generate Wrong Sentences with High Acceptability Score,Marco Di Giovanni;Marco Brambilla,marco.digiovanni@polimi.it;marco.brambilla@polimi.it,3;3;1,I have published one or two papers in this area.:I assessed the sensibility of the experiments.:I made a quick assessment of this paper.:N/A;I have published one or two papers in this area.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:N/A;I have published one or two papers in this area.:I assessed the sensibility of the experiments.:I made a quick assessment of this paper.:N/A,Withdrawn,0,6,,yes,9/25/19,Politecnico di Milano;Politecnico di Milano,128;128,347;347,3;4;4
2020,The Convex Information Bottleneck Lagrangian,Borja Rodríguez Gálvez;Ragnar Thobaben;Mikael Skoglund,borjarg@kth.se;ragnart@kth.se;skoglund@kth.se,3;3;1,I do not know much about this area.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:I assessed the sensibility of the derivations and theory.;I have published one or two papers in this area.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:I assessed the sensibility of the derivations and theory.;I have published one or two papers in this area.:I did not assess the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:I assessed the sensibility of the derivations and theory.,Withdrawn,0,5,,yes,9/25/19,"KTH Royal Institute of Technology, Stockholm, Sweden;KTH Royal Institute of Technology, Stockholm, Sweden;KTH Royal Institute of Technology, Stockholm, Sweden",128;128;128,222;222;222,1
2020,Deep Learning-Based Average Consensus,Masako Kishida;Masaki Ogura;Yuichi Yoshida;Tadashi Wadayama,kishida@nii.ac.jp;oguram@is.naist.jp;yyoshida@nii.ac.jp;wadayama@nitech.ac.jp,1;1;3,I have published in this field for several years.:I carefully checked the experiments.:I read the paper thoroughly.:I carefully checked the derivations and theory.;I have published one or two papers in this area.:I assessed the sensibility of the experiments.:I read the paper thoroughly.:I carefully checked the derivations and theory.;I do not know much about this area.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:I assessed the sensibility of the derivations and theory.,Withdrawn,0,4,,yes,9/25/19,"Meiji University;Nara Institute of Science and Technology, Japan;Meiji University;Meiji University",481;481;481;481,332;1397;332;332,
2020,STYLE EXAMPLE-GUIDED TEXT GENERATION USING GENERATIVE ADVERSARIAL TRANSFORMERS,Kuo-Hao Zeng;Mohammad Shoeybi;Ming-Yu Liu,khzeng@cs.washington.edu;mshoeybi@nvidia.com;sean.mingyu.liu@gmail.com,3;3;1,I have published in this field for several years.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:I carefully checked the derivations and theory.;I have published one or two papers in this area.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:I assessed the sensibility of the derivations and theory.;I have published one or two papers in this area.:I carefully checked the experiments.:I read the paper thoroughly.:I assessed the sensibility of the derivations and theory.,Withdrawn,0,0,,yes,9/25/19,University of Washington;NVIDIA;NVIDIA,6;-1;-1,26;-1;-1,5
2020,GraphFlow: Exploiting Conversation Flow with Graph Neural Networks for Conversational Machine Comprehension,Yu Chen;Lingfei Wu;Mohammed J. Zaki,cheny39@rpi.edu;lwu@email.wm.edu;zaki@cs.rpi.edu,1;1,I have published one or two papers in this area.:I carefully checked the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:I carefully checked the derivations and theory.;I have published one or two papers in this area.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:I assessed the sensibility of the derivations and theory.,Withdrawn,0,0,,yes,9/25/19,Rensselaer Polytechnic Institute;College of William and Mary;Rensselaer Polytechnic Institute,172;154;172,438;235;438,1
2020,Revisiting the Information Plane,Martin Schiemer;Juan Ye,martin.schiemer@web.de;juan.ye@st-andrews.ac.uk,3;3;1,I have read many papers in this area.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:I assessed the sensibility of the derivations and theory.;I have read many papers in this area.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:N/A;I have published one or two papers in this area.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:N/A,Withdrawn,0,0,,yes,9/25/19,University of St Andrews;University of St Andrews,-1;-1,-1;-1,
2020,Fully Quantized Transformer for Improved Translation,Gabriele Prato;Ella Charlaix;Mehdi Rezagholizadeh,prato.gab@gmail.com;ella.charlaix@huawei.com;mehdi.rezagholizadeh@huawei.com,3;1;3,I have published one or two papers in this area.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:I assessed the sensibility of the derivations and theory.;I do not know much about this area.:I assessed the sensibility of the experiments.:I read the paper at least twice and used my best judgement in assessing the paper.:N/A;I have published one or two papers in this area.:I carefully checked the experiments.:I read the paper thoroughly.:N/A,Withdrawn,0,3,,yes,9/25/19,University of Montreal;Huawei Technologies Ltd.;Huawei Technologies Ltd.,128;-1;-1,85;-1;-1,3